{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5分钟数据",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPO8kKwxk0eI8za+EQflMb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harry-zhao78/colab/blob/master/5%E5%88%86%E9%92%9F%E6%95%B0%E6%8D%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO9HSaFC2-qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "data_to_load = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK31d0zGIDri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb118254-2a15-46a7-c7ed-7b7b259203a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path=\"/content/drive/My Drive/datasets/SH1min.csv\"\n",
        "#df= pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2gTshwp3Aqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import sklearn.metrics\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (15, 10)\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(90)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#saving and loading model\n",
        "\n",
        "\n",
        "#model_save_name = 'dense.h5'\n",
        "#path = F\"/content/drive/My Drive/{model_save_name}\" \n",
        "#model.save(path)\n",
        "#model=keras.models.load_model(path) \n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "#for model evaluation\n",
        "\n",
        "\n",
        "\n",
        "# ytrue=denorm(y_test,df.target)\n",
        "# yhat=denorm(model.predict(X_test),df.target)\n",
        "\n",
        "# model.evaluate(X_test,y_test)\n",
        "# print(\"sklearn mae：\",sklearn.metrics.mean_absolute_error(ytrue,yhat))\n",
        "\n",
        "# gene_hist(ytrue,yhat)\n",
        "# calculate_profit(ytrue,yhat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3peWn6Ig3OXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequences)):\n",
        "# find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "# check if we are beyond the dataset\n",
        "    if end_ix > len(sequences):\n",
        "      break\n",
        "# gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return array(X), array(y)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def denorm (prediction,col):\n",
        "  max=np.max(col)\n",
        "  min=np.min(col)\n",
        "  denormed=prediction*(max-min)+min\n",
        "  denormed=denormed.reshape((len(prediction),1))\n",
        "  return denormed    \n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def gene_hist(a,b):\n",
        "\n",
        "  error = b - a\n",
        "  plt.hist(error, bins = 200)\n",
        "  plt.xlabel(\"Prediction Error\")\n",
        "  plt.xlim(-100, 100)\n",
        "  _ = plt.ylabel(\"Count\")   \n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def gene_scat(a,b):\n",
        "  time=np.arange(0,len(a),1)\n",
        "  plt.plot(time,a)\n",
        "  plt.plot(time,b)\n",
        "\n",
        "\n",
        "#ytrue=denorm(y_test,df.target)\n",
        "#yhat=denorm(model.predict(X_test),df.target)\n",
        "#gene_scat(ytrue,yhat)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def gene_df(a,b):\n",
        "  a=pd.DataFrame(a)\n",
        "  b=pd.DataFrame(b)\n",
        "  c=pd.concat([a,b],axis=1)\n",
        "  c.columns = [\"ytrue\", \"yhat\"]\n",
        "  return c\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def calculate_profit(ytrue,yhat):\n",
        "\n",
        "  #t, ytrue(t+1), yhat(t+1)\n",
        "  returns=gene_df(ytrue,yhat)\n",
        "  returns[\"t\"]=returns.ytrue.shift(1)\n",
        "  returns=pd.concat([returns.t,returns.ytrue,returns.yhat],axis=1)\n",
        "  returns=returns.drop(returns.head(1).index) # drop first n rows\n",
        "\n",
        "  money_array=[]\n",
        "  pos=0\n",
        "  money=0\n",
        "  pos_array=[]\n",
        "\n",
        "  for ind, row in returns.iterrows():\n",
        "    if row.yhat>row.t and pos==0:\n",
        "      money=money-row.t\n",
        "      money_array.append(money+row.t)\n",
        "      pos=pos+1\n",
        "\n",
        "    elif row.yhat<row.t and pos==1:\n",
        "      money=money+row.t\n",
        "      money_array.append(money)\n",
        "      pos=pos-1\n",
        "    \n",
        "    else:\n",
        "      if len(money_array)==0:\n",
        "        money_array.append(0)\n",
        "      else:\n",
        "        money_array.append(money_array[-1])\n",
        "\n",
        "    pos_array.append(pos)\n",
        "\n",
        "    \n",
        "  if pos==1:\n",
        "    money=money+returns.iloc[-1][\"t\"] \n",
        "    pos=pos-1\n",
        "\n",
        "  returns[\"profit\"]=np.array(money_array)\n",
        "  returns[\"position\"]=np.array(pos_array)\n",
        "\n",
        "  returns=pd.concat([returns.t,returns.yhat,returns.ytrue,returns.profit,returns.position],axis=1)\n",
        "\n",
        "  time=np.arange(0,len(money_array),1)\n",
        "  plt.plot(time,money_array)\n",
        "\n",
        "  \n",
        "  print(\"profit is\",money,\"position in portfolio is\",pos)\n",
        "  print(len(money_array),returns.shape)\n",
        "  return returns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE_9sNAO3X6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data preparation\n",
        "\n",
        "#df = pd.read_csv(path, parse_dates=['time'], index_col=\"time\")\n",
        "df = pd.read_csv(path, parse_dates=['DateTime'], index_col=\"DateTime\")\n",
        "\n",
        "df[\"target\"]=df.close.shift(-1)\n",
        "df=df.drop(df.tail(1).index) # drop last n rows\n",
        "df=df[[\"close\",\"target\"]]\n",
        "\n",
        "values=df.values\n",
        "values = values.astype('float32')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled=scaler.fit_transform(values)\n",
        "\n",
        "\n",
        "X,y=split_sequences(scaled,1)\n",
        "y=y.reshape(len(y),1)\n",
        "\n",
        "a=130000\n",
        "b=150000\n",
        "X_train=X[:a]\n",
        "y_train=y[:a]\n",
        "\n",
        "X_val=X[a:b]\n",
        "y_val=y[a:b]\n",
        "\n",
        "X_test=X[1:]\n",
        "y_test=y[1:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIBD3-Kj9dtn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "1e077612-1a21-4b27-837d-4158cbeca8ee"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# lloss: 2.9192e-05 - mean_absolute_error: 0.0034 sklearn mae： 3.8791945\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]), \n",
        "    keras.layers.Dense(units=32, activation='relu'),\n",
        "    keras.layers.Dense(units=1)])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,early_stopping_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "   1/4063 [..............................] - ETA: 0s - loss: 0.1402WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0422s). Check your callbacks.\n",
            "4063/4063 [==============================] - 5s 1ms/step - loss: 8.1015e-04 - val_loss: 4.2874e-06\n",
            "Epoch 2/20\n",
            "4063/4063 [==============================] - 5s 1ms/step - loss: 2.5481e-06 - val_loss: 4.2351e-06\n",
            "Epoch 3/20\n",
            "4063/4063 [==============================] - 4s 1ms/step - loss: 2.9508e-06 - val_loss: 4.2611e-06\n",
            "Epoch 4/20\n",
            "4063/4063 [==============================] - 5s 1ms/step - loss: 2.9673e-06 - val_loss: 4.2672e-06\n",
            "Epoch 5/20\n",
            "4063/4063 [==============================] - 4s 1ms/step - loss: 2.9025e-06 - val_loss: 6.3485e-06\n",
            "Epoch 6/20\n",
            "4063/4063 [==============================] - 4s 1ms/step - loss: 2.9214e-06 - val_loss: 4.5639e-06\n",
            "Epoch 7/20\n",
            "4063/4063 [==============================] - 4s 1ms/step - loss: 2.9325e-06 - val_loss: 4.4953e-06\n",
            "Epoch 8/20\n",
            "4063/4063 [==============================] - 5s 1ms/step - loss: 2.9442e-06 - val_loss: 4.2388e-06\n",
            "Epoch 9/20\n",
            "1619/4063 [==========>...................] - ETA: 2s - loss: 2.9966e-06"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-294a2f97c69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m history = model.fit(X_train, y_train, epochs=20, batch_size=32, \n\u001b[1;32m     32\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     callbacks=[checkpoint_cb,early_stopping_cb,tensorboard_cb], shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' - %.0fs'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_update\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woUx4matet0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "61b5d53a-8f11-4a0a-e617-478dd06c9a7b"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# lloss: 2.9192e-05 - mean_absolute_error: 0.0034 sklearn mae： 3.8791945\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.LSTM(256, return_sequences=True,\n",
        "                             kernel_initializer=\"lecun_normal\", input_shape=(X.shape[1],X.shape[2])),\n",
        "    keras.layers.PReLU(),\n",
        "\n",
        "    keras.layers.LSTM(64, return_sequences=True,\n",
        "                             kernel_initializer=\"lecun_normal\"),\n",
        "       # keras.layers.BatchNormalization(),\n",
        "    keras.layers.PReLU(),\n",
        "\n",
        "\n",
        "    \n",
        "    #keras.layers.Dropout(0.2),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.PReLU(),\n",
        "\n",
        "\n",
        "    keras.layers.LSTM(32, return_sequences=True,\n",
        "                             kernel_initializer=\"lecun_normal\"),\n",
        "       # keras.layers.BatchNormalization(),\n",
        "    keras.layers.PReLU(),\n",
        "\n",
        "\n",
        "    #keras.layers.Dropout(0.2),\n",
        "    keras.layers.LSTM(32, return_sequences=True,\n",
        "                             kernel_initializer=\"lecun_normal\"),\n",
        "    #keras.layers.Dropout(0.2),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(24),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.PReLU(),\n",
        "\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"lstm.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,early_stopping_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "   2/4063 [..............................] - ETA: 8:39 - loss: 0.3621WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.2406s). Check your callbacks.\n",
            "4063/4063 [==============================] - 53s 13ms/step - loss: 0.0020 - val_loss: 6.0276e-06\n",
            "Epoch 2/20\n",
            "4063/4063 [==============================] - 51s 13ms/step - loss: 7.6973e-06 - val_loss: 1.0105e-05\n",
            "Epoch 3/20\n",
            "4063/4063 [==============================] - 51s 12ms/step - loss: 6.9620e-06 - val_loss: 7.2376e-06\n",
            "Epoch 4/20\n",
            "4063/4063 [==============================] - 50s 12ms/step - loss: 7.0209e-06 - val_loss: 4.4548e-06\n",
            "Epoch 5/20\n",
            "4063/4063 [==============================] - 52s 13ms/step - loss: 6.2489e-06 - val_loss: 4.4157e-06\n",
            "Epoch 6/20\n",
            "4063/4063 [==============================] - 49s 12ms/step - loss: 5.7726e-06 - val_loss: 5.5944e-06\n",
            "Epoch 7/20\n",
            "4063/4063 [==============================] - 49s 12ms/step - loss: 5.8578e-06 - val_loss: 5.5578e-06\n",
            "Epoch 8/20\n",
            "4063/4063 [==============================] - 50s 12ms/step - loss: 5.8519e-06 - val_loss: 5.0941e-06\n",
            "Epoch 9/20\n",
            "4063/4063 [==============================] - 51s 13ms/step - loss: 6.1527e-06 - val_loss: 6.0758e-06\n",
            "Epoch 10/20\n",
            "4063/4063 [==============================] - 51s 13ms/step - loss: 5.2232e-06 - val_loss: 4.4358e-06\n",
            "Epoch 11/20\n",
            "4063/4063 [==============================] - 49s 12ms/step - loss: 5.3399e-06 - val_loss: 6.1380e-06\n",
            "Epoch 12/20\n",
            "4063/4063 [==============================] - 51s 13ms/step - loss: 5.2574e-06 - val_loss: 4.4322e-06\n",
            "Epoch 13/20\n",
            "4063/4063 [==============================] - 50s 12ms/step - loss: 5.4878e-06 - val_loss: 4.4818e-06\n",
            "Epoch 14/20\n",
            "4063/4063 [==============================] - 49s 12ms/step - loss: 4.8136e-06 - val_loss: 4.6117e-06\n",
            "Epoch 15/20\n",
            "4063/4063 [==============================] - 49s 12ms/step - loss: 4.9516e-06 - val_loss: 5.0373e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtpJPF4PdJiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(20, return_sequences=True,  input_shape=(X.shape[1],X.shape[2])),\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.GRU(20, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmLpTl48e6Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTyHx0kJe6Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isXfX_0RyNmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./my_logs --port=6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMtibk2VyN2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "494566c2-5da3-4669-fd7a-b835f4759b23"
      },
      "source": [
        "model=keras.models.load_model(\"lstm.h5\") \n",
        "\n",
        "\n",
        "ytrue=denorm(y_test,df.target)\n",
        "yhat=denorm(model.predict(X_test),df.target)\n",
        "\n",
        "model.evaluate(X_test,y_test)\n",
        "print(\"sklearn mae：\",sklearn.metrics.mean_absolute_error(ytrue,yhat))\n",
        "\n",
        "gene_hist(ytrue,yhat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5513/5513 [==============================] - 20s 4ms/step - loss: 3.1169e-06\n",
            "sklearn mae： 1.1316257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxZq-JTIyN9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b79a86a4-594a-4195-e12f-9f164fbfc82d"
      },
      "source": [
        "calculate_profit(ytrue,yhat).head(60)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "profit is 243.071533203125 position in portfolio is 0\n",
            "176415 (176415, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>yhat</th>\n",
              "      <th>ytrue</th>\n",
              "      <th>profit</th>\n",
              "      <th>position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3279.919922</td>\n",
              "      <td>3280.683105</td>\n",
              "      <td>3278.530273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3278.530273</td>\n",
              "      <td>3279.304199</td>\n",
              "      <td>3280.280029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3280.280029</td>\n",
              "      <td>3281.040527</td>\n",
              "      <td>3280.520020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3280.520020</td>\n",
              "      <td>3281.278320</td>\n",
              "      <td>3281.060059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3281.060059</td>\n",
              "      <td>3281.813965</td>\n",
              "      <td>3280.729980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3280.729980</td>\n",
              "      <td>3281.486816</td>\n",
              "      <td>3279.310059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3279.310059</td>\n",
              "      <td>3280.078125</td>\n",
              "      <td>3277.830078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3277.830078</td>\n",
              "      <td>3278.609375</td>\n",
              "      <td>3277.429932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3277.429932</td>\n",
              "      <td>3278.212158</td>\n",
              "      <td>3275.389893</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3275.389893</td>\n",
              "      <td>3276.186035</td>\n",
              "      <td>3274.720215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3274.720215</td>\n",
              "      <td>3275.520508</td>\n",
              "      <td>3274.629883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3274.629883</td>\n",
              "      <td>3275.430664</td>\n",
              "      <td>3274.939941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3274.939941</td>\n",
              "      <td>3275.739014</td>\n",
              "      <td>3275.919922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3275.919922</td>\n",
              "      <td>3276.712402</td>\n",
              "      <td>3276.199707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3276.199707</td>\n",
              "      <td>3276.990479</td>\n",
              "      <td>3276.139893</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3276.139893</td>\n",
              "      <td>3276.930908</td>\n",
              "      <td>3275.689941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3275.689941</td>\n",
              "      <td>3276.483887</td>\n",
              "      <td>3274.770020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3274.770020</td>\n",
              "      <td>3275.570068</td>\n",
              "      <td>3274.020020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3274.020020</td>\n",
              "      <td>3274.824463</td>\n",
              "      <td>3274.520020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3274.520020</td>\n",
              "      <td>3275.321777</td>\n",
              "      <td>3274.379883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3274.379883</td>\n",
              "      <td>3275.182373</td>\n",
              "      <td>3275.090088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3275.090088</td>\n",
              "      <td>3275.888184</td>\n",
              "      <td>3275.479980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3275.479980</td>\n",
              "      <td>3276.275635</td>\n",
              "      <td>3275.889893</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3275.889893</td>\n",
              "      <td>3276.682617</td>\n",
              "      <td>3275.790039</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3275.790039</td>\n",
              "      <td>3276.583496</td>\n",
              "      <td>3276.830078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3276.830078</td>\n",
              "      <td>3277.616455</td>\n",
              "      <td>3277.330078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3277.330078</td>\n",
              "      <td>3278.112793</td>\n",
              "      <td>3277.739990</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3277.739990</td>\n",
              "      <td>3278.520020</td>\n",
              "      <td>3278.199951</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3278.199951</td>\n",
              "      <td>3278.976562</td>\n",
              "      <td>3278.149902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3278.149902</td>\n",
              "      <td>3278.926758</td>\n",
              "      <td>3278.199951</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3278.199951</td>\n",
              "      <td>3278.976562</td>\n",
              "      <td>3277.470215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3277.470215</td>\n",
              "      <td>3278.251953</td>\n",
              "      <td>3277.189941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>3277.189941</td>\n",
              "      <td>3277.973633</td>\n",
              "      <td>3277.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3277.000000</td>\n",
              "      <td>3277.785156</td>\n",
              "      <td>3277.560059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>3277.560059</td>\n",
              "      <td>3278.341309</td>\n",
              "      <td>3277.350098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3277.350098</td>\n",
              "      <td>3278.132812</td>\n",
              "      <td>3276.919922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3276.919922</td>\n",
              "      <td>3277.705566</td>\n",
              "      <td>3276.549805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3276.549805</td>\n",
              "      <td>3277.338135</td>\n",
              "      <td>3276.340088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3276.340088</td>\n",
              "      <td>3277.129883</td>\n",
              "      <td>3276.549805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3276.549805</td>\n",
              "      <td>3277.338135</td>\n",
              "      <td>3276.649902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>3276.649902</td>\n",
              "      <td>3277.437500</td>\n",
              "      <td>3276.080078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3276.080078</td>\n",
              "      <td>3276.871582</td>\n",
              "      <td>3275.919922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3275.919922</td>\n",
              "      <td>3276.712402</td>\n",
              "      <td>3274.800049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3274.800049</td>\n",
              "      <td>3275.599854</td>\n",
              "      <td>3274.180176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>3274.180176</td>\n",
              "      <td>3274.983887</td>\n",
              "      <td>3274.149902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3274.149902</td>\n",
              "      <td>3274.953613</td>\n",
              "      <td>3273.950195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>3273.950195</td>\n",
              "      <td>3274.755371</td>\n",
              "      <td>3273.840088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>3273.840088</td>\n",
              "      <td>3274.645996</td>\n",
              "      <td>3274.320068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3274.320068</td>\n",
              "      <td>3275.123047</td>\n",
              "      <td>3274.810059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>3274.810059</td>\n",
              "      <td>3275.609863</td>\n",
              "      <td>3275.129883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>3275.129883</td>\n",
              "      <td>3275.927734</td>\n",
              "      <td>3275.419922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>3275.419922</td>\n",
              "      <td>3276.215820</td>\n",
              "      <td>3275.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>3275.000000</td>\n",
              "      <td>3275.798584</td>\n",
              "      <td>3274.449951</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>3274.449951</td>\n",
              "      <td>3275.251953</td>\n",
              "      <td>3274.290039</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>3274.290039</td>\n",
              "      <td>3275.093018</td>\n",
              "      <td>3274.280029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>3274.280029</td>\n",
              "      <td>3275.083008</td>\n",
              "      <td>3274.020020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>3274.020020</td>\n",
              "      <td>3274.824463</td>\n",
              "      <td>3273.179932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>3273.179932</td>\n",
              "      <td>3273.989746</td>\n",
              "      <td>3273.459961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>3273.459961</td>\n",
              "      <td>3274.268066</td>\n",
              "      <td>3273.550049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>3273.550049</td>\n",
              "      <td>3274.357422</td>\n",
              "      <td>3273.280273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              t         yhat        ytrue  profit  position\n",
              "1   3279.919922  3280.683105  3278.530273     0.0         1\n",
              "2   3278.530273  3279.304199  3280.280029     0.0         1\n",
              "3   3280.280029  3281.040527  3280.520020     0.0         1\n",
              "4   3280.520020  3281.278320  3281.060059     0.0         1\n",
              "5   3281.060059  3281.813965  3280.729980     0.0         1\n",
              "6   3280.729980  3281.486816  3279.310059     0.0         1\n",
              "7   3279.310059  3280.078125  3277.830078     0.0         1\n",
              "8   3277.830078  3278.609375  3277.429932     0.0         1\n",
              "9   3277.429932  3278.212158  3275.389893     0.0         1\n",
              "10  3275.389893  3276.186035  3274.720215     0.0         1\n",
              "11  3274.720215  3275.520508  3274.629883     0.0         1\n",
              "12  3274.629883  3275.430664  3274.939941     0.0         1\n",
              "13  3274.939941  3275.739014  3275.919922     0.0         1\n",
              "14  3275.919922  3276.712402  3276.199707     0.0         1\n",
              "15  3276.199707  3276.990479  3276.139893     0.0         1\n",
              "16  3276.139893  3276.930908  3275.689941     0.0         1\n",
              "17  3275.689941  3276.483887  3274.770020     0.0         1\n",
              "18  3274.770020  3275.570068  3274.020020     0.0         1\n",
              "19  3274.020020  3274.824463  3274.520020     0.0         1\n",
              "20  3274.520020  3275.321777  3274.379883     0.0         1\n",
              "21  3274.379883  3275.182373  3275.090088     0.0         1\n",
              "22  3275.090088  3275.888184  3275.479980     0.0         1\n",
              "23  3275.479980  3276.275635  3275.889893     0.0         1\n",
              "24  3275.889893  3276.682617  3275.790039     0.0         1\n",
              "25  3275.790039  3276.583496  3276.830078     0.0         1\n",
              "26  3276.830078  3277.616455  3277.330078     0.0         1\n",
              "27  3277.330078  3278.112793  3277.739990     0.0         1\n",
              "28  3277.739990  3278.520020  3278.199951     0.0         1\n",
              "29  3278.199951  3278.976562  3278.149902     0.0         1\n",
              "30  3278.149902  3278.926758  3278.199951     0.0         1\n",
              "31  3278.199951  3278.976562  3277.470215     0.0         1\n",
              "32  3277.470215  3278.251953  3277.189941     0.0         1\n",
              "33  3277.189941  3277.973633  3277.000000     0.0         1\n",
              "34  3277.000000  3277.785156  3277.560059     0.0         1\n",
              "35  3277.560059  3278.341309  3277.350098     0.0         1\n",
              "36  3277.350098  3278.132812  3276.919922     0.0         1\n",
              "37  3276.919922  3277.705566  3276.549805     0.0         1\n",
              "38  3276.549805  3277.338135  3276.340088     0.0         1\n",
              "39  3276.340088  3277.129883  3276.549805     0.0         1\n",
              "40  3276.549805  3277.338135  3276.649902     0.0         1\n",
              "41  3276.649902  3277.437500  3276.080078     0.0         1\n",
              "42  3276.080078  3276.871582  3275.919922     0.0         1\n",
              "43  3275.919922  3276.712402  3274.800049     0.0         1\n",
              "44  3274.800049  3275.599854  3274.180176     0.0         1\n",
              "45  3274.180176  3274.983887  3274.149902     0.0         1\n",
              "46  3274.149902  3274.953613  3273.950195     0.0         1\n",
              "47  3273.950195  3274.755371  3273.840088     0.0         1\n",
              "48  3273.840088  3274.645996  3274.320068     0.0         1\n",
              "49  3274.320068  3275.123047  3274.810059     0.0         1\n",
              "50  3274.810059  3275.609863  3275.129883     0.0         1\n",
              "51  3275.129883  3275.927734  3275.419922     0.0         1\n",
              "52  3275.419922  3276.215820  3275.000000     0.0         1\n",
              "53  3275.000000  3275.798584  3274.449951     0.0         1\n",
              "54  3274.449951  3275.251953  3274.290039     0.0         1\n",
              "55  3274.290039  3275.093018  3274.280029     0.0         1\n",
              "56  3274.280029  3275.083008  3274.020020     0.0         1\n",
              "57  3274.020020  3274.824463  3273.179932     0.0         1\n",
              "58  3273.179932  3273.989746  3273.459961     0.0         1\n",
              "59  3273.459961  3274.268066  3273.550049     0.0         1\n",
              "60  3273.550049  3274.357422  3273.280273     0.0         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jibxrp8YyOIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7SeJglJ5UZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmQbEnmh5Ugs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evPdg4tc5VMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXGkmASn5VTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z-qH6jE5VP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDhkkJBr5UfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO7bp20Z5UdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66hiLrOo5UXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XDK_Hti5UVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9FsiLRMyOGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqKEhCX3yOEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9KEBWqnyOCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naNUfxsDyN8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ximmOayN6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbFqMZGbyN0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvvxvU2UyNsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-G-K70Kycfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqAmcsLRycpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPTncapbyc56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48cma3oYyc9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZVIAS-Oyc30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvFCX89wyc0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JIAzKdcycyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glBJiXW2ycwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDyTXm-fyctf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv3T7bzMycnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az8lYHyCycla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDBdJIke5Nv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrkwcU_M5Nt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFoG-jBHH2mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxx1IR6SH2kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q-aGr7EH2hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]))\n",
        "for _ in range(7):\n",
        "  model.add( keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(units=15,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(units=5,activation=\"relu\"))\n",
        "\n",
        "model.add(keras.layers.Dense(units=1))\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb,early_stopping_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C86LTriqH2dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "9a672bf5-c3b4-4d46-b149-915c78ade569"
      },
      "source": [
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(30, return_sequences=True, input_shape=[X.shape[1],X.shape[2]]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/782 [..............................] - ETA: 1:04 - loss: 0.6003 - mean_absolute_error: 0.6061WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.1562s). Check your callbacks.\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0399 - mean_absolute_error: 0.1293 - val_loss: 4.9143e-04 - val_mean_absolute_error: 0.0153\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0044 - mean_absolute_error: 0.0497 - val_loss: 3.6216e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0024 - mean_absolute_error: 0.0364 - val_loss: 2.8047e-04 - val_mean_absolute_error: 0.0116\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0017 - mean_absolute_error: 0.0309 - val_loss: 2.1389e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0015 - mean_absolute_error: 0.0284 - val_loss: 2.3661e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0014 - mean_absolute_error: 0.0271 - val_loss: 2.1648e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0013 - mean_absolute_error: 0.0263 - val_loss: 1.9725e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0012 - mean_absolute_error: 0.0259 - val_loss: 1.9065e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0012 - mean_absolute_error: 0.0253 - val_loss: 1.6488e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0012 - mean_absolute_error: 0.0251 - val_loss: 1.5588e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0012 - mean_absolute_error: 0.0249 - val_loss: 1.8166e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0011 - mean_absolute_error: 0.0245 - val_loss: 1.6061e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0011 - mean_absolute_error: 0.0243 - val_loss: 1.9051e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0011 - mean_absolute_error: 0.0240 - val_loss: 2.0135e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0011 - mean_absolute_error: 0.0240 - val_loss: 1.5946e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 16/100\n",
            " 12/782 [..............................] - ETA: 3s - loss: 0.0011 - mean_absolute_error: 0.0248"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5e80f90c1e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n\u001b[1;32m     41\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9xDOVXHJRYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "adcdb56e-08ea-416f-ee93-d6151f6847cf"
      },
      "source": [
        "model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5183906 ],\n",
              "       [0.5224686 ],\n",
              "       [0.5230979 ],\n",
              "       ...,\n",
              "       [0.79983646],\n",
              "       [0.79839706],\n",
              "       [0.7978742 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCdJz7r-5NsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37c25e3b-adb8-4161-d952-cea3ea446a98"
      },
      "source": [
        "model2=keras.models.load_model(\"baseline.h5\")\n",
        "model2.evaluate(X_test,y_test)\n",
        "model.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 0s 751us/step - loss: 2.6260e-05 - mean_absolute_error: 0.0031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7d578275f8>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1VwbiED5Npw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9fd6593-39d1-4b1f-ab49-412972c4a4f3"
      },
      "source": [
        "model.evaluate(X_test,y_test)\n",
        "model.summary\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 0s 783us/step - loss: 2.6700e-05 - mean_absolute_error: 0.0032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7d578275f8>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyVY8OGO5Nl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "ed73de9d-2820-4d7e-fd1b-fabd1afab58f"
      },
      "source": [
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "model = tf.keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]),  \n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "                 \n",
        "    keras.layers.Dense(units=1280, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "\n",
        "    keras.layers.Dense(units=640, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "\n",
        "    keras.layers.Dense(units=320, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/782 [..............................] - ETA: 23s - loss: 1.8559 - mean_absolute_error: 1.1639WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_end` time: 0.0468s). Check your callbacks.\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.0112 - mean_absolute_error: 0.0571 - val_loss: 0.0061 - val_mean_absolute_error: 0.0713\n",
            "Epoch 2/100\n",
            "493/782 [=================>............] - ETA: 3s - loss: 0.0034 - mean_absolute_error: 0.0435"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-1f5319841995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n\u001b[1;32m     45\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJt7s1MAyNp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da676408-071e-414d-dc46-a14f728e51d3"
      },
      "source": [
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]), \n",
        "    tf.keras.layers.Dense(units=528, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "\n",
        "    tf.keras.layers.Dense(units=328, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "  \n",
        "    tf.keras.layers.Dense(units=128, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dense(units=64, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dense(units=32, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"selu2.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=500, batch_size=256, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 2/98 [..............................] - ETA: 4s - loss: 1.9718 - mean_absolute_error: 1.2888WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.0824s). Check your callbacks.\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 0.0464 - mean_absolute_error: 0.0649 - val_loss: 2.5768e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 2/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.4388e-04 - mean_absolute_error: 0.0091 - val_loss: 1.4630e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 3/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.0194e-04 - mean_absolute_error: 0.0076 - val_loss: 1.0944e-04 - val_mean_absolute_error: 0.0068\n",
            "Epoch 4/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 7.3692e-05 - mean_absolute_error: 0.0064 - val_loss: 1.0478e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 5/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 7.6960e-05 - mean_absolute_error: 0.0067 - val_loss: 9.7154e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 6/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 7.7950e-05 - mean_absolute_error: 0.0067 - val_loss: 1.5202e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 7/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.1116e-05 - mean_absolute_error: 0.0059 - val_loss: 8.2192e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 8/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.5649e-05 - mean_absolute_error: 0.0062 - val_loss: 4.7546e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 9/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 8.6742e-05 - mean_absolute_error: 0.0072 - val_loss: 7.9771e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 10/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.2569e-05 - mean_absolute_error: 0.0054 - val_loss: 5.0376e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 11/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.1073e-04 - mean_absolute_error: 0.0081 - val_loss: 6.0936e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 12/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.2520e-05 - mean_absolute_error: 0.0055 - val_loss: 4.6945e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 13/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.2863e-04 - mean_absolute_error: 0.0086 - val_loss: 1.4559e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 14/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.3882e-05 - mean_absolute_error: 0.0055 - val_loss: 4.7032e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 15/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 8.3467e-05 - mean_absolute_error: 0.0070 - val_loss: 1.0179e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 16/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.5263e-05 - mean_absolute_error: 0.0063 - val_loss: 8.2337e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 17/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 8.4529e-05 - mean_absolute_error: 0.0072 - val_loss: 5.5652e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 18/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.0172e-05 - mean_absolute_error: 0.0053 - val_loss: 6.0248e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 19/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.9195e-05 - mean_absolute_error: 0.0062 - val_loss: 3.8478e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 20/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.7031e-05 - mean_absolute_error: 0.0058 - val_loss: 3.6913e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 21/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.1082e-05 - mean_absolute_error: 0.0059 - val_loss: 4.9907e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 22/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.0967e-05 - mean_absolute_error: 0.0053 - val_loss: 9.9010e-05 - val_mean_absolute_error: 0.0084\n",
            "Epoch 23/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.7611e-05 - mean_absolute_error: 0.0056 - val_loss: 1.3155e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 24/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 8.3418e-05 - mean_absolute_error: 0.0071 - val_loss: 5.2641e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 25/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.7949e-05 - mean_absolute_error: 0.0062 - val_loss: 3.2729e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 26/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.2765e-05 - mean_absolute_error: 0.0049 - val_loss: 4.5286e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 27/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 9.4044e-05 - mean_absolute_error: 0.0074 - val_loss: 4.2795e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 28/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.4586e-05 - mean_absolute_error: 0.0044 - val_loss: 4.0909e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 29/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.0843e-05 - mean_absolute_error: 0.0047 - val_loss: 3.1176e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 30/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.6802e-05 - mean_absolute_error: 0.0056 - val_loss: 3.1524e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 31/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.6327e-05 - mean_absolute_error: 0.0051 - val_loss: 4.6421e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 32/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.6691e-05 - mean_absolute_error: 0.0052 - val_loss: 3.6364e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 33/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 7.1308e-05 - mean_absolute_error: 0.0062 - val_loss: 3.4520e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 34/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.8279e-05 - mean_absolute_error: 0.0038 - val_loss: 2.7958e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 35/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.9352e-05 - mean_absolute_error: 0.0046 - val_loss: 3.1596e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 36/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.5784e-05 - mean_absolute_error: 0.0060 - val_loss: 3.8836e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 37/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.3247e-05 - mean_absolute_error: 0.0056 - val_loss: 4.5689e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 38/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.2166e-05 - mean_absolute_error: 0.0048 - val_loss: 4.8197e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 39/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.6812e-05 - mean_absolute_error: 0.0045 - val_loss: 4.9082e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 40/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1810e-05 - mean_absolute_error: 0.0048 - val_loss: 8.2125e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 41/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.5129e-05 - mean_absolute_error: 0.0056 - val_loss: 3.9032e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 42/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8412e-05 - mean_absolute_error: 0.0045 - val_loss: 4.2105e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 43/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 9.9067e-05 - mean_absolute_error: 0.0074 - val_loss: 7.6931e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 44/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1214e-05 - mean_absolute_error: 0.0041 - val_loss: 3.2328e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 45/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 4.2348e-05 - mean_absolute_error: 0.0048 - val_loss: 3.5260e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 46/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0385e-05 - mean_absolute_error: 0.0040 - val_loss: 4.9114e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 47/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.3477e-05 - mean_absolute_error: 0.0049 - val_loss: 3.0754e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 48/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9354e-05 - mean_absolute_error: 0.0040 - val_loss: 4.1187e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 49/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.7386e-05 - mean_absolute_error: 0.0051 - val_loss: 3.9978e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 50/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.5105e-05 - mean_absolute_error: 0.0057 - val_loss: 3.2823e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 51/500\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 3.5671e-05 - mean_absolute_error: 0.0043 - val_loss: 3.1753e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 52/500\n",
            "98/98 [==============================] - 3s 30ms/step - loss: 3.2075e-05 - mean_absolute_error: 0.0042 - val_loss: 3.4932e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 53/500\n",
            "98/98 [==============================] - 3s 30ms/step - loss: 2.7481e-05 - mean_absolute_error: 0.0038 - val_loss: 3.2378e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 54/500\n",
            "98/98 [==============================] - 3s 28ms/step - loss: 5.4922e-05 - mean_absolute_error: 0.0055 - val_loss: 5.3652e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 55/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2392e-05 - mean_absolute_error: 0.0042 - val_loss: 4.3532e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 56/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.9320e-05 - mean_absolute_error: 0.0046 - val_loss: 3.4876e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 57/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1813e-05 - mean_absolute_error: 0.0041 - val_loss: 3.7987e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 58/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.5463e-05 - mean_absolute_error: 0.0055 - val_loss: 3.1780e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 59/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.4583e-05 - mean_absolute_error: 0.0061 - val_loss: 3.6228e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 60/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9490e-05 - mean_absolute_error: 0.0039 - val_loss: 4.5268e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 61/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5370e-05 - mean_absolute_error: 0.0036 - val_loss: 5.4723e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 62/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9228e-05 - mean_absolute_error: 0.0039 - val_loss: 3.2892e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 63/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1742e-05 - mean_absolute_error: 0.0049 - val_loss: 3.2510e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 64/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3936e-05 - mean_absolute_error: 0.0043 - val_loss: 3.2664e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 65/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3638e-05 - mean_absolute_error: 0.0042 - val_loss: 4.6610e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 66/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.6449e-05 - mean_absolute_error: 0.0056 - val_loss: 3.1743e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 67/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.0154e-05 - mean_absolute_error: 0.0051 - val_loss: 2.9508e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 68/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.7561e-05 - mean_absolute_error: 0.0046 - val_loss: 7.2046e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 69/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8558e-05 - mean_absolute_error: 0.0039 - val_loss: 3.2671e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 70/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.4046e-05 - mean_absolute_error: 0.0051 - val_loss: 2.9017e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 71/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 4.1611e-05 - mean_absolute_error: 0.0048 - val_loss: 2.6784e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 72/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5667e-05 - mean_absolute_error: 0.0044 - val_loss: 3.0318e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 73/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9131e-05 - mean_absolute_error: 0.0039 - val_loss: 3.0974e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 74/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.6279e-05 - mean_absolute_error: 0.0044 - val_loss: 2.6539e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 75/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.5691e-05 - mean_absolute_error: 0.0051 - val_loss: 3.6041e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 76/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.0275e-05 - mean_absolute_error: 0.0046 - val_loss: 2.7864e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 77/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.6027e-05 - mean_absolute_error: 0.0045 - val_loss: 2.5676e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 78/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1465e-05 - mean_absolute_error: 0.0041 - val_loss: 2.7196e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 79/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.3345e-05 - mean_absolute_error: 0.0049 - val_loss: 2.8581e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 80/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 9.2047e-05 - mean_absolute_error: 0.0070 - val_loss: 8.5041e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 81/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.6821e-05 - mean_absolute_error: 0.0045 - val_loss: 3.6385e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 82/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6143e-05 - mean_absolute_error: 0.0037 - val_loss: 2.6518e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 83/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9902e-05 - mean_absolute_error: 0.0040 - val_loss: 5.7563e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 84/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.3088e-05 - mean_absolute_error: 0.0053 - val_loss: 2.5038e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 85/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6054e-05 - mean_absolute_error: 0.0037 - val_loss: 2.8553e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 86/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8926e-05 - mean_absolute_error: 0.0045 - val_loss: 2.6072e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 87/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.2045e-05 - mean_absolute_error: 0.0041 - val_loss: 2.4763e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 88/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2646e-05 - mean_absolute_error: 0.0042 - val_loss: 4.1591e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 89/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8244e-05 - mean_absolute_error: 0.0046 - val_loss: 7.1031e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 90/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.7135e-05 - mean_absolute_error: 0.0046 - val_loss: 9.5829e-05 - val_mean_absolute_error: 0.0087\n",
            "Epoch 91/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8403e-05 - mean_absolute_error: 0.0046 - val_loss: 3.2039e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 92/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1960e-05 - mean_absolute_error: 0.0042 - val_loss: 5.7606e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 93/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.0215e-05 - mean_absolute_error: 0.0047 - val_loss: 4.8354e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 94/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5751e-05 - mean_absolute_error: 0.0044 - val_loss: 4.4609e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 95/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 7.0701e-05 - mean_absolute_error: 0.0065 - val_loss: 3.0642e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 96/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0727e-05 - mean_absolute_error: 0.0040 - val_loss: 7.1937e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 97/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.3281e-05 - mean_absolute_error: 0.0050 - val_loss: 2.5751e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 98/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8156e-05 - mean_absolute_error: 0.0039 - val_loss: 2.6030e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 99/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.9191e-05 - mean_absolute_error: 0.0047 - val_loss: 2.6563e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 100/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2645e-05 - mean_absolute_error: 0.0042 - val_loss: 2.7606e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 101/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2853e-05 - mean_absolute_error: 0.0042 - val_loss: 3.3518e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 102/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.9422e-05 - mean_absolute_error: 0.0047 - val_loss: 1.0426e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 103/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 6.4234e-05 - mean_absolute_error: 0.0060 - val_loss: 4.9395e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 104/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6805e-05 - mean_absolute_error: 0.0037 - val_loss: 2.4808e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 105/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6479e-05 - mean_absolute_error: 0.0037 - val_loss: 2.5691e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 106/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 4.1365e-05 - mean_absolute_error: 0.0048 - val_loss: 2.3615e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 107/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8309e-05 - mean_absolute_error: 0.0046 - val_loss: 3.3206e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 108/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2013e-05 - mean_absolute_error: 0.0042 - val_loss: 3.6243e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 109/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6448e-05 - mean_absolute_error: 0.0037 - val_loss: 2.5844e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 110/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1111e-05 - mean_absolute_error: 0.0042 - val_loss: 8.6101e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 111/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.8496e-05 - mean_absolute_error: 0.0052 - val_loss: 2.4986e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 112/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0619e-05 - mean_absolute_error: 0.0041 - val_loss: 2.7405e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 113/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5767e-05 - mean_absolute_error: 0.0044 - val_loss: 3.0021e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 114/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.7912e-05 - mean_absolute_error: 0.0038 - val_loss: 2.4524e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 115/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8308e-05 - mean_absolute_error: 0.0039 - val_loss: 2.5814e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 116/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3683e-05 - mean_absolute_error: 0.0042 - val_loss: 7.1545e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 117/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.2443e-05 - mean_absolute_error: 0.0054 - val_loss: 2.5431e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 118/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.2863e-05 - mean_absolute_error: 0.0042 - val_loss: 2.3430e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 119/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.2390e-05 - mean_absolute_error: 0.0042 - val_loss: 6.3603e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 120/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3988e-05 - mean_absolute_error: 0.0043 - val_loss: 2.8712e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 121/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 0.0142 - mean_absolute_error: 0.0475 - val_loss: 0.0051 - val_mean_absolute_error: 0.0704\n",
            "Epoch 122/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.5623e-04 - mean_absolute_error: 0.0114 - val_loss: 8.7655e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 123/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 4.0454e-05 - mean_absolute_error: 0.0045 - val_loss: 6.2369e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 124/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2093e-05 - mean_absolute_error: 0.0040 - val_loss: 5.1282e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 125/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.7136e-05 - mean_absolute_error: 0.0036 - val_loss: 4.3949e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 126/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4493e-05 - mean_absolute_error: 0.0034 - val_loss: 3.8525e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 127/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.7810e-05 - mean_absolute_error: 0.0037 - val_loss: 3.8417e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 128/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4527e-05 - mean_absolute_error: 0.0034 - val_loss: 3.7536e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 129/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3459e-05 - mean_absolute_error: 0.0033 - val_loss: 3.7194e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 130/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5576e-05 - mean_absolute_error: 0.0036 - val_loss: 3.3583e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 131/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2297e-05 - mean_absolute_error: 0.0032 - val_loss: 3.1832e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 132/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2225e-05 - mean_absolute_error: 0.0032 - val_loss: 3.5060e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 133/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4766e-05 - mean_absolute_error: 0.0035 - val_loss: 3.0908e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 134/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3489e-05 - mean_absolute_error: 0.0034 - val_loss: 3.6793e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 135/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5476e-05 - mean_absolute_error: 0.0036 - val_loss: 5.2043e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 136/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4155e-05 - mean_absolute_error: 0.0034 - val_loss: 3.5113e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 137/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8679e-05 - mean_absolute_error: 0.0039 - val_loss: 2.9990e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 138/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2622e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9365e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 139/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4041e-05 - mean_absolute_error: 0.0035 - val_loss: 3.8240e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 140/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0030e-05 - mean_absolute_error: 0.0040 - val_loss: 2.8466e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 141/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5765e-05 - mean_absolute_error: 0.0036 - val_loss: 3.1657e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 142/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.4844e-05 - mean_absolute_error: 0.0044 - val_loss: 6.4180e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 143/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0917e-05 - mean_absolute_error: 0.0040 - val_loss: 3.3736e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 144/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5014e-05 - mean_absolute_error: 0.0044 - val_loss: 4.0830e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 145/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0855e-05 - mean_absolute_error: 0.0040 - val_loss: 2.8755e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 146/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.7273e-05 - mean_absolute_error: 0.0045 - val_loss: 8.1317e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 147/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3262e-05 - mean_absolute_error: 0.0042 - val_loss: 4.2302e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 148/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2348e-05 - mean_absolute_error: 0.0041 - val_loss: 2.6852e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 149/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9699e-05 - mean_absolute_error: 0.0038 - val_loss: 3.3978e-04 - val_mean_absolute_error: 0.0175\n",
            "Epoch 150/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.6902e-05 - mean_absolute_error: 0.0054 - val_loss: 2.6005e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 151/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4958e-05 - mean_absolute_error: 0.0035 - val_loss: 2.6381e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 152/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6446e-05 - mean_absolute_error: 0.0037 - val_loss: 5.0126e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 153/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.7205e-05 - mean_absolute_error: 0.0044 - val_loss: 2.6283e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 154/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.3130e-05 - mean_absolute_error: 0.0049 - val_loss: 4.4275e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 155/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.2669e-05 - mean_absolute_error: 0.0048 - val_loss: 3.6038e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 156/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.6374e-05 - mean_absolute_error: 0.0044 - val_loss: 2.7668e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 157/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.1382e-05 - mean_absolute_error: 0.0041 - val_loss: 3.7177e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 158/500\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 2.6458e-05 - mean_absolute_error: 0.0037 - val_loss: 2.5507e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 159/500\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 5.0420e-05 - mean_absolute_error: 0.0054 - val_loss: 3.6727e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 160/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.4421e-05 - mean_absolute_error: 0.0043 - val_loss: 6.0003e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 161/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.2218e-05 - mean_absolute_error: 0.0048 - val_loss: 5.4848e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 162/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8029e-05 - mean_absolute_error: 0.0038 - val_loss: 6.6607e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 163/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1187e-05 - mean_absolute_error: 0.0048 - val_loss: 2.7797e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 164/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1702e-05 - mean_absolute_error: 0.0048 - val_loss: 3.1226e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 165/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6937e-05 - mean_absolute_error: 0.0037 - val_loss: 2.6692e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 166/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5700e-05 - mean_absolute_error: 0.0044 - val_loss: 7.6237e-05 - val_mean_absolute_error: 0.0075\n",
            "Epoch 167/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.0231e-05 - mean_absolute_error: 0.0047 - val_loss: 5.0452e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 168/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0111e-05 - mean_absolute_error: 0.0040 - val_loss: 2.9299e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 169/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.4732e-05 - mean_absolute_error: 0.0055 - val_loss: 4.1698e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 170/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0029e-05 - mean_absolute_error: 0.0040 - val_loss: 2.5782e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 171/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1926e-05 - mean_absolute_error: 0.0047 - val_loss: 3.4270e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 172/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.6220e-05 - mean_absolute_error: 0.0043 - val_loss: 2.7850e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 173/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5322e-05 - mean_absolute_error: 0.0036 - val_loss: 2.6533e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 174/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3345e-05 - mean_absolute_error: 0.0042 - val_loss: 3.0079e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 175/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0194e-05 - mean_absolute_error: 0.0040 - val_loss: 3.9255e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 176/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.6296e-05 - mean_absolute_error: 0.0044 - val_loss: 4.3245e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 177/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.8027e-05 - mean_absolute_error: 0.0050 - val_loss: 6.3070e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 178/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.4809e-05 - mean_absolute_error: 0.0051 - val_loss: 3.2424e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 179/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.8431e-05 - mean_absolute_error: 0.0039 - val_loss: 2.3242e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 180/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5763e-05 - mean_absolute_error: 0.0044 - val_loss: 6.0027e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 181/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2666e-05 - mean_absolute_error: 0.0042 - val_loss: 2.3529e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 182/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8578e-05 - mean_absolute_error: 0.0046 - val_loss: 4.1616e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 183/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8290e-05 - mean_absolute_error: 0.0039 - val_loss: 2.4906e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 184/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1217e-05 - mean_absolute_error: 0.0041 - val_loss: 4.4100e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 185/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 7.3611e-05 - mean_absolute_error: 0.0064 - val_loss: 2.3758e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 186/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2689e-05 - mean_absolute_error: 0.0033 - val_loss: 3.8877e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 187/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6907e-05 - mean_absolute_error: 0.0038 - val_loss: 2.7819e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 188/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5093e-05 - mean_absolute_error: 0.0036 - val_loss: 2.7693e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 189/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.8406e-05 - mean_absolute_error: 0.0058 - val_loss: 4.7545e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 190/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6236e-05 - mean_absolute_error: 0.0037 - val_loss: 6.1408e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 191/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5784e-05 - mean_absolute_error: 0.0037 - val_loss: 3.4482e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 192/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.3773e-05 - mean_absolute_error: 0.0050 - val_loss: 2.2837e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 193/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3071e-05 - mean_absolute_error: 0.0043 - val_loss: 2.2936e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 194/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6616e-05 - mean_absolute_error: 0.0037 - val_loss: 4.2523e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 195/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2743e-05 - mean_absolute_error: 0.0042 - val_loss: 2.9920e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 196/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8794e-05 - mean_absolute_error: 0.0039 - val_loss: 2.4786e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 197/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5489e-05 - mean_absolute_error: 0.0036 - val_loss: 2.8428e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 198/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.4024e-05 - mean_absolute_error: 0.0050 - val_loss: 2.7591e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 199/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.5216e-05 - mean_absolute_error: 0.0044 - val_loss: 5.4294e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 200/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1271e-05 - mean_absolute_error: 0.0041 - val_loss: 3.0458e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 201/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9198e-05 - mean_absolute_error: 0.0039 - val_loss: 3.3644e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 202/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.1038e-05 - mean_absolute_error: 0.0049 - val_loss: 1.9581e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 203/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 3.4689e-05 - mean_absolute_error: 0.0042 - val_loss: 2.2516e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 204/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.1005e-05 - mean_absolute_error: 0.0032 - val_loss: 2.2511e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 205/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1771e-05 - mean_absolute_error: 0.0048 - val_loss: 4.3725e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 206/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1784e-05 - mean_absolute_error: 0.0041 - val_loss: 2.7367e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 207/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3925e-05 - mean_absolute_error: 0.0043 - val_loss: 2.2020e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 208/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1992e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9198e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 209/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3566e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4355e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 210/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5920e-05 - mean_absolute_error: 0.0036 - val_loss: 2.5945e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 211/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.4337e-05 - mean_absolute_error: 0.0042 - val_loss: 4.2564e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 212/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 5.8763e-05 - mean_absolute_error: 0.0057 - val_loss: 5.9406e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 213/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6508e-05 - mean_absolute_error: 0.0037 - val_loss: 2.2204e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 214/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0641e-05 - mean_absolute_error: 0.0040 - val_loss: 2.3303e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 215/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5581e-05 - mean_absolute_error: 0.0037 - val_loss: 2.2317e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 216/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4201e-05 - mean_absolute_error: 0.0035 - val_loss: 7.5540e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 217/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6328e-05 - mean_absolute_error: 0.0036 - val_loss: 3.1664e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 218/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9530e-05 - mean_absolute_error: 0.0040 - val_loss: 3.9140e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 219/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0542e-05 - mean_absolute_error: 0.0040 - val_loss: 3.2157e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 220/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8110e-05 - mean_absolute_error: 0.0038 - val_loss: 6.3600e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 221/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9299e-05 - mean_absolute_error: 0.0039 - val_loss: 2.7151e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 222/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9325e-05 - mean_absolute_error: 0.0040 - val_loss: 2.6802e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 223/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.4360e-05 - mean_absolute_error: 0.0042 - val_loss: 7.2297e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 224/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.7733e-05 - mean_absolute_error: 0.0038 - val_loss: 4.0410e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 225/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3293e-05 - mean_absolute_error: 0.0034 - val_loss: 3.1281e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 226/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0396e-05 - mean_absolute_error: 0.0040 - val_loss: 2.6877e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 227/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3824e-05 - mean_absolute_error: 0.0043 - val_loss: 2.5421e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 228/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0195e-05 - mean_absolute_error: 0.0040 - val_loss: 1.0266e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 229/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9650e-05 - mean_absolute_error: 0.0039 - val_loss: 4.5009e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 230/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2673e-05 - mean_absolute_error: 0.0042 - val_loss: 2.8285e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 231/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3948e-05 - mean_absolute_error: 0.0035 - val_loss: 2.9346e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 232/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0396e-05 - mean_absolute_error: 0.0031 - val_loss: 3.5910e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 233/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8561e-05 - mean_absolute_error: 0.0039 - val_loss: 2.3355e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 234/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1471e-05 - mean_absolute_error: 0.0041 - val_loss: 2.9561e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 235/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8510e-05 - mean_absolute_error: 0.0039 - val_loss: 2.5425e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 236/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2591e-05 - mean_absolute_error: 0.0041 - val_loss: 3.9892e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 237/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1916e-05 - mean_absolute_error: 0.0048 - val_loss: 2.6761e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 238/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3560e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4026e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 239/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1037e-05 - mean_absolute_error: 0.0042 - val_loss: 2.3055e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 240/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0875e-05 - mean_absolute_error: 0.0032 - val_loss: 3.1466e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 241/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6865e-05 - mean_absolute_error: 0.0038 - val_loss: 3.1486e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 242/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0423e-05 - mean_absolute_error: 0.0041 - val_loss: 2.6701e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 243/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.7327e-05 - mean_absolute_error: 0.0038 - val_loss: 4.4973e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 244/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3504e-05 - mean_absolute_error: 0.0042 - val_loss: 3.3486e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 245/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9693e-05 - mean_absolute_error: 0.0031 - val_loss: 2.5016e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 246/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6030e-05 - mean_absolute_error: 0.0036 - val_loss: 3.6991e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 247/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6235e-05 - mean_absolute_error: 0.0037 - val_loss: 5.6826e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 248/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2899e-05 - mean_absolute_error: 0.0034 - val_loss: 3.9823e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 249/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2362e-05 - mean_absolute_error: 0.0033 - val_loss: 3.6563e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 250/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.9684e-05 - mean_absolute_error: 0.0047 - val_loss: 2.6246e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 251/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6964e-05 - mean_absolute_error: 0.0037 - val_loss: 2.7397e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 252/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9928e-05 - mean_absolute_error: 0.0040 - val_loss: 2.8566e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 253/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4544e-05 - mean_absolute_error: 0.0035 - val_loss: 4.5008e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 254/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.8280e-05 - mean_absolute_error: 0.0044 - val_loss: 6.4056e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 255/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.7811e-05 - mean_absolute_error: 0.0053 - val_loss: 2.8648e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 256/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3165e-05 - mean_absolute_error: 0.0034 - val_loss: 4.0868e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 257/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3910e-05 - mean_absolute_error: 0.0035 - val_loss: 4.4262e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 258/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1035e-05 - mean_absolute_error: 0.0032 - val_loss: 2.4551e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 259/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3383e-05 - mean_absolute_error: 0.0034 - val_loss: 2.5903e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 260/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3888e-05 - mean_absolute_error: 0.0034 - val_loss: 2.6963e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 261/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6891e-05 - mean_absolute_error: 0.0037 - val_loss: 4.2991e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 262/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2570e-05 - mean_absolute_error: 0.0034 - val_loss: 2.9075e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 263/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2739e-05 - mean_absolute_error: 0.0034 - val_loss: 2.6973e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 264/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4883e-05 - mean_absolute_error: 0.0036 - val_loss: 3.2676e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 265/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1675e-05 - mean_absolute_error: 0.0041 - val_loss: 2.8192e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 266/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1530e-05 - mean_absolute_error: 0.0042 - val_loss: 4.0351e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 267/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6289e-05 - mean_absolute_error: 0.0037 - val_loss: 2.9425e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 268/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0063e-05 - mean_absolute_error: 0.0031 - val_loss: 2.7739e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 269/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0057e-05 - mean_absolute_error: 0.0031 - val_loss: 5.0187e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 270/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3145e-05 - mean_absolute_error: 0.0034 - val_loss: 3.0526e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 271/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4477e-05 - mean_absolute_error: 0.0035 - val_loss: 5.2138e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 272/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.7759e-05 - mean_absolute_error: 0.0038 - val_loss: 2.7338e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 273/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1477e-05 - mean_absolute_error: 0.0033 - val_loss: 3.2115e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 274/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6314e-05 - mean_absolute_error: 0.0037 - val_loss: 4.4634e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 275/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1331e-05 - mean_absolute_error: 0.0032 - val_loss: 2.4766e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 276/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2612e-05 - mean_absolute_error: 0.0042 - val_loss: 3.2445e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 277/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1791e-05 - mean_absolute_error: 0.0033 - val_loss: 4.1765e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 278/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3772e-05 - mean_absolute_error: 0.0035 - val_loss: 2.4348e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 279/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6139e-05 - mean_absolute_error: 0.0036 - val_loss: 2.7046e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 280/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5018e-05 - mean_absolute_error: 0.0036 - val_loss: 3.5879e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 281/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0134e-05 - mean_absolute_error: 0.0040 - val_loss: 5.6903e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 282/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6883e-05 - mean_absolute_error: 0.0037 - val_loss: 7.5686e-05 - val_mean_absolute_error: 0.0074\n",
            "Epoch 283/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4080e-05 - mean_absolute_error: 0.0033 - val_loss: 2.4450e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 284/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.1468e-05 - mean_absolute_error: 0.0048 - val_loss: 4.0316e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 285/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3021e-05 - mean_absolute_error: 0.0034 - val_loss: 3.3555e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 286/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9897e-05 - mean_absolute_error: 0.0031 - val_loss: 2.6538e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 287/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1350e-05 - mean_absolute_error: 0.0032 - val_loss: 2.4440e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 288/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0749e-05 - mean_absolute_error: 0.0032 - val_loss: 3.1392e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 289/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3366e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4821e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 290/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1557e-05 - mean_absolute_error: 0.0033 - val_loss: 2.5190e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 291/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.4576e-05 - mean_absolute_error: 0.0050 - val_loss: 2.6914e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 292/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2125e-05 - mean_absolute_error: 0.0033 - val_loss: 2.7669e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 293/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3881e-05 - mean_absolute_error: 0.0034 - val_loss: 3.3917e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 294/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3340e-05 - mean_absolute_error: 0.0041 - val_loss: 7.0110e-05 - val_mean_absolute_error: 0.0069\n",
            "Epoch 295/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2177e-05 - mean_absolute_error: 0.0032 - val_loss: 3.0821e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 296/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0938e-05 - mean_absolute_error: 0.0032 - val_loss: 3.2327e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 297/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9520e-05 - mean_absolute_error: 0.0030 - val_loss: 3.3530e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 298/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6525e-05 - mean_absolute_error: 0.0037 - val_loss: 2.4610e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 299/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2845e-05 - mean_absolute_error: 0.0033 - val_loss: 3.4083e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 300/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3941e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8397e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 301/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.9768e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0238e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 302/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.0813e-04 - mean_absolute_error: 0.0081 - val_loss: 2.7594e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 303/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.1925e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7748e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 304/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.7853e-05 - mean_absolute_error: 0.0028 - val_loss: 2.8500e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 305/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.9158e-05 - mean_absolute_error: 0.0030 - val_loss: 2.7075e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 306/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.7077e-05 - mean_absolute_error: 0.0027 - val_loss: 2.5224e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 307/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.8296e-05 - mean_absolute_error: 0.0029 - val_loss: 2.7050e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 308/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.9129e-05 - mean_absolute_error: 0.0030 - val_loss: 2.7960e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 309/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.7945e-05 - mean_absolute_error: 0.0028 - val_loss: 2.7839e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 310/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.2687e-05 - mean_absolute_error: 0.0034 - val_loss: 3.4178e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 311/500\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 2.0196e-05 - mean_absolute_error: 0.0031 - val_loss: 3.1499e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 312/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.0804e-05 - mean_absolute_error: 0.0032 - val_loss: 2.8847e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 313/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.9970e-05 - mean_absolute_error: 0.0031 - val_loss: 3.6946e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 314/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0505e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7468e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 315/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9601e-05 - mean_absolute_error: 0.0030 - val_loss: 4.2958e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 316/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2719e-05 - mean_absolute_error: 0.0033 - val_loss: 3.0322e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 317/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4068e-05 - mean_absolute_error: 0.0035 - val_loss: 3.1200e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 318/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9619e-05 - mean_absolute_error: 0.0030 - val_loss: 2.9344e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 319/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3978e-05 - mean_absolute_error: 0.0035 - val_loss: 3.3775e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 320/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1271e-05 - mean_absolute_error: 0.0032 - val_loss: 3.0169e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 321/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1422e-05 - mean_absolute_error: 0.0032 - val_loss: 3.1468e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 322/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1368e-05 - mean_absolute_error: 0.0040 - val_loss: 2.5738e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 323/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0640e-05 - mean_absolute_error: 0.0032 - val_loss: 2.8361e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 324/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3469e-05 - mean_absolute_error: 0.0034 - val_loss: 2.6149e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 325/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9130e-05 - mean_absolute_error: 0.0030 - val_loss: 3.1738e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 326/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3178e-05 - mean_absolute_error: 0.0034 - val_loss: 2.7458e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 327/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3325e-05 - mean_absolute_error: 0.0034 - val_loss: 3.2700e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 328/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4326e-05 - mean_absolute_error: 0.0035 - val_loss: 3.5223e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 329/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0864e-05 - mean_absolute_error: 0.0032 - val_loss: 3.0290e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 330/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4574e-05 - mean_absolute_error: 0.0035 - val_loss: 3.5891e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 331/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0951e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6016e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 332/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1534e-05 - mean_absolute_error: 0.0032 - val_loss: 3.4421e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 333/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0350e-05 - mean_absolute_error: 0.0041 - val_loss: 2.7981e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 334/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8400e-05 - mean_absolute_error: 0.0029 - val_loss: 2.8298e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 335/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2079e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9372e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 336/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1643e-05 - mean_absolute_error: 0.0033 - val_loss: 2.6919e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 337/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.1372e-05 - mean_absolute_error: 0.0032 - val_loss: 3.4334e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 338/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.2607e-05 - mean_absolute_error: 0.0033 - val_loss: 2.5704e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 339/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.2662e-05 - mean_absolute_error: 0.0033 - val_loss: 2.4561e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 340/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 2.4388e-05 - mean_absolute_error: 0.0035 - val_loss: 2.7621e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 341/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0847e-05 - mean_absolute_error: 0.0032 - val_loss: 2.4941e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 342/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9737e-05 - mean_absolute_error: 0.0031 - val_loss: 4.9705e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 343/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6081e-05 - mean_absolute_error: 0.0036 - val_loss: 5.5991e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 344/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1505e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6642e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 345/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1796e-05 - mean_absolute_error: 0.0033 - val_loss: 3.2911e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 346/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.3553e-05 - mean_absolute_error: 0.0043 - val_loss: 8.2230e-05 - val_mean_absolute_error: 0.0078\n",
            "Epoch 347/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8918e-05 - mean_absolute_error: 0.0039 - val_loss: 2.9985e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 348/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9260e-05 - mean_absolute_error: 0.0030 - val_loss: 3.0129e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 349/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0537e-05 - mean_absolute_error: 0.0032 - val_loss: 2.8005e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 350/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9519e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0026e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 351/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9392e-05 - mean_absolute_error: 0.0030 - val_loss: 3.0035e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 352/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.2169e-05 - mean_absolute_error: 0.0041 - val_loss: 5.5144e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 353/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.9405e-05 - mean_absolute_error: 0.0039 - val_loss: 3.0321e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 354/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0035e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0017e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 355/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8283e-05 - mean_absolute_error: 0.0029 - val_loss: 2.7956e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 356/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3681e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8224e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 357/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9347e-05 - mean_absolute_error: 0.0030 - val_loss: 2.5501e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 358/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7938e-05 - mean_absolute_error: 0.0029 - val_loss: 5.3682e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 359/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2960e-05 - mean_absolute_error: 0.0034 - val_loss: 4.3354e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 360/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0446e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6385e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 361/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8693e-05 - mean_absolute_error: 0.0029 - val_loss: 2.6631e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 362/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3612e-05 - mean_absolute_error: 0.0035 - val_loss: 2.9661e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 363/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.8125e-05 - mean_absolute_error: 0.0038 - val_loss: 4.7678e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 364/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9523e-05 - mean_absolute_error: 0.0031 - val_loss: 2.9417e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 365/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0136e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0863e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 366/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1387e-05 - mean_absolute_error: 0.0033 - val_loss: 3.0724e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 367/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2375e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9836e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 368/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6191e-05 - mean_absolute_error: 0.0037 - val_loss: 2.8813e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 369/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9839e-05 - mean_absolute_error: 0.0031 - val_loss: 2.9224e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 370/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4835e-05 - mean_absolute_error: 0.0036 - val_loss: 3.2454e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 371/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9960e-05 - mean_absolute_error: 0.0031 - val_loss: 4.5257e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 372/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0319e-05 - mean_absolute_error: 0.0031 - val_loss: 2.9766e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 373/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9032e-05 - mean_absolute_error: 0.0030 - val_loss: 2.7152e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 374/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0245e-05 - mean_absolute_error: 0.0031 - val_loss: 2.7003e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 375/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4411e-05 - mean_absolute_error: 0.0035 - val_loss: 2.7678e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 376/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3762e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8192e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 377/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0344e-05 - mean_absolute_error: 0.0032 - val_loss: 4.8580e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 378/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1747e-05 - mean_absolute_error: 0.0033 - val_loss: 2.7214e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 379/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9820e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0496e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 380/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9547e-05 - mean_absolute_error: 0.0030 - val_loss: 2.5618e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 381/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0843e-05 - mean_absolute_error: 0.0032 - val_loss: 2.8317e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 382/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3880e-05 - mean_absolute_error: 0.0035 - val_loss: 5.1961e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 383/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5348e-05 - mean_absolute_error: 0.0036 - val_loss: 1.0434e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 384/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4853e-05 - mean_absolute_error: 0.0035 - val_loss: 2.6346e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 385/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7523e-05 - mean_absolute_error: 0.0028 - val_loss: 2.7553e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 386/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1583e-05 - mean_absolute_error: 0.0033 - val_loss: 3.0263e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 387/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1197e-05 - mean_absolute_error: 0.0032 - val_loss: 3.4843e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 388/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8096e-05 - mean_absolute_error: 0.0029 - val_loss: 3.2516e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 389/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3118e-05 - mean_absolute_error: 0.0034 - val_loss: 5.0858e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 390/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5548e-05 - mean_absolute_error: 0.0036 - val_loss: 1.0908e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 391/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.1724e-05 - mean_absolute_error: 0.0041 - val_loss: 2.7209e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 392/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2066e-05 - mean_absolute_error: 0.0033 - val_loss: 3.4658e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 393/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1488e-05 - mean_absolute_error: 0.0033 - val_loss: 3.2191e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 394/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7995e-05 - mean_absolute_error: 0.0029 - val_loss: 3.0295e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 395/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9156e-05 - mean_absolute_error: 0.0030 - val_loss: 2.8763e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 396/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7972e-05 - mean_absolute_error: 0.0029 - val_loss: 2.8590e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 397/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9143e-05 - mean_absolute_error: 0.0030 - val_loss: 3.4180e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 398/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8101e-05 - mean_absolute_error: 0.0029 - val_loss: 2.9264e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 399/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 3.0976e-05 - mean_absolute_error: 0.0039 - val_loss: 3.0986e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 400/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2098e-05 - mean_absolute_error: 0.0033 - val_loss: 2.7678e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 401/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8690e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2003e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 402/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0786e-05 - mean_absolute_error: 0.0032 - val_loss: 3.1598e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 403/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0668e-05 - mean_absolute_error: 0.0031 - val_loss: 3.6802e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 404/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3819e-05 - mean_absolute_error: 0.0034 - val_loss: 5.2168e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 405/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9383e-05 - mean_absolute_error: 0.0030 - val_loss: 2.8275e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 406/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8169e-05 - mean_absolute_error: 0.0029 - val_loss: 2.9132e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 407/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9074e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2400e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 408/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8875e-05 - mean_absolute_error: 0.0030 - val_loss: 3.0115e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 409/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9854e-05 - mean_absolute_error: 0.0031 - val_loss: 3.5931e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 410/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8110e-05 - mean_absolute_error: 0.0029 - val_loss: 3.2705e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 411/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.3593e-05 - mean_absolute_error: 0.0034 - val_loss: 3.1573e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 412/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8487e-05 - mean_absolute_error: 0.0029 - val_loss: 3.6691e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 413/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6173e-05 - mean_absolute_error: 0.0037 - val_loss: 2.7774e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 414/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2232e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9928e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 415/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9099e-05 - mean_absolute_error: 0.0030 - val_loss: 2.9542e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 416/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9718e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0272e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 417/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0089e-05 - mean_absolute_error: 0.0031 - val_loss: 3.9127e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 418/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1133e-05 - mean_absolute_error: 0.0033 - val_loss: 4.8698e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 419/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0679e-05 - mean_absolute_error: 0.0032 - val_loss: 4.1283e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 420/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9504e-05 - mean_absolute_error: 0.0031 - val_loss: 4.5906e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 421/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8242e-05 - mean_absolute_error: 0.0029 - val_loss: 3.2989e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 422/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9927e-05 - mean_absolute_error: 0.0031 - val_loss: 3.1185e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 423/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9538e-05 - mean_absolute_error: 0.0031 - val_loss: 2.9305e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 424/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0403e-05 - mean_absolute_error: 0.0031 - val_loss: 3.1628e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 425/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0965e-05 - mean_absolute_error: 0.0032 - val_loss: 3.1901e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 426/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1830e-05 - mean_absolute_error: 0.0033 - val_loss: 4.9308e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 427/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1714e-05 - mean_absolute_error: 0.0033 - val_loss: 3.2998e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 428/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9449e-05 - mean_absolute_error: 0.0031 - val_loss: 3.3957e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 429/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1330e-05 - mean_absolute_error: 0.0033 - val_loss: 3.4034e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 430/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4017e-05 - mean_absolute_error: 0.0035 - val_loss: 3.9598e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 431/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1468e-05 - mean_absolute_error: 0.0033 - val_loss: 3.0137e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 432/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8207e-05 - mean_absolute_error: 0.0029 - val_loss: 3.2287e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 433/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 4.5358e-05 - mean_absolute_error: 0.0045 - val_loss: 5.3877e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 434/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5431e-05 - mean_absolute_error: 0.0036 - val_loss: 3.0575e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 435/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7989e-05 - mean_absolute_error: 0.0029 - val_loss: 3.1479e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 436/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8777e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2786e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 437/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7518e-05 - mean_absolute_error: 0.0028 - val_loss: 3.3014e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 438/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7545e-05 - mean_absolute_error: 0.0028 - val_loss: 3.3108e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 439/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0114e-05 - mean_absolute_error: 0.0031 - val_loss: 3.3876e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 440/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7957e-05 - mean_absolute_error: 0.0029 - val_loss: 3.1000e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 441/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7583e-05 - mean_absolute_error: 0.0029 - val_loss: 4.2955e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 442/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4269e-05 - mean_absolute_error: 0.0035 - val_loss: 3.1610e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 443/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8149e-05 - mean_absolute_error: 0.0029 - val_loss: 4.2991e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 444/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0833e-05 - mean_absolute_error: 0.0032 - val_loss: 3.3832e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 445/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.6181e-05 - mean_absolute_error: 0.0027 - val_loss: 3.3133e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 446/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9780e-05 - mean_absolute_error: 0.0031 - val_loss: 4.0694e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 447/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9869e-05 - mean_absolute_error: 0.0031 - val_loss: 3.1509e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 448/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.4920e-05 - mean_absolute_error: 0.0035 - val_loss: 3.2172e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 449/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8699e-05 - mean_absolute_error: 0.0030 - val_loss: 3.6419e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 450/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8479e-05 - mean_absolute_error: 0.0030 - val_loss: 4.1434e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 451/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0089e-05 - mean_absolute_error: 0.0031 - val_loss: 3.2640e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 452/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8969e-05 - mean_absolute_error: 0.0030 - val_loss: 3.1901e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 453/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2408e-05 - mean_absolute_error: 0.0034 - val_loss: 3.4780e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 454/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8570e-05 - mean_absolute_error: 0.0030 - val_loss: 3.3848e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 455/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.6196e-05 - mean_absolute_error: 0.0027 - val_loss: 3.2509e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 456/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7720e-05 - mean_absolute_error: 0.0029 - val_loss: 3.2876e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 457/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2788e-05 - mean_absolute_error: 0.0034 - val_loss: 3.7524e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 458/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0300e-05 - mean_absolute_error: 0.0031 - val_loss: 3.2971e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 459/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.6320e-05 - mean_absolute_error: 0.0027 - val_loss: 3.1290e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 460/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1221e-05 - mean_absolute_error: 0.0033 - val_loss: 3.2036e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 461/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7712e-05 - mean_absolute_error: 0.0029 - val_loss: 3.0851e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 462/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1404e-05 - mean_absolute_error: 0.0032 - val_loss: 3.5686e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 463/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0410e-05 - mean_absolute_error: 0.0032 - val_loss: 4.3070e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 464/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8613e-05 - mean_absolute_error: 0.0030 - val_loss: 3.3140e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 465/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0071e-05 - mean_absolute_error: 0.0031 - val_loss: 2.9153e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 466/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9595e-05 - mean_absolute_error: 0.0031 - val_loss: 3.3421e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 467/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.6629e-05 - mean_absolute_error: 0.0027 - val_loss: 3.3805e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 468/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9352e-05 - mean_absolute_error: 0.0031 - val_loss: 3.5042e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 469/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8979e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2249e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 470/500\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 1.9931e-05 - mean_absolute_error: 0.0031 - val_loss: 3.3591e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 471/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.9326e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2330e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 472/500\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 1.9762e-05 - mean_absolute_error: 0.0031 - val_loss: 3.2701e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 473/500\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 2.0340e-05 - mean_absolute_error: 0.0032 - val_loss: 3.2897e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 474/500\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 1.6671e-05 - mean_absolute_error: 0.0027 - val_loss: 3.9786e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 475/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2879e-05 - mean_absolute_error: 0.0034 - val_loss: 3.2499e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 476/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.0524e-05 - mean_absolute_error: 0.0031 - val_loss: 6.3778e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 477/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.6367e-05 - mean_absolute_error: 0.0036 - val_loss: 2.9667e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 478/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7741e-05 - mean_absolute_error: 0.0029 - val_loss: 3.3599e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 479/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7719e-05 - mean_absolute_error: 0.0029 - val_loss: 3.0590e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 480/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8096e-05 - mean_absolute_error: 0.0029 - val_loss: 3.9203e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 481/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1301e-05 - mean_absolute_error: 0.0033 - val_loss: 3.3224e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 482/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1678e-05 - mean_absolute_error: 0.0033 - val_loss: 3.5648e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 483/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7252e-05 - mean_absolute_error: 0.0028 - val_loss: 2.9901e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 484/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7309e-05 - mean_absolute_error: 0.0028 - val_loss: 3.1308e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 485/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8742e-05 - mean_absolute_error: 0.0030 - val_loss: 3.1212e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 486/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7448e-05 - mean_absolute_error: 0.0029 - val_loss: 2.9718e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 487/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2911e-05 - mean_absolute_error: 0.0034 - val_loss: 3.1348e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 488/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.5711e-05 - mean_absolute_error: 0.0036 - val_loss: 2.9745e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 489/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.7542e-05 - mean_absolute_error: 0.0029 - val_loss: 3.3167e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 490/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8153e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2171e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 491/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8711e-05 - mean_absolute_error: 0.0030 - val_loss: 3.2565e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 492/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.8371e-05 - mean_absolute_error: 0.0029 - val_loss: 3.1987e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 493/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.7131e-05 - mean_absolute_error: 0.0028 - val_loss: 3.1527e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 494/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.9180e-05 - mean_absolute_error: 0.0030 - val_loss: 3.6752e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 495/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.8397e-05 - mean_absolute_error: 0.0030 - val_loss: 3.0389e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 496/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.7944e-05 - mean_absolute_error: 0.0029 - val_loss: 2.9870e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 497/500\n",
            "98/98 [==============================] - 2s 18ms/step - loss: 1.9016e-05 - mean_absolute_error: 0.0030 - val_loss: 3.3288e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 498/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.2993e-05 - mean_absolute_error: 0.0034 - val_loss: 3.2103e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 499/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 2.1969e-05 - mean_absolute_error: 0.0033 - val_loss: 3.3116e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 500/500\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 1.8584e-05 - mean_absolute_error: 0.0030 - val_loss: 3.0851e-05 - val_mean_absolute_error: 0.0025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJEBYV4lI52R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "5420b518-a949-4bf6-b8b1-0dc9c68df0aa"
      },
      "source": [
        "model2=keras.models.load_model(\"selu2.h5\") \n",
        "ytrue=denorm(y_test,df.target)\n",
        "yhat=denorm(model2.predict(X_test),df.target)\n",
        "\n",
        "model2.evaluate(X_test,y_test)\n",
        "print(\"sklearn mae：\",sklearn.metrics.mean_absolute_error(ytrue,yhat))\n",
        "\n",
        "gene_hist(ytrue,yhat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 0s 2ms/step - loss: 3.1103e-05 - mean_absolute_error: 0.0034\n",
            "sklearn mae： 3.9013095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnPkLEWXVqVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0c21ac4-c857-4d88-d3c2-f9197f729b51"
      },
      "source": [
        "calculate_profit(ytrue,yhat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "profit is 169.868896484375 position in portfolio is 0\n",
            "5075 (5075, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>yhat</th>\n",
              "      <th>ytrue</th>\n",
              "      <th>profit</th>\n",
              "      <th>position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3044.845703</td>\n",
              "      <td>3044.776367</td>\n",
              "      <td>3045.209961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3045.209961</td>\n",
              "      <td>3046.358154</td>\n",
              "      <td>3044.386230</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3044.386230</td>\n",
              "      <td>3046.316650</td>\n",
              "      <td>3052.290039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3052.290039</td>\n",
              "      <td>3051.814209</td>\n",
              "      <td>3052.827881</td>\n",
              "      <td>7.080078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3052.827881</td>\n",
              "      <td>3053.076904</td>\n",
              "      <td>3046.581787</td>\n",
              "      <td>7.080078</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5071</th>\n",
              "      <td>3366.390869</td>\n",
              "      <td>3365.633545</td>\n",
              "      <td>3364.749023</td>\n",
              "      <td>166.811279</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5072</th>\n",
              "      <td>3364.749023</td>\n",
              "      <td>3363.659424</td>\n",
              "      <td>3354.088379</td>\n",
              "      <td>166.811279</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5073</th>\n",
              "      <td>3354.088379</td>\n",
              "      <td>3355.418213</td>\n",
              "      <td>3357.145996</td>\n",
              "      <td>166.811279</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5074</th>\n",
              "      <td>3357.145996</td>\n",
              "      <td>3355.701416</td>\n",
              "      <td>3354.165771</td>\n",
              "      <td>169.868896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5075</th>\n",
              "      <td>3354.165771</td>\n",
              "      <td>3352.074951</td>\n",
              "      <td>3354.035156</td>\n",
              "      <td>169.868896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5075 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                t         yhat        ytrue      profit  position\n",
              "1     3044.845703  3044.776367  3045.209961    0.000000         0\n",
              "2     3045.209961  3046.358154  3044.386230    0.000000         1\n",
              "3     3044.386230  3046.316650  3052.290039    0.000000         1\n",
              "4     3052.290039  3051.814209  3052.827881    7.080078         0\n",
              "5     3052.827881  3053.076904  3046.581787    7.080078         1\n",
              "...           ...          ...          ...         ...       ...\n",
              "5071  3366.390869  3365.633545  3364.749023  166.811279         0\n",
              "5072  3364.749023  3363.659424  3354.088379  166.811279         0\n",
              "5073  3354.088379  3355.418213  3357.145996  166.811279         1\n",
              "5074  3357.145996  3355.701416  3354.165771  169.868896         0\n",
              "5075  3354.165771  3352.074951  3354.035156  169.868896         0\n",
              "\n",
              "[5075 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAI/CAYAAADQuvCeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhb1Z3/8c+5WmzHSxzH2RPihOyEPQTCUtZCaOnQdmZa2k4XutDOMN3pNtN9/3Wdoe20pe3Qlil0KN2YlpZSdigBEiABErKQheyJszjxKune8/tDurJsy3EiS766yvv1PDxIV1fSsZxE+uh7zvcYa60AAAAAAOHkBD0AAAAAAEDhCHUAAAAAEGKEOgAAAAAIMUIdAAAAAIQYoQ4AAAAAQoxQBwAAAAAhFg16AEejubnZtrS0BD0MAAAAAAjEihUrWq214/LdFopQ19LSouXLlwc9DAAAAAAIhDFmy2C3Mf0SAAAAAEKMUAcAAAAAIUaoAwAAAIAQI9QBAAAAQIgR6gAAAAAgxAh1AAAAABBihDoAAAAACDFCHQAAAACEGKEOAAAAAEKMUAcAAAAAIUaoAwAAAIAQI9QBAAAAQIgR6gAAAAAgxAh1AAAAABBihDoAAAAACDFCHQAAAACEGKEOAAAAAEKMUAcAAAAAIUaoAwAAAIAQI9QBAAAAQIgR6gAAAAAgxAh1AAAAABBi0aAHAAAAAJTKTx7ZpFsf35K97hijjy2dp8sWTAhwVEBxUakDAABAxXpg7R7t60ho3qQGzZvUoE2tHVq2cV/QwwKKikodAAAAKpbrWc0aV6fvvfEMSdLpn/+LEq4X8KiA4qJSBwAAgIrlelYRx2SvxyKOkoQ6VBhCHQAAACpWvlCXSNkARwQUH6EOAAAAFcu1fUNdPEqlDpWHUAcAAICKNbBSZ7RiywHd9sRLAY4KKC5CHQAAACpWyrWK5oS6l80epwOdCf3nX9cHOCqguOh+CQAAgIrl9Zt++cmrFqgjkdK9a/YEOCqguAh1AAAAKHvWWn397rXafrBLkjRmVFyffOV8RSP5J5796dmdenzTfqX6Tb+UJGOMPEuzFFQOQh0AAADKXltXUv/1wItqqo3LMVJre0JvO7dFLc21ec9//y+fUcL11FwXV8TpG/wixsgj06GCsKYOAAAAZa8nle5Y+eHL5+hTVy2QpCNW2/wNxlvbE2qo7lvHcEy6gQpQKajUAQAAoOwlMqGuKhqRMenplEfKZS+bM04Prdur/73uHC2cMrrPbY7D9EtUFkIdAAAAyl5PypUkVUUdZTKd7BGCmedZnXFCo86eOXbAbRFj5FGpQwVh+iUAAADKmudZff4PaySlNw93jqJSl3S9QZuoOI6RS6UOFYRQBwAAgLK261C3Hlq3V5I0b2K9/GaWVoMHs5RnFYuYvLc5NEpBhRl2qDPGVBtjnjDGrDTGPG+M+Vzm+AxjzOPGmA3GmP81xsQzx6sy1zdkbm8Z7hgAAABQufymJt/4x1M1fWytpEylzst/ftL11J10B3S99DlGTL9ERSlGpa5H0iXW2lMlnSZpqTHmHEn/T9K3rbWzJB2Q9I7M+e+QdCBz/NuZ8wAAAIC8UpkAFs2U6PxKXb5mJ9ZaXfi1+/X8jkOKD1Kpi9AoBRVm2KHOprVnrsYy/1lJl0i6I3P8Z5Jenbl8dea6MrdfavwWRgAAAEA/bqYkF8mGuvT/8+WylGe1o61bkvSO82fmfTyTmX55pEYrQJgUZU2dMSZijHlG0h5J90h6UdJBa20qc8o2SVMyl6dI2ipJmdvbJA1sSwQAAABISrr9KnWZT7D5qm3+VM2PXDFXS07M/xEzcoRQCIRRUUKdtda11p4maaqkxZLmDfcxjTHXGWOWG2OW7927d9hjBAAAQDj5Qc2v1JnMmrp8mcwPev65+fg30QETlaKo3S+ttQcl3S9piaRGY4y/D95USdszl7dLmiZJmdtHS9qX57FustYustYuGjduXDGHCQAAgBDx19TFMlsUmCOsqcsGwCOs7nEyqe7Pz+3S4xsHfAwFQqcY3S/HGWMaM5drJL1c0hqlw90/ZE57q6TfZy7fmbmuzO33WSY0AwAAYBCDr6kb+BHSb2rpHKFS11QblyS997an9fqblmlXW7f+9OxO/ftvn9WvV2wr5tCBEREd+pQhTZL0M2NMROmQeLu19g/GmNWSfmmM+aKkpyX9JHP+TyTdYozZIGm/pGuKMAYAAABUqMPd6TYN0X6hzrPS1d99RKu2t2lCfbWWnDg2W8U7QqbT6xdN06LpY3TPmt362p/XqjOR0n/eu14v7DqsXzz+kqpjEU1rqtEpUxtL+nMBxTLsUGetXSXp9DzHNyq9vq7/8W5J/zjc5wUAAMDx4WO/XiVJqo5HJOVMv/Ss1uw6rKhjFI86emjdXu3rSEgaYk2dYzR7Qr1e2HU4/TjWKuH2bnp3/a1PqSYW0ZovLC3FjwMUXVHX1AEAAADFFnUcNdfFdVqmcta7pi4d7K572Uw99NGL9fmrF2bv4xzFjll+8HM9KeX2TuWMRYy6km4RfwKgtAh1AAAAKGuetbpk3vjsOrnsmjpZudZmm6LEcjYbP1Klzuc/jutZJXMqdVXRdEWQtg8Ii2KsqQMAAACK7vblW7VlX4faupKKOL21iOyaOi+915wf9uLR3HOGfnw/+HnWZvfCyz5OT/qxj6LgBwSOUAcAAICy9NE7VmUvR3NSmn9x5baDknq3L4hHBga/I/FPdz2rlNdbqfMfx7NWjkh1KH9MvwQAAEDZ6T/1MXc6pZ/Xvn73Wkm9lbpYTqXumKZfWquDncnscb/i5zH7EiFBqAMAAEDZyZ0OKfWt1Jl+VTg/wNVXRwccOxL/nO0Huvo+V6R3WiYQBoQ6AAAAlJ3cLQYkKZLTBCXaL7D50y/nTqjPHvObnRyJf7/2nvQ+eLWZLRMiLKRDyLCmDgAAAGUnkeob6nKD3PxJDbrh8jn6xl/WSeqdfmmM0d0feJme296mi+aOG/I5/Pt1JtLbF/zzRSdq+8Eu1cajWr+nnUodQoNQBwAAgLLz0Lq9fa5Hc7pfxiKO/vWS2Xr6pYO694U9yiniae7Ees2dWK+j4U+/7M7sSTd/UoP+9ZLZ+tFDGyWl19S196R05zM7tP1gp+ZObND0plEaV1+lyY01w/nxgKIi1AEAAKDstHWlG5fEo+n+k/PyBDV/bd3RrJ/Lx2+U8tunt0vqnbLpz75s60rq0m8+oO5k36phTSyiVZ+9XLEIK5lQHgh1AAAAKDupTOvJJ//9Mo2uieU9x89U/RunHK2Jo6slSRv2tEuSGkfF+jzevvYedSc9vWHxNN32xFZJ0uknNOrplw4q5VrFhl62B4wIQh0AAADKjpvZN65/U5RcftjL3XT8WExprNHaLy7Vqm1tqo5GdNLkBkm9++D5FbrzZjVnQ93k0TV6WgdZb4eyQqgDAABA2fErdUeaWvmBy+bo5CmjtXThxIKfpyoa0VktTX2O+dMy/bV2uZua++Mh0qGcEOoAAABQdtzMPnVHqtRNbqzRm5e0FP25/afs8kNdTiXQ38Ou/+boQJBY3QkAAICyczSVulLx19T95fndkvrueRfLdOH0yHQoI4Q6AAAAlJ2U5ynimIKboAyH/5Srth2UJJ04rjZ7W3YTdEIdygihDgAAAGUn5dlAqnRS75q6hOvp7BlNGt9Qnb0tlhkTjVJQTgh1AAAAKCs/fnij7li+7Yjr6UrJf9qepDegs2Y00zSFSIdyQqgDAABAWbnr2Z2ykq572cxAnt+f8tmdcvt0vpR6G6VQqUM5IdQBAACgrCRcT6dNa9QHLpsTyPP70y8PdiYV6xfq/EYpZDqUE0IdAAAAykoi5SkWCWbqpSQ11caylwdOv2RLA5Qf9qkDAADAiHA9q1ufeEmHu5PZY+fPatYpUxv7nJd0reI52wiMtIvnjs9e9qdZfuSKubp3zW6NGRWXxJo6lBdCHQAAAEbEmp2H9KnfPdfn2KOzWvWLd57T59jBzsSAtWwjyRijqGOU8qzOnjlWknT9xbN0/cWzdNsTL0li+iXKC9MvAQAAMCJ6Up4k6cdvWaQXvrBUi1ualHT7pqOX9nXqQGcy8EYk/ubntfG+FUN/UmjQ4wNyEeoAAAAwItxMUKqJR1QdiyjimAFr01o7eiRJSzIVsqCNr6/uc91vokKkQzlh+iUAAABK5vGN+/T4pv2KOEaTRqcDkr+puONIntv3fC8T/CaO7humgjJgHJlSnT9OoBwQ6gAAAFAyX75rjVZua5MkLZ7RJCkn1BkzYBqjX82LBLTxeH/91/b5lTqgnDD9EgAAACWTdK0unZfuJumvqfMDmzFG/Qte/vVyCU/RflsrsKYO5YhQBwAAgJKxSoe3iGOUzIS6aLZSN3C/Nz8slUmhbkCoy+w9TvdLlBVCHQAAAErGWitj0iEt4fat1IVh+mXM6ftx2WRqdVTqUE4IdQAAACgpo3S1Ljkg1Eme1/fcbKWuXEJdtF+oywyLSIdyQqgDAABAyVirbKVuy75OSb3TL02eSl3v9MtgQ93Fc8epKuqoekCoy2xpQKpDGaH7JQAAAErGysrI9AlpTbVVkvqum/vU757TLcu26NRpjZKkSMCh7sdvPUtJ11M00n/6ZVr/tYBAkAh1AAAAKJneSl06Dr1szjg11cYl9V1T98KuQ5Kk57entz9wAp5PFnGMIk5kwHE2H0c5YvolAAAASibd/bJ3LVp9dW9NwcnZ0sAvfKXKrFFKf/7PQaMUlBNCHQAAAErG2vT0Sz+kRXPCmjG94ah/SAp6Td1g/OFf/d1HtedQd7CDATIIdQAAACgZK0k50y9zK3COMdkKXf+6V7mGusUzxmrW+Dr1pDxtau0IejiAJEIdAAAASsmmm4v4WS7aJ9TlVur63q0qWp4fU5tq4/rC1QslSS5TMFEmaJQCAACAkkmvqTPZrQAiOR1Q+mw+bq2mNdXoXRfMVFNtXFPH1AQw2qMTjaR/Frd/EgUCQqgDAABAyaTX1OWv1BljspuPe1aaNa5Ob1nSMuJjPFb+1FBCHcpFeda1AQAAUBH87pf519T17vdmZct2HV1//s9AB0yUC0IdAAAASsZm1tTtbEt3ioz0637Z2p7Q+3/5tFKuVUgyXXZjdNcLeCBABqEOAAAAJWNls+vpJOn82c3Zy1ecNFFTx9To98/sUGt7T5/zypkfTF2PVIfyQKgDAABAyfiVOt+Fs8dlL186f4Le9bKZktKbjocj0uWGuoAHAmQQ6gAAAFAy1koy0mnTGjWhoUqO0ze6+VddL0xr6tL/Z0sDlAu6XwIAAKCkjIzueM+SAXvRSX07SYYk0+WMmVIdygOhDgAAACVjbTqsRSP5J4j5ASkVokpdNLPX3qa9HepOuqqORUbkee9cuUPf+sta+dn4+otn6XWLpo3Ic6O8Mf0SAAAAJZOZfTkofy9yz7NHPrGM1FZFZIx0430b9B9/XT8iz9mVcHXjvevV2p7Q6dMatfdwj5Zt3Dciz43yR6gDAABAyVirI06rDGOlbmxdlf7vX8/XmFExtXUlRuQ5v3TXam3Y066TJjfoP645Xc11VWJJH3xMvwQAAEDJWFmZI5TgcoNcOCJd2sIpozUqHlUiVdpktXV/p/7rgQ16cO1eOUa68Q2nS0o3mGHzc/io1AEAAKBkjrZSl748AgMqonjU0YY9h7Vy60Gt331YtgQh669rduu2J7bKSvrgZXM0oaFaUvp1y9d4BscnKnUAAAAoGasjh7rc/ilh2Xzct+dQtza1urr6e49Kkn79z0t05vSmoj5HIpXusPnXD12o2qrej+6GSh1yUKkDAABAyaRzx+BhLTfIhSzTqSPhSpJefdpkSdKhrlTRnyOVKcfF+nUPdYwpSWUQ4USoAwAAQAkdef+5vmvqQpbqMk6e2igpvX6w2PxKXSzSf9N2I7bJg49QBwAAgJKxQ+xUkFuACtuaujcsPkGNo2JqGTuqZM+RdD3FImbA1FSmXyIXoQ4AAAAlM9SaujBPv/zKa0/WM5++XM11VZJUki0GUp4dMPVSolEK+iLUAQAAoGSsPfotDcKyT11//rCLHer2dyR000Mb81bkHEesqUMWoQ4AAAAlM2T3yxBX6nx+aC12xNrV1i1JunzBxAG3pSt1hDqkEeoAAABQMkOtqcttABJ1wvnRtLdSV9yQ5WbmV/7dqZPzPCfTL9GLfeoAAABQUkfaf+70E8boc393kjoTrl5x8sCKVJgUmrE2tXZo24FOndXSpOpYJHs8lWlvGYkMfP0cGqUgB6EOAAAAJTNU9SoedfTWc1tGZjAlVmjGuuamx7T7UI8+ddUCveP8GdnjfqUumqctaHqfusKe73iXSHmKOEaRsLVbPQJCHQAAAEpmqDV1laD35yssZbW2JyRJh7uTkqTntrdpZ1t3dtpqvvBBpW5oew516+7nd8mz0t9ebNXfXtynxS1NuveFPWqqjeuRj12sUfHKiEOV8VMAAACgPB0HuWM4m6Zba7MVuZRrlXI9vea/HlXStVo0fYykvs1kss9Jo5Qh/ejhjfrRw5v6HLv3hT2S0p1FD3YmKybUhXM1KgAAAELBanihJwyGs6XB4Z5U9nLKs0q4npJu+oF2H053v4wOuqbu2J+vknUnXd2ybIvuX7tH3UlXP39si6Y01ujsGU15z3cr6AWsjGgKAACAsmStPW6mXxYSEd7x0yezl12vN9BJ0tb9XZKkSJ6uoI4xcjONVJD22MZ9+tTvnpMk3XztWepJeRpTG1NNPJL3/EoqdFKpAwAAQEl09KTUkXArvE6Xs09dASHhQGdSjklX3pKZ6ZeSdMHs5uw5gzVKeWbrwcIGXKHau3urnj1JV5L0//7+lEG3ynArKNUR6gAAAFAST7+UDh111ZU9Oay3UnfsIcFaqytPnqTGUXG5nlUqMyXwyoWT9NrTp0hKdwjt72BXQrHI8flR/pH1rfrBgy9qxZb9fY53Z4KcJPWk0uG4KurkDcVSZU2/HPafBGPMNGPM/caY1caY540x788cbzLG3GOMWZ/5/5jMcWOMudEYs8EYs8oYc8ZwxwAAAIDy05X5kH3pvAkBj2RkFFL4sTZddYs4RinPUzJTqYtGjD511QJ95w2na/b4ugH3W9wyVk6lz2vNcbg7qd88tU3bDnTqo3es1Ff/9II+e+fq7O0rtuzXPat3Z693JtJ/9qKOk3efP6n4m8UHqRjxPiXpw9baBZLOkXS9MWaBpI9LutdaO1vSvZnrknSlpNmZ/66T9P0ijAEAAABlxq+cVMcqu6LkR4ZCIoJrrRyT7nB52xNbs2vqoo7RmNq4XnXq5Lybt0ecyqo0DeW3T2/Xh25fqS/+YY06M3+ucitzX/jDGv0lT6iL5anUzZtYL4npl31Ya3daa5/KXD4saY2kKZKulvSzzGk/k/TqzOWrJf3cpi2T1GiMmTTccQAAAKC8bG7tkCRVx/I3qqgUwymYedbKMUZNtXFJ0vfu3yBJig4xtTLiOBUVSobSlQlpbV1JJTJTK/2qppQOeJfOG69PXbVAktSZ6Soac8yANXVVmT+PlRSKi/q1iTGmRdLpkh6XNMFauzNz0y5Jft19iqStOXfbljkGAACACtLa3iNJGlsXD3gkpeY3Sjn2kOB56emX3379aaqKOrpjxTbFo46mN4064v2Ot0qdH2Bzp6jmdgp1PauqmKOaTGD75j3rJKXDcf9KXSxzvZKahxZt1aoxpk7SryV9wFp7KLdMbK21xphj+lNnjLlO6emZOuGEE4o1TAAAAIwQY4zqqqIVs8HzYIZTqbOZ6ZdzJ9ZrzeeXZvb1k5xBmnv4Io4j17OZLSMqf22dlwmwiVTvtg+pnFSW8qyijqNL54/XWU+P0ZObD6gmFtGoeESTG2skSUtmjtW+jh69fMEELd9yoKI2by/K3zBjTEzpQPcLa+1vMod3G2MmWWt3ZqZX7skc3y5pWs7dp2aO9WGtvUnSTZK0aNGiynnFAQAAjhOetXk3zq402TV1BXxidTPTL6Whg1yuSOY+npWOg5c42xV0/Z727LHcSl3S9RR1jCY0VOtX7zlXew51qzoeUXUsovddOktvPPsENdfFZYzR/WvTsaSSpq8Wo/ulkfQTSWustd/KuelOSW/NXH6rpN/nHH9LpgvmOZLacqZpAgAAoEK4ns2Gj0rmV8oK2dLAs8cW5nx+WD5epmD6lbr5kxq0eEaTTj+hUfs7Etmf3/X6foEwvqFaDdUxSenfz7j6quzvKRuIK+i1K8aauvMkvVnSJcaYZzL/vULSVyW93BizXtJlmeuSdJekjZI2SPqRpH8pwhgAAABQZjxrCwosYTOcSp0//fJY+dW94yXUudYq6hj9+p/P1e3vXqIlM8dKkj7xm1WS0lW7yCCbjPcXcXqrnJVi2NMvrbWPqPfPcn+X5jnfSrp+uM8LAACA8na8VOp8BU2/9GxB+835zT8qaQrhkaS8vl8QvP38GfqvB17UrkM9staqtb1HsaOch+q/3D948EU9uXm/rr94VimGPKIqe9MQAAAABMazKqgKFTZ+SCgkXnm2t3J0LPyA84tlW/TzxzZr6/7OAp49PDzP9uli2VxXpTNOaJTnWd300EZJUk386LbOmNFcq5nNtXpi0359/e61OtSdLMmYRxKhDgAAACXhecfL9MvCf0bP2oK6Z05prJYkfeVPL+jTv38+u79dpXI9Daj6Rhwjz1rtOZzeOuO6C2Ye1WNNGl2j+264SDdcPif92G74q52V3V8WAAAAgXGtLagKFTbZSl0BUyGtVUHTL5cunKSVn75cKc/Tq77ziBJuBW26lofreYr0m15pjJHrWbmeVX11VGPrqo7pMSMVNIWVUAcAAICSOO7W1BVwn/SausKeb/SodHdHxzGFPXkI7Grr1pt+vEw7Dnartqrv9MpIJtR5BX554DdWqYRmM4Q6AAAAlMRx0/0y2/7y2O7XmUipK+kO+zUylZvptKm1Qy/u7dDFc8fp8pMm9rnNcaSEawv+8iCSWYiWItQBAAAA+Xne8dIopbB96t7/y2ckSZMaqof3/DIFTf0MA//nes+FJ+rszDYGPsek19QV+uWBX6mrhP3qaJQCAACAYfM8q2S/dV2uLaxdf9gUuk/doa6k4lFHbz23ZXjPX8Evsb/eLV9oc4yR5xVeqfO7aVZCpY5QBwAAgGF7681P6Nyv3idrrXYc7NKN967Xi3vaj69GKcd4v4Tr6ewZTdlKX8HPX8Bzh4Wft/J9ORBxjFxr050xh7EtRCWsqSPUAQAAYNgeXt+qvYd75HpWty/fqm/ds04bWzs0d0J90EMLVHtPatDpfT1JT1XR4X8cN8YUtPF5GPivXb7Mlq7U+Ws3j/2xoxUU6lhTBwAAgIJZa/V33300ez3lWXUnPcUjjtZ96coARzZy/H3qrJVe9Z1HtGbnIb313Ba9Zcl0Xfj1B7T0pIn6wZvPHHC/hOspXoRQJ1Vupc4PXPkqcY5JB7rCG6X40y/Dvx0ElToAAAAMy7Pb27KXk66nlOspGqn8aZc+P08kUq6e3d6mlGe1esch7WrrliT9+fldA+6zeschbdjTrlikCJU6FbZHXhh4/pq6QaZfetam124WMP0ynnntX/29R3X9L54a3kADRqgDAABAwfwsMSazZ1rKTTdMKUZYCQs/Tnz2/1Znj7meVdIdfOrg6p2HJElX9GvTX+gAKjPSHTnUOf4+dQVW6hbPaNIHL5ujlrG1em5H29B3KGPHz982AAAAFJ0fJvwQl/Kskp5V7Diq1KnfjzqjuVYpz8t2A+0/ddD1rD7z++ckSeed2Fycp6/QVOc3VM07/dIxautKaeuBzoIapdRWRfX+y2Zr4ZTR2fAYVqypAwAAQMH8aX+9oc5TMnW8Vep6A8VnX7VAD6zbqwMdCfWk0onEMUZ3rtyh1sM9kqRD3Ul1JFxNaaxRQ83wP44Pt3tmOfPDVr4/TuPqqtTa3qPW9h5dMLvwcGzMsW9HUW4IdQAAABg2vzL3x1U7tam147hcUydJNfGIoo5JVywzZaaelKf33fZ0n/tEHKMfvvnMogSy9JYGIU8lg/BDXb7X6d9fOV9vPXe6JGnCMDZwdyqgeyihDgAAAAXzPwuPb6jW5n2d+uIf10iSzpw+JrhBjbDcuFEdi6T3T/Osfvf09j7nfek1C3XVyZMlSbGo0ah4cT6KV0KlaTDZ7peDNEqZPrZ22M9hJKZfAgAA4PjlfxZ+2exm3XjN6epJuZKk8fWFV07CbGxtlaKOo5TX25ExHnGUcD01VMc0OtNQpthCnkkG5W8hV8pN7B1jCHUAAAA4fvnT/owxmjj6+AxyuVMDZ4yrzVbqUpnpl4nM/0vVPMbIVMT0y92HunXHim19Nmv3u1KWctmg4/SG4kTK03M72jR/YoNq4pHSPWmREeoAAACAYcjNG6Ni6TV1m1o7NL6+qs95Uac0zWMqZfrl/z65Vd+6Z92A4021cY0ZFS/Z8xpjshXBn/5tk7581wv664deplnj60v2nMVGqAMAAEDBKiFMDFd1rLeiU1sVzTaJeXzT/j7nRUrYPKYSfg0dPSnFo45Wf+6KPscdYwraXPxoOaa3i+vOzIbxkxtrSvZ8pUCoAwAAwLBVcFf9IdXEI3r045fIMVI86ui9l8zW7cu3DTgvVrJKXWW8+N1JVzWxiKIjvB2GUXpN3Sd/96x+89R2TWmsKVoTm5ESrtECAACgLJn+O3AfZ6bkVHbqq/N/xC7VNg9GlVEx/eOzO1UVHfn9DR2TrnQ+vL5VzXVVet+ls0d8DMN1/OwKCQAAgKKrhDBRbPmqPMZIzXVVec4evnShLty/iP0dCbW2J7JNZUaSMUaeZ5Vyrc5qadI/nDl1xMcwXFTqAAAAULDe7pcBD6SMxKOOfnrtWXr3LSv0LxfN0mvPmKKaeKRkoU4Kf7j2t8L42NJ5I/7c/ubjrmcVLeHavVIi1AEAAKBgfpgI50fh0rlo7nit/eKVI/JcxoS9Tiel3PRPEESoMia9+XjK80o2RbbUmH4JAACAYaNSFxwjk+3eGFapzJ4CsRFukiL1rqlLhbhSR6gDAABAwcIdJSpDJVTqXC+9lifJ1KIAACAASURBVC4SQKhyTLr7Zcq1ipSoQ2mphXPUAAAAKAt+heh4734ZpErofpl0/UpdENMv05uPpzwvkOcvBtbUAQAAoGB+lmD6ZYAq4MV3M9Mvg6iUmczm490pG0ilsBio1AEAAAAhZhT+6ZfJzFYGQTQqcUxupTCc8YhKHQAAAAoW9ml/lSKsjVKstbr+1qe0ZudhScF0v3RyKp1vPPuEEX/+YghnFAUAAEB58Lc0qIApgGEV5pe+K+nqrmd3KeIY/d2pk3XylNEjPgY/D9fGI5rQUD3iz18MVOoAAABQsOzm4wGP43gW5kYp/lq61y+apne9bGYgY2iqjUuSLp43PpDnLwZCHQAAAIYtzNWisDPGyMpq6/5OjauvUiziyEhyQtD0I5PpAh3r285t0eUnTdCUxprAxjBchDoAAAAULKwVokpiJD26YZ8u+Nr92WNjRsX00EcvVn11LLiBHQUvk+qCzJ+OYzR1zKjgBlAErKkDAABAwbJbGgQ6iuNbbpX07efN0CtOnqgDnUm1tieCG9RR8qy/lQF/goaDUAcAAIBho1FKefjEK+bplSdPltS7TUA5c/3N6/nzMyyEOgAAABQsrK30K4nJqZPGIo5imb3eEqnyD3VeZogRQt2wsKYOAAAABctOv+QzeXAyr/3CKQ2SpHg0XbfpKaNQt3zzfu053KMTx9Vp7sT67PHe6ZdBjawyEOoAAABQML9QR6YLjv/aR5x0MopnEtJL+zt05vQxAY2qV1tXUv/4w8dkrTSlsUaPfvyS7G3+lgZMvxweMjEAAACGjw/lgfFf+mim2UhDTbrj5Qf/d6VSZbCurifpytp0h8vORKrPbf6XAky/HB5CHQAAAApmxZq6oPlr6vwOkidNbtAlmY20U17wvx9/BNGIo/7D8RulOKSSYeHlAwAAQOGYfhm4/pU6Y4zOmdkkqXd6Y5D8dXMxx2T3pet/m0OlblgIdQAAACgYjVLKR+5eb35IKodKnT+EiGOyIS57m0eoKwZCHQAAAIbNUKsLTP9KXe7l/pWxIPhjyDf9MjfwoXCEOgAAABSMbeqC17umrvejvR+SyqFSZ3OCm9vvD8yh7qSkdBMVFI5QBwAAgIL5jVKYPRecUfGIJKm+une3Msev1JVB6vbHEHXMgM3qX9rXKUmqikVGfFyVhH3qAAAAUDD2qQveF1+zUNcsnqZTpzZmj0XLqVKX+X96TV3f21JeesuFORPqhcIR6gAAADBsVOqCM76+WpfMq+5zzG88UhZr6vzulxFnQDfO7mQ61NVQqRsWpl8CAACgYMFHBuQTjaRDXTlsaeBPufTX+fnXD3cn9bO/bZYkVceIJcPBqwcAAICC+R/Q6X5ZXsplS4OuhJutxkX86mFmSHc/v1sbWztUHXNUHaVSNxyEOgAAAAwfma6s+FWxG361MrApmMs379f8T/9ZV33nkT5j8qdjdiddSdJfP3RhtrELCkOoAwAAQMHKoLki8jhtWrppyjNbD2p/ZyKQMWzOdLb0xfpNCfX/z3q64SPUAQAAYNios5SXqWNG6SuvPVmSlHS9QMbQmUj1ud67pi593Q91UYdIMlx0vwQAAEDBslsa0P6y7MQi6bCUckeunNrRk9L7f/mMDnUntbOtq89tfnjzp1/6oY5MN3y8hAAAABg2Il358ac7fuVPawZUzUpl494O/XXNbrV1JjWlsUZV0d644XfkvPG+9frNU9uyTVyo1A0fryAAAAAKZtnUoGzFM5W6u57dpRVbDozIcybcdPOTf3vlfP3yuiX62j+ckr3txHF1ikcc/fDBjfrwr1ZmG6WQ6YaPlxAAAAAF651+Gew4MJA//VIaua0NelLp9Xt+oIzkdLW8ZP54rfvSlfr0VQtkrXSoOymJSl0x8AoCAACgYH5UINSVnwkN1dnLdoTalCb8UJeZdpkb2Py980bF090u27tTmeMjMrSKRqgDAADAsLH5ePk5eepo/fTasyRJI9EAc8fBLm3dn97GoCob6nr/XPgXG2pikqTfPr1dEcfQZKcI6H4JAACAgnX0jEwDDhRmXH2VpN6Ok6XyzNaDevX3Hs1er6tKx4yW5lGqiUVkTHqbBUm6ZN54SekpofEINaZiINQBAACgYJ/7v+clSTVxNpAuR/6UR6/Ea+r2d/RIkm64fI5OmdqoluZaSdKs8fVa84Wlfc6tjkX08Svnafnm/VowqaGk4zpeEOoAAABQMM+mp9r51ReUl2yoK/GSOn9654VzxuvkqaOHPP89F54oXXhiaQd1HKHeCQAAgIKlPKtzZo7t02kR5cP/tbglnn7JRuLB4mUHAABAwVKu16cZBsqL34Sk1N0v/TV7Ef4sBIJQBwAAgIK5nuWDfBmLZEKdW+L5l/7jR+hkGQhCHQAAAAqW8ixTL8vYSK2p8yt1bE8QDP4GAgAAoGAp16NSV8b8jFXqLQ2YfhmsooQ6Y8x/G2P2GGOeyznWZIy5xxizPvP/MZnjxhhzozFmgzFmlTHmjGKMAQAAACMv5VlFI3yQL1d+yCr1lgZ+90umXwajWJW6n0pa2u/YxyXda62dLenezHVJulLS7Mx/10n6fpHGAAAAgBG07UCnth3oolFKGRux6Zd0vwxUUV52a+1Dkvb3O3y1pJ9lLv9M0qtzjv/cpi2T1GiMmVSMcQAAAGDk/Gr5NknSvIlsIF2unBHa0oDpl8EqZZaeYK3dmbm8S9KEzOUpkrbmnLctcwwAAABlKuV62nOoW21dyeyxpOspFjF6+/kzAhwZjsSv1N386Cbdu2Z3yZ7HD40O0y8DMSIFUpveGOOYvh4wxlxnjFlujFm+d+/eEo0MAAAAR+ODt6/U4i/fq9M//xet231YEtsZhMGYUXFddcokbdvfpT8+u3PoOxQoO/2SUBeIUoa63f60ysz/92SOb5c0Lee8qZljfVhrb7LWLrLWLho3blwJhwkAAICh7G7rVsQx8qy051CPpEyTFBZRlbWIY/TdN56hCaOrVMoZmH4Fl5AfjFL+LbxT0lszl98q6fc5x9+S6YJ5jqS2nGmaAAAAKENWVlXR9EfHZKbVIZW68HCMKdm2Bves3q1v/GWdJCkeJeQHoVhbGtwm6TFJc40x24wx75D0VUkvN8asl3RZ5rok3SVpo6QNkn4k6V+KMQYAAACUjmd7P7D7oS7leXS+DImIMXKPsgXm3sM9OuWzd+tfb31KiZSnRMqTHSQQHupO6l0/Xy5J+uQr56uuKlq0MePoFeVVt9a+YZCbLs1zrpV0fTGeFwAAACPDWqtYJB3qUplwQKUuPIzRUU+/3HqgU4e6U/rDqp36w6r0hLq/P2Oqvvm6Uwec29GTkiRde16L3nnBzKKNF8eGKA0AAIAheVaKR/pV6lxLpS4kjmX6ZWePK0m6eO44LWpp0q+Wb9XG1va85yZS6T8LCyePLs5AURBCHQAAAIZk1Tv98qV9ndrc2qG2rqQiEUJdGKSb3BxdqPvjszskSTdcMVcnTR6t5Zv3a19HIu+5fsBnLV2wCHUAAAAYkrU2W6n75j3r9M170o0x5k6oD3JYOErGGLmetHV/p9p7Upo3sV5mkO0HDnamO1nOyfxuI87g6/F6MpU6f2ougkGoAwAAwJCslcbVV6mhJqq9h3v03ktmy3Gk+ZMagh4ajoJjpPaepC742v2SpFvesVgXzB64bdjGve3avK9TZ5zQmA1qTk6TlRVbDuhQzgb0G1s7JCnbGRXBINQBAABgSP6WBv/zzrODHgoK4BijzoSbvb6vPf90yvf/8hmt2XlIV50yKXssGkmHuk2tHfr77/8t7/3G1MaLO2AcE0IdAAAAhuR56Q6KCCfHMUpmpkpKUlfSzXteRyKluRPq9Y1/7O106VfqDnenK3SffOV8LWppyt5eG49o1vi6Eo0cR4NQBwAAgCFZadA1WCh/jknvK+hbta1Nb1ic50QrzZlYr+pYJHso4hi51mabosyeUK/TpjWWesg4Bkx+BQAAwJCstSLShZdjTHZ/QUm67YmXtG734QHneXl+zxHHKOVaJd30/WNsY1F2CHUAAAAYkrVMvwyzSE6zE79jaVtOwxOfVbqq1/++nrVKZUJdlE6XZYffCAAAAIbkWSuHVBdaxigbyk6anO5Ymm+bgny/Z39Lg2Rm+maUvQnLDqEOAAAAQ0qvqQt6FChUevpl31Dm5Qt13sC1kxHHqLW9R9fe/KQkKeYQIcoNvxEAAAAMyVpLo5SQ232oR1LvRuGpPKHOWjtg+uVrTp+is3K6XVKpKz+EOgAAAAzJWtEoJcTOmN7brdIPda7NN/1SA6ZfLmpp0vf/6UydN2usLpo7TtPHjirtYHHM2NIAAAAAQ0o30CDWhdW5Jzbre/e/KEmKOkeYfmmt8s2ubKqN6xfvPKekY0ThqNQBAABgSJ61rKkLsdxA7nevzN8ohf0Iw4hQBwAAgCEx/TLcIjkL5WJ+o5Q80y/zralD+SPUAQAAYEhsaRBufUOdX6kbeB6/53Ai1AEAAGBI1opSXYjlhjq/e6W/xUGufI1SUP4IdQAAADgqfNgPr0jO787fZ25za+eA81g7GU6EOgAAAAzJs5ZCXYjldrRsqEk3wP/2X9cNOM9SqQslQh0AAACGxIf9cMudfjm+vlovXzAh73kejVJCiX3qAAAAMKiU6+n3z+xQR0+KaXkhljv90hhp/qQG3bN6t6y1Msbo1yu2af2edhqlhBShDgAAAIN6eutBffhXKyVJk0bXBDwaFMrJKb/VV0ezIc+zUsQo+zuW2KcujJh+CQAAgEF1JVxJ0s1vO0vvu3RWwKNBoXIrdWecMOaIHTCZfhk+hDoAAAAMyv/QP6Y2TgUnxEbXxCRJs8bXyRiTnWKZJ9PpUHdyJIeGImD6JQAAAAaVcq0kKUr5JtTG1Mb15L9fptqqiKTe32fK85Ry+/5uz2ppGvHxYXgIdQAAABhUysuEugihLuzG1VdlL/tr7DxPuvanT/Y5rzoWGdFxYfiYfgkAAIBBZUMdlbqKklup236gq89t8SgRIWz4jQEAAGBQKTe96Crq8LGxkviVOtdaudbqgtnN2duqIvyuw4bfGAAAAAblV+oiVOoqit8Nc+PeDiVSnmrjvauyqNSFD2vqAAAAMMDKrQf15p88rs7MlgZ80K8sfsOUa25aJkk6f1ZU157Xon3tCc2b1BDk0FAAQh0AAAAG2LCnXYe6U3rD4hM0a3ydxuc02UD4XXHSRP3gn87UJ3/3nFrbexSNOPrMq04KelgoEF+5AAAAYIBkZi3d+y6dpXecP4M96ipMdSyipQsnasyo9P51NMIJN0IdAAAABvBDXYymGRXN//2yZjLc+FsKAACAARKZTccJdZUtllkrSaUu3PhbCgAAgAH8Sl2cUFfR4plN5anUhRt/SwEAADDA3c/vkiTFInzYr2TVsXQXTCqy4Ub3SwAAAAyQSKUrdVRwKtsHLput06Y16nWLpgU9FAwDoQ4AAAADuJ7VyxdMoOtlhTtzepPOnN4U9DAwTNRZAQAAMIBnrSIEOiAUCHUAAAAYwPUsUy+BkCDUAQAAYADPSg6hDggFQh0AAAAG8KwVmQ4IB0IdAAAABnA91tQBYUGoAwAAwACeZ5l+CYQEoQ4AAAADuHS/BEKDUAcAAIABXI9GKUBYEOoAAAAwgGetInxSBEKBv6oAAAAYIN39kkodEAaEOgAAAAzgeoQ6ICwIdQAAAMhq70npFf/5sA53pxRlTR0QCoQ6AAAAZG070KnVOw/p/FnNes0ZU4IeDoCjQKgDAABAVnfSkyRde16LTpo8OuDRADgahDoAAABkdSddSVJ1LBLwSAAcrWjQAwAAAEB5uH35Vt27ZrckqTrGd/9AWBDqAAAAIEn67J3PK+VaTWms0QlNtUEPB8BRItQBAABA1lp1JV299+JZ+tDlc4MeDoBjQF0dAAAASrierJWqWEsHhA6hDgAAANmul1VRPh4CYcPfWgAAAOiBtXskSXFCHRA6/K0FAACADnenJEnnz2oOeCQAjhWhrgg27m3Xfz2wQT0pN+ihAAAAFMRaK0lqqIkFPBIAx4rul0XwmTuf18PrW3X6tDFacuLYoIcDAABwzLx0ppNjTLADAXDMqNQNU3fS1cPrWyVJXclUwKMBAAAojJep1DlkOiB0CHXDdPvyrdnLftcoAACAsPErdYZKHRA6hLphWLn1oH788Kbs9U2tHQGOBgAAoHD+mjoyHRA+rKkbhnf8bLla23uy13e2dQU4GgAAgML1Tr8k1QFhQ6VuGHID3aTR1frL87vVlaADJgAACJ/eRinBjgPAsQss1Bljlhpj1hpjNhhjPh7UOIplcmON9hzu0a9WbB36ZAAAgDJj6X4JhFYgoc4YE5H0PUlXSlog6Q3GmAVBjKVY/vttZ0mSDnQkAx4JAADAsfNYUweEVlCVusWSNlhrN1prE5J+KenqgMZSFKMzG3V++6/rdM/q3QGPBgAA4NhY1tQBoRVUqJsiKXee4rbMsdD424utg9724Lo9IzgSAACA4WPzcSC8yrZRijHmOmPMcmPM8r179wY9nAGmjRmltyyZ3ufYd994uiSpaVQ8iCEBAAAUjM3HgfAKKtRtlzQt5/rUzLEsa+1N1tpF1tpF48aNG9HBHY1pTaP04cvn9jl21SmTFXVM9psuAACAsGDzcSC8gtqn7klJs40xM5QOc9dIemNAYynY6JqYPnLFXI2rq8oec4yRa0l1AAAgXKy1VOmAkAok1FlrU8aYf5V0t6SIpP+21j4fxFiG6/qLZ/W5bkzv9AUAAICw8KylSgeEVFCVOllr75J0V1DPXyoRx8hj/iUAAAgZz7KeDgirsm2UElaOYU0dAAAIHyp1QHgFVqmrVA7TLwEAQIikXE+S5LqsqQPCilBXZA7TLwEAQEh86Y+r9aOHN2Wv11fx0RAII/7mFhnTLwEAQFi8uLdD4+ur9OZz0nvvzplYH/CIABSCUFdkbGkAAADCwrNWE0dX672Xzg56KACGgUYpReaY9D4vAAAA5c5aNhsHKgGhrsgcY+Qy/xIAAISAx4bjQEUg1BVZxGFNHQAACAdrJTIdEH6EuiLb296jO1Zs07f+sjbooQAAABxRulJHrAPCjlBXZIlUeq+XHzy0MeCRAAAAHJm1ItQBFYBQV2Q/+KczJUkTGqoCHgkAAMCRedaKTAeEH6GuyJYunKh/OHOqPC/okQAAABwZlTqgMhDqSiDqGKVIdQAAoMxZUakDKgGhrgQch20NAABA+fOo1AEVgVBXAlFCHQAACAHW1AGVgVBXAhHHKEWoAwAAZY5KHVAZCHUlEDF9K3XWWnUn3QBHBAAAkAeVOqAiRIMeQCWKRHordd/6y1rdeN8GSdK6L16peJQcDQAAygOVOqAykDBKIOoYJVKeXM9mA50ktfekAhwVAABAX561csh0QOgR6krAZmZebmrt6PMPZUdPSh5r7QAAKLmt+zt158odspb33SOxVjJU6oDQY/plCZx+whhJUlfCVdRxlHDTe9Zd8LX7JUmvPm2y/uOa0wMbHwAAle7Dv1qpJzbt15wJdZo3sSHo4ZQtz1oR6YDwo1JXAjWxiCSpK+mqpXlU9nh1LP1y/+6ZHdq6vzOQsQEAUEy3Pv6S5nzyT1rw6T/rwXV7gx5O1oY97ZKkh8poTEFxPasv37VGd67cMeA2y5o6oCIQ6kqgJp5+WW/41Uq9tL9TF88dp/VfulJrPr9UN197liTpG39ZG+QQAQAoihd2HVLK9dSZcLV+9+FAx/Li3nat3XVYnmc1aXS1JOmvq/cEOqZysHlfh256aKPed9vTA27zrJXDp0Eg9Jh+WQLzJzXotWdM0eHulOZOrNffnzFVsUj6X8wLZ4+TJPaxAwBUBM9aVcci6ky4SrrBvbet231Yl3/7oQHH93cmAhhNeem/zVLuGjor1tQBlYBQVwKj4lF963Wn5b3NcYzmTaxXMuUV/Pg9KVfxiMM/wgCAwLmeVBV1MqGu8Pe24TrQkQ5v58xs0pKZzZKkPz23Uy/sOqxfPL5Fbzp7emBjC1oqJ2zP+MRdOn9Wc/b69gNdmjexPohhASgiQl0AYhHniJW6/R0J/WHVjuw/whHH6JWnTFJzXVX2m8g3nX2CvvSak0dqyAAA5GWtzc5GSbme3vyTx/Xinnbd+q5z1NJcO2LjcDNdLt9/6RwtOXGsJGnuxDq953+e0s/+tjnQUJdyPa3YckCj4lGdPHX0iD+/168DaFfSzV5eMLlBV5w0caSHBKDICHUBiEaMVmw5oNuf3KqrT5+sqmikz+13rNiqL9/1Qp9jn//Dav3wn87Uqu1tkqQH1rLwGwAQPNezijhG8YijJzcf0GMb90mS/uknj+uqUybrA5fNlmetRsV7P3J89s7n9cKuQxpdE9O3X39an9uGMw4p/R7rW7pwkl558iS9sOvQsB9/OP747E69/5fPSJJ+9JZFmtxYrYbqmCY0VCseLf2CNv+L5Bsun6PXnjFVkxtrSv6cAEYWoS4AsYijtq6kPvrrVZowuloXzhnX5/b27vQm5c98+uUyMnrN9x/Vxr0deufPl2fPaa6Lj+iYAQDIx8t0T0y4XjbQSdK2A136wYMv6gcPvqh4xNGDH71Ik0bXKOl6+unfNquuKqr2npQ2tXbopMnDr175oa5/J0fHMQp6GfvBzmT28rty3stfvmCCfvSWRSV/ftdLT4s9eWojgQ6oUPQ7CkA80vuyd+dMgcgeS3mqjjlqHBXX6FEx3Zizp92v3rNEzXXxonyrCQDAcPXvnvieC0/Utee19Dkn4Xr6zVPbdc1Nj+lV33lEkrSoJb2na6pIzVX8KYYRp2+oizqmT6OQIPSk0u/1flXuhsvn6NRpjbpn9e4R2RzdX+oYdViLD1QqkkEAGmp6X/Z8b2abWjv6BL/aqt7zz2pp0uzx9Up5wS1GBwDA51mriDH654tOVNQx+vDlc7V6xyHd+cwOvWHxCXrlKZN05X8+rK/fnd7K59J54zWjuVbnzmrWA2v3Fu39bLDg4pgyCHXJ9OBWf+4KOcbIcYx2H+rRyq0H9dU/v6BPXDn/mB4v5Xq6f+1eTWio0ilTG4c+P/Masx8dULkIdQH44qtP1jkzx+rTv38+75vZ9gNdfRYxT26s1nmzxmppZiFzNGLUlcz/BvXGHy3TE5v2S5LefeFMfeSKeSX4CQAASHM9K8cYfWxp7/vNgskNWvGpl2evj66Jqa0rqVOnjtZP3pber/VvG1olqWjbILiDBJeIo0BD3ROb9uvBdXsVcYyiOV/YfuIV83TLsi36xbKX9Ikr52tTa4fuf2GPrj2vRcYYWWv14t4O9aRcTWsapYbqWPa+f3txX3Ya56avvGLIbtj51hsCqCyEugA01cZ10Zzxkp4f9M3srJam7OWqaES/eOc52euxiDPoG9TKrQe1cMpo7T3coyc3HVB7T0p1VfyaAQClYW163dqR3PvhC7X9QJdOaBqVPRbNdswsVqhL/7//9MuI42Q7YwbhPf+zQvs7EjptWt+K2qh4VG9ZMl0/f2yLfv/M9mwjlXNnjdW8iQ16cN1eve3mJyVJi1uadPt7lmTvu6+jJ3u5I+EO+j7fmUhpw552bdjTLolKHVDJWFMXEP/bMv+bRdez6k66staqK+lqbF3V4Pd1jNp7Ulq945A27DmcnY9vrVVn0tUFs5t1ytTRemLzfi38zN369Yptpf+BAADHJddLT788kua6Kp06rVFjanubfPnvg8k8M1Zcz+ord63Rl+9ac9RVNneQNXVBVupe3Nuu/R0JXb5ggn53/XkDbm/OvNf7gU6SXv/DZfI8qz2H08Ft3sR6bT/Ylb192cZ9+uD/rsxef+alg4M+/7//9jn93Xcf1ef+b7Ukqb6aL3mBSsXf7oD4b2YdPa6e3Lxf1978pNp70l0vYxGjxTmVuv7qqqPa1NqhV9z4sCTp+286Q11JVy/t75S1Uk08ohuumKszp4/RF/+4Rjty3gwAACgmz1oVUgCKZbqrJFKerLXZKYSeZ/XZO5/XLcu2SJJmj6/TPy6aNuTj+V+SDgh1Aa6pO9iZ3hD9dYOMP992Bm1dSX3w9me0aHq6kcycCfW6c+UO3fr4S3rFyRP1hT+kA9rUMTXadqBL//3oJp00uaFPYPYd6EyoZewofeqqBaqvjmn2+Lpi/WgAygyhLiDRzJvZ5zP/OOeaP6lBrz59yqD3/bdXzNflCybqUHdSH71jlX78yCat2HJAUvrNbPb4ep04rk7Tm0bpi39cU5ofAAAAZRqlFNBVsSqWfh989y0rNLY2rm+87lSdMW2Mth7ozAY6SfrIHat07qxmTWyozvs8rme1bOM+ffSOVZI0oGoYcQZfslBqXYl00Bw9Kpb39tymaLnW7jqshZltHt5+/gzduXKH/u23z+rffvusJOmVJ0/SR66Yq4u+8YDue2GPbn50kz50+dwBj+N6Vo2j4rp0/oRi/DgAyhihLiB1VVFNbKjWrkPdA277l4tmacmJYwe9b3NdlZYunKi2zqQ+qlXZQLfy05errjo64E0v4O15AABl4sF1e/W9+zbofZfO1vmzm4vymH6jlGM1a1ydPn/1SbrlsS1av6dd12bWj52b8/537XktuvnRzTrvq/dpZnOt7rvhogGP85k7n9P/LHtJkrRk5liNb+i7fCHipNeWjTTXs7r1iXQ4rYlF8p7Tv1L3pdcs1LPb2vTLJ7fqK39Kfym7YFKDPn3VAt2zerdOaBqluRPrtXThRNXlTKXsSeXvIOp6lm0MgOMEoS4g8aijRz9+iVzP6sKv36+dbb3h7mgbm+S+GdTEIgO+CRyqGxYA4Phy/wt79MTm/brruZ3DDnVdCVdf+dMard55SBNHH/uG1o5j9JYlLXrzOdO1dX+XfvjQi1q2cZ92HOzSSZMbdOs7z9HG1nbd/OhmSdLG1g4lUt6AILRlX2f28m3XnaP+wjtwZwAAIABJREFUjElvPv7c9jYtnDL8Tc4Hs+dwt/7tN8/q3ReeqLNamvTM1gO669ldkjQgaPpyv8D9+zOm6k1nT9f6lsMaWxeXtVJLc63iUUdvP3+G3n7+jAH3X/aJS3XOV+7VbU+8pI9fOW/A+77r2SGb2ACoDIS6AEUco4hjNGt8nXa2deud58/Qml2HNH9S/VHdP5bTmvgNi08Y9LwAm34BAMqIPw3x1sdf0seumDfotMCjsXpnm37+2BY111XpglmFB0RjjE4YO0pfes3JA26bM6FeF80dp/W727X9YJfuWb1b589q7jNu/4vQT1yZfwufy+ZP0E0PbdTHf7NKf3jvBQWPcyhPv3RQf12zR3sP9+j29yzR4e50dfCWdyzW+PrqvPc5cVyd/vOa0/Tg2r26ZnF63d3sCfVHvR3RxNHVmtBQpd2HenSgM6mmfuvqXM/mXbcHoPLwN70MfPN1p+rma8/SJ14xX7945zlH7HyZK3e/m1iUb+IAAEfm5XzLt/PQ8Jpo+Vvy3HjNabrhioHruYqhtiqqn167WP/+yvTm3Nff+pS+dvcLA8axYFKD3n3hiXkfw99K4Lnth/SZ3z+n7px9YIupK5F+3JXb2vSeW1aoO7PheP+g1d/Vp03Rt15/Wp+tjI6FHwAPdycH3OYWuN4RQPgQ6srA+PpqXTx3/LD+4fW7iOXin3EAQK7cUNfRM7xw4+8vFx2k2UcxLT1pov74vvM1pbFGbV3p8LL3cI9+8sgmdSVTih2hGhWPOvr0VQskST97bIue295W9PF5ntXPH9ucvX7/2r1avSP9PNWDrKcrlrqq9OOv2jbw5/I8Qh1wvCDUhdy8iempmtHI4P9oW1qlAAAk5W4J94nfrMruc1qI1CBbCJSC4xidNHm0Gmpi2aYg37lvvb7wh9V6dMM+xY/wHij1dtqUBm8qMhzr9hzWU/32i7vxvg0yRmqsKXyK69GYO7FBkvTe254ecFvqKPYQBFAZWFMXcv5aglieb0r5dxwAkMu1VuPrq5R0Pa3b3a62rqQaR+WfHvjc9jY1VMd0wthReW/3K3WxIQJVMVVFnWwo23Gwt8FYvvfAvvfrrZb1pHorlO09Kf3HPev088e2KOF6qquK6pqzpumTmcre0erMTL380VsWKeoY/c+yLVo4ZbSuPHniUS+pKNSk0b3r9X744It9pqG6VOqA4wahLuT8Ct2R3lRplAIAkNLTL+NRRx9bOk8f/tVKnfb5e/T9N52hK0+eNODcq77ziCRp3RevVDzq6LdPb9Pvnt6hC2Y3650XzFQq03RlJENDVdTRxr3tuuSbD2jj3o7s8Znjao94v9z3yJ7MWrdblm3Rp373XJ/zOhMpPfrivmMeVyITNGvjEZ07q1kXzxt/zI9RqKqoowtmN+vh9a36yp9e0GnTGrONZLqSLqEOOE4Q6kJu0fQmLdu4X/+/vfuMjqu6/j7+PdPUZVm25S73blzAuFBNCRgIoQUCIZAACRBI55+EkoQESCDJExJIoSRACCVAKAm9mWJMcwP3JlsucpNl2ZKsNu08L6ZIsorVRzPz+6zlpZl778w9kq41s2efs/fovMxYD0VERHq4YLin3NShOYwfkMW63RV8+4llvHPDiRQUHyTd42rU6mDsz17DYSDSv7uwpDIc1IUCmcNlyTrT+AFZfFpYCsDUIb04d/pgLpmZT8phKjyeMKYfp03sz5tr9vDX9wp4a+0eUlxOUt0Obj9nMp8WllLjC1BZ6w+vhytn4qDsVo/LFwj/LGJQadIYw2NXzeLhhYXc9vIavvLgJw32t7cAi4jEFwV1ce7/Th/XbNUx9akTEZH6ApZoK53Xf3ACP3z6c174bAcn/+H96DELf3oSQ3rXTbn80tRBpHuc/PfzHdT4gmwrraK4vIZtpaH+cN2ZCfrVOZP5xdmT2nze3hke7r1kOlc/tpSt+yp5ftkOxg/IIifNw4UzhnLhjFA7gYcXFvLu+r3cO38j91921GGf958fFnLUsNxops7TjQHuoa48bgTb91fxyIdbmDdpAOdMGwTADAV1IklBQV0S0OxLERGB0PTL+p/3/eHCqcwemcuCjSV8vu0AOw5U8/qq3Xzl6FCQ86MvjOV7p4wB4K4LpkSzQTN/Mz/6HJG13d2lvUFkqtvJv66cyZItpXz5/o/Zsq+SQYc0Tb/yuBG8vGInb6/dw91vbWDiwGzmTR7AO+v2sHZXBV+bNYxe6W52l9Wwee9BfvnSmgaPj3VPuFvPnsTPz5qohuMiSUhBnYiISJIIHlIN0eEwfOXofL5ydH54rdr73PHKWu56LdQL7tBpjVccO5w1u8p5dmkRAFceO4L+2U031u6pRvXLZFS/DMqq/Rwzuk+j/VmpbvxBy73zNwLwf6eN5e63NhC0oaIk5x85hNP/tCDaWgEg3eOkb2ZKoyAxFhTQiSQnBXXJQJVSRESEUKbO0czU/JH9Mvna7Hwe/2Qb/qDF7TSM6d9wvbYxhlvOnBAN6k4c16/Lx9zZemd4mH/D3Gb3Txuaw/sb9kbv/783N0Rv1/qDBIOWsmof50wbxFdmDGXq0BwyujlbKSJyKP0VSnBaViciIhGBYMuvC3ecewR3nHtEi8+RlerC43Lg9QcZnBP7zFRn+8GpY8hIcXLC2H5kp7o55q53ovv8gWC06ueYvEyOGd23uacREelWCupEREQSXDBoqfUHsbbjfctcTgef/fwL+ALBZnvcxTNjDFefUNfr7Z6Lp7Fs634e/XgrvoCNVv10xbAoiojIoRTUJQFNvhQRSW7XPL6Ut9bsAeCIwb06/HzJNN3wnGmDOXVCfx79eCv+YBBfuOm6S2vXRKQH0cdMCU4vOSIiUlgSatSdmeJi6tCOB3XJxhVuXu4LWPyB7u/PJyJyOMnzUVsSU50UEZHkFghazp46iD9fMj3WQ4lLbkcogPt8+wFOHBsqDhMJ9EREegIFdQlODchFRMQXCOLWdMF2czgM2aku3lqzJzqNNRLoiYj0BPqLlASsVtWJiCS8rfsq+XTzPrbtq2q0zx+wyix10MvfPZ7/d+HU6P2+WYlXJEZE4pcydSIiInEuELTM+9MHVPsCZKa4WPnL0xrM1PAHg6rW2EH5fdLJ75NOnwwPB2v9nDy+f6yHJCISpaAuwelzWRGRxOf1B6n2BchOdVFe4+f7T33Oyh1l3H3RVKbn98YXsHgU1HWKk8bnxXoIIiKNKKhLAiqUIiKS2Hzh3ml52amU1xzkxeU7ATjvbx9xycx8qrx+leAXEUlgCuoSnOqkiIgkPp8/FNQdN7oveVkp+IOWylo/eytqeXvtHnIzPEzP7x3jUYqISFdRUJcElKgTEUlskYbY4wZk8csvTYrxaEREpLtpgn2CM1pVJyKS8HzhhtiaYikikpyUqRMREYlTCzeW8Nd3C6jyBQDwuPRZrYhIMtJf/ySgQikiIonp7bV7WLSllBSXgxPG9uNIrZsTEUlKytQlOs3EERFJWIGgpVeam2eumRProYiISAwpU5cErEqliIgkJH/Q4tQ6OhGRpKegLsHppV5EJHEFgkEVRxEREQV1IiIi8UqZOhERgQ4GdcaYC40xq40xQWPMjEP23WSMKTDGrDfGnF5v+7zwtgJjzI0dOb+0kmZfiogkpICCOhERoeOZulXA+cCC+huNMROBi4FJwDzgb8YYpzHGCfwVOAOYCFwSPla6iNFrvYhIwlJQJyIi0MHql9batQCmceRwDvCUtbYWKDTGFAAzw/sKrLWbw497Knzsmo6MQ1qmRJ2ISGIKBK3W1ImISJetqRsMbK93vyi8rbnt0kWMSqWIiCSs0Jo6LY8XEUl2h83UGWPeBgY0sesWa+3/On9I0fNeDVwNkJ+f31WnERERiSvV3gD3vVdApTfAut3l5KR5Yj0kERGJscMGddbaU9vxvDuAofXuDwlvo4Xth573QeBBgBkzZmgGYQdYqx+fiEiiWLK1lHvfKSDN7cTpMJw4tl+shyQiIjHWoTV1LXgReNIYczcwCBgDLCLUNm2MMWYEoWDuYuCrXTQGQYVSRKR1Kmp8BC1kp7rwBSwel6b09VSVtX4Anr/uGCYMzI7xaEREpCfoUFBnjDkP+DPQD3jFGPO5tfZ0a+1qY8wzhAqg+IHrrbWB8GO+A7wBOIGHrbWrO/QdyGEpUSciLany+jnil28CMDgnDYAPbzw5lkOSFuw8UANAhqerPpcVEZF409Hqly8ALzSz79fAr5vY/irwakfOK62nRJ2IHE55tT96e8eBakCl8nuyjcUVAPTOcMd4JCIi0lNofo2ISJLzBYKNtlX7AjEYibRGiiu0li4rVUGdiIiEKKhLcMYY9akTkRb5g43/Svx9weYYjERaw1pLVqqmXoqISB0FdSIiSS6SqfvLV6ez4McnAbB06/4OPeeiwlL+vWhbh8eW6Cpr/dS0MSsatJpaLyIiDSmoSwIqlCIiLYkEdS6Hg/w+6cwckdvklMyI3WU13PbSmuj6u6Zc+/hSbnp+Jdv2VXX6eBNF0f4qJt36BlN+9WaLP+9DWSwOlTYWEZF6NH8jwellX0SaEgxaVu4oY1FhKVv2VQLgcYX+Yridhhpf80HGyyt28vCHhew9WMuQ3mkY4PqTRpORUveSUlrpBeD9DcVcNmd4l30f8ay4ohYArz9ItS+A29m6z1mDNjS1XkREJEJBnYhIEnpt1W6uf3JZg21p7tBLgsvhwB+oq4i5v9LLC5/t4ISxfRmdl0VZtQ+Al5bvjB4zZUgO8yYP4IONe9leWs2wPuls3VfV5Ho9CQnW+9n4/G3I1FmrHqQiItKAgrpEZ0JTdURE6ttfFcqk/e6CKdT6A2SnuTl6eG8glKnbVVZDeY2P7FQ3DyzYzP3vb2LKkF5MH5rDox9vbfR889fuYd7kAXz78WUcrK0LCAMK6ppV/2fTluDXWlC3CRERqU9BnYhIEoqs4TptUn9y0j0N9pVV+yiuqOWbjy7hmWvmsLBgLwArispYUVSGx+Xg9nMmUVxeS0aKi9teXhPNHHlcDqiFC48awn+WFimoa0H9H423DZm6oLUYTa4XEZF6FNQlARVKEZFDRYK6ptZxLd4Sqny5qLCUJVtKWbWjPLpvQHYqn9x8SoPjn1y0jXW7K9i4p4I0t5MLjhzC7edO5j9LizT9sgVB275MXVCZOhEROYSCugSn130RaYovEAoimgrqrjlhJA+E+9R9+f6PAbjxjPGUV/uYnt+70fHDctOZv66YL/xxAR6XgzSPA2c46ggqqGtW/Sxmm6pfqlCKiIgcQkGdiEgSikz3czsbBwc3njGe4X0zuOn5lQD0y0rhW8ePjAZqh7rva0fx4IJNPL1kOy6Hg2NG9cUZDjqUqWteoF6mrqD4IGP7Z7XqcSqUIiIih1JQl+D0aa6IBIMWR73M2fVPLmPxllJcDtPk3whjDJfMzOfcaYMpLKlkdF5mswEdhNbRfefkMXzn5DGHPE9oiqG1lr+8U8DJE/IYnZfJRQ98wp6yGo4ekcufL5neud9sHLH1grrKesVlDvs4UJ86ERFpQM3HRUQSWGFJJZN/+QavrtwFwK9eWs1rq3aTl5XKdXNHtfjYNI+TiYOyQ8VP2sFpDIGgpbiilj+8tYFvPbqE5dvLWL79AKVVXt5bV9yu5+3pqrx+Tvvj+7y4fCdl1b5mp6DWn3HZlqAuaK3W1ImISAPK1CU4Yxp+GiwiyWVLSSVV3gA3v7CS0kpvtB3Bz784kTmj+nTpuZ2OUFBX7Q0AsLOshoseCK3RG5KTxpZ9leGphIkToZRWejntj+9TctDLr15czb5KL5fMHMqd509pdGz9NXUfb97HN44d0apzqPm4iIgcSpk6EZEE9L1/f8bxv3uHJz7dBsCBKh8/++8qAG49u+sDOggFdWt2lbNqZxkAJ47tx8BeqQDkZacQtPCrl9Z0+Ti60x/eXE/JwVAPwH2Voa///Wxnk8fWr35ZXt2G6ZdaUyciIodQpk5EJMGU1/h4cXkokNheWg3Av781m1F5GbgcDnIzPC09vNMMyE7lg40lfLCxBIBvHDOc/tmpPLesiFMn9OeTzZ/wz4+28MsvTeqW8XSl4ooaHvlwCx8WlJCV6mLCgGwWbSkFoNoXYGVRGUcM6dXgMZGgrl9WCh9v3se764o5aXwe1lqWbdtP0ML63RVMHtyLzBQXo/MygUjzcUV1IiJSR0FdgjOEFtWLSOJbtaOMyx76lP1VvgbbM1NcTByUTa80d7eO55XvHc8Pn/6c11fvBmBobhqj87KYOGgiAN89eTR/ebegW8fUVd5YtZv73ttEusfJJTPz+fHp4wgELU98upXfvLqO55YVNQjqrLVs2F0BwA9PHcvNL6xk+/4qvP4gv/jfKp5avL3ROa49cRQ3njE+3HxcRESkjoI6EZEEcfMLKxsFdABLf34qKS5nt48nzePka7OH4Q0EOW/6YEbnNSzZ73I4sDa0tqyl6prx4GBtaN3g0p99gTRP3c/66hNG8dDCQqq9AV5ZsYu7Xl+LtVC0vzp6zMwRod5/Nb4AS7aUNhnQAdz//ibG5GUqUyciIo1oTV2CM8agOikiyWHdrooG90+f1J9fnzc5JgFdxHFj+vLwN47m7KmDGu1zhXvkNdV421rLqyt38d76nl8h80CVl91l1RgDqe7GL6vpHhevr97N/HV7KC6vZeaI3Oi+Z66Zw7A+GQDU+oKNgvLTJvZn02/O5CszhgJww3+WhzJ1iulERKQeZepEROKctZYDVT68gSA/OHUMM4fnkuJ2MH1o72h/up4o0vi8qQbl6/dUcN0TywBYfutp3T51tLVqfAGOvesdKr0BctLdTValHJCdSmFJJc8v28GQ3mncfdE0jhvdl8paPzNH5EYrFK/YUUZxRW2Dx47pH+oRePHMoTy9JJTBU/VLERE5lII6EZE45QsEKSg+yHNLi/jHwkIAeqd7OGZ03xiPrHVcjlBWy99Epu5gTV01yB37q3tsULe9tIpKb4BLZ+VzUTibdqh/fH0Gk259A4A0dyhrev6RQ6L7IwHaW2v2kJ3a8GX54qPzAZie35vvnzKGe+Zv5O21e5g0KLvTvxcREYlfmn6Z4EKFUjT/UiTR1PgCHHPXO5xxzwf8Y2EhA7JTuf2cSZw7fXCsh9ZqkUzdSyt2cdtLa3gzXFAFwOuvC/RufH5Ft4+ttZYXhdo1zB2Xx9ShOU0ek5Hi4tErZzIgO5Xjx/Rr8pgbvjAWgPIaf7TtQ+SxEVceV9fHbseBujV5IiIiytSJiMSh1TvL2BueqnfWEQM5ZUJeg+xPPMjNSAHg5+H+eQ9/WMjUoTl8aeogRvbNiB63oqiMdbvLGT+g52anxvXPanH/iWP78cnNpzS7/zsnjw5N0fxsBykuB5fOymdhQUmDzF2vNDe/+OJEbnt5TTTLKSIiAgrqEp4xqFCKSAJaunU/AC9+51imDGk6Q9TTnXnEAE6d0J+31+4B4KRx/VhRVMaLn+9gdrg5+o++MJa739rAwo0lPTKoC4bXA3Y0xjLGMCrch27fQS+/Pu+IJo+74tjhpLqdjBuQ2bETiohIQtFHfSIicSjyYc2ofvH75t4Yw8/OmgDAF6cM5JErZjJ7VB/Ka/y8uToU6H11VmhN2R2vrOXh8LrBniQQ/kV0RkuG6fmh4Hxw77RmjzHG8NVZ+Rw1LLfZY0REJPkoU5fwjFbUiSSgyJozjyu+P5sb3jeDDXecgSscFPVKc1NYUgnAJTOH0jczhctmD+OxT7Zy7zsbuXzOMFzOnvM9B8KZOmcnVKM8ZlRf/nv9sQzITj38wSIiIvUoqBMRiTOVtX627KsCiAZD8ax+YHrNCSPJz00HQmsFAW4/dzIAj32ylTE/e42fnD6eb88d1f0DbULQRqZfds7vYVozxVZERERaoqBORKSHs9ay40A1g3PSQtPv/v5JtOpiovUrG9Yng2tPbByw/fALY3E5DW+u3sOf3t7AhwUl/POKo2OetYtk6hIhuBYRkfjVc+awSJdQoRSR+OT1B9kWzsbd+do6jvvtu4y46VXmr90TDeiSSW6Gh1vPnsRvL5jC+IHZLCwoobTKC0B5jY/5a/dQXuPrsvNf8cgijr3rHf73+Y7o9FCoC+p6cpN3ERFJfMrUiYj0MAeqvPz29fX8e9E2fnz6OB5csDm67+YXVkZvj6hX9j9ZHDemL/sqa/n+U5/z7NIirjhmBKf/cQG7ymoAOGZUH+679Ch6pTduVl7jCxC0lnSPi2DQtikQe3f9XgC+/9TnAGy56yygc9fUiYiItJeCugQXepuhVJ1IvFiypZQv3/9x9P7v31jfYH/JwVB2avkvTiPN4+zWsfUUw/qEgtnfvb6e99bvjQZ0AB9t2sfiLaU8tLCQsf0zue6k0TgdhgNVPs64ZwG+gOUHp47h/vc3Ma5/Ft+eO5p5kwe0eL5I24L6/IEgLqejU6tfioiItJemX4qI9CC7y0MByvdOHs3Rw3sDMKxPOh/deDLT83MYk5fJudMG0SvdHfeVL9tr2tAcnvv2MQAsKiylb6aH28+ZFG1Y/uCCzXy8eR+PfryV2XfOZ8Ydb/Pkp9vwBUIB2J/e3kiNL8jyojKufXwppZXeFs/nDQQbbfvf5zuBen3qlKkTEZEYUqZORKQHiSSFvjRtMN+eO5qfPLeCc6cNYlBOGi9cd2xsB9eDHDWsNxt/fQaBoMXlMLicDk6bNIBZv5nPoi2l0eMia4of/jDU4+6rs/J5e80eeqW5+ebxI/jpcyv51Uuruefi6c2eq9ZfF9TlZaVQXFHLn+Zv4O21e3ht1W5AhVJERCS2kvNj3iSiQiki8cVGSuQbSPM4+fMl0zllQv8Yj6pncjsdpLqd0QqY/bNTWfDjk5o9/v9dOJXfnHcEi245lbd+dCLnTR+Cw8Cbq/dw+8trmnzM//1nOWfd+wEQaq2w6JZT+e7Jo0lzO9m09yBOh2FwTpoKpYiISEwpUyci0oNE+55pOl+75PdJZ1S/DDbtreSn88ZzsNZHuseFx+ng3GmDGhzrcTm4/2tHcdvLa3h91W5+/sWJDfYXFFfw7NIiJgzM5sKj+nDSuH4A3HDaOG44bRwQmn4Z0CdnIiISYwrqEpzBKFMnEkciy7dUeKP9/nrpkSwqLOWy2cMO28fvtEkDWLBxL6+t3N1o35tr9gBw0xnjOWFsvyYf73AYHOh3JSIisaXplyIiPUgkU6dEXfuNH5DN5XOGt7oxe5rbyb5KLw+8vyk6/XXjngp+93qo8ujskX26bKwiIiKdQUGdiEgPYjX9stuleUKTVu58bR1PfLoNgD3ltQB8/5QxSVtlVERE4odeqRKcMWDVp04kbmj6Zfe76rgRfOek0QD86qXVAPiDoV/EieOannYpIiLSkyioExGJgdJKLzPueIufPLu8wXZNv+x+vdLc/N/p47hu7ih8AYu1lkC4t4RaFYiISDxQUJfgDGppINIT7TxQTclBL88sKWqwXdMvYycr1Q1AjS+IPxzUKWMqIiLxQEGdiEgM1G9oXeMLRG9HMkQK6rpfmjv0knj7K2vqZer0MikiIj2fXq0SXGurv4lI9/LWC+r+/M7G6O1wLIFT/3e73YzhuQA8+ek2av2hQFuZOhERiQcK6pKAZl+K9DzeQF1Qt6KoLHo7uqZOf5273eTBvbjpjPEAVNaGgjqtqRMRkXigtw0iIjGwuLAUgL6ZHj7YWMLSraH7kTWwmn4ZGynh9gVVXj+gTJ2IiMQHBXVJQIVSRHqWihoff3m3AIDvnTIGgG/9ayl3vraWQLRQSsyGl9RS3U6AaL86l1O/CBER6flcsR6AiEiyqfKGpvZdN3cUl88ZTo0vwG9eXccD72+OHqNMXWykp4ReFrfuq2LCwGx6p3tiPCIREZHDU1CX4PS+UKTn8YXX0w3vmwHA1SeM4qhhvbngvo8B8DgdeJyaSBELJ4/P47ZzJnHmEQPpm5kS6+GIiIi0ioK6JGBVKkUkpvYdrGXBxr3RqdA56aF+aO56U/uOGpbL3RdNZVtpFVefMBKH5l/GRGaKi8vnDI/1MERERNpEQZ2ISBe7771N/GNhYfR+72hQ1zAbd/6RQ7p1XCIiIpIYNL8nwRkDe8preH/DXj7ZvC/aUFdEuk9FjZ++mSm8/+O5HD+mL/urfIAaW4uIiEjnUKYuwWWluPmwYB8fFuwD4KGvz+CUCf1jPCqR1jlQ5eWm51ficjr42qx8Zo3sE91nraWs2kdOHBSyqPUHyEhxMqxPBrkZdeP1uDTFUkRERDpOQV2C+9dVM9m6r4rdZTVc/+Qyymt8sR6SyGFZa7nyn4t5d/3e6Lb9ld4GQd0dr6zloYWFPPmtWRwzqm8shtlqtf5gtP/ZrgM10e1De6fHakgiIiKSQDT3J8H1zUzhqGG9mTq0FwA+v6ZfSs8XCNoGAR3AwoIS7nxtLR8VlFDjC7B4S6hZd2FJZSyG2Gq+QJDXVu3GEw7qzjtyMH0yPHzwk5MY0z8rxqMTERGRRKBMXZKIvKH0hkupi/RkzS39fOD9zQ16uQHc8sIqnlq0nVMn9Gfe5AGMG9CzAqWNew4CoaqKAJfMzOeSmfmxHJKIiIgkGAV1SSLS88qnoE7iQDBc+//Hp4+jaH+oCfQTn2xj5ohcKmp8uJwOBvVKZXNJJa+t2s3KHWWs3FHG1tJK7r5oWoxH31Dkg5SrTxgZ45GIiIhIolJQlyQipdOL9lezbnc5o/plNiqnLtJTRPq5OR2GO8+fAtBs7zBrLf6g5fQ/LsDr73kfWkTG5HE6YzwSERERSVQK6pJEisuBx+ngoYWFPLSwkOvmjuIn88ZH97+3vpiSg97ofbfTcOqE/mSk6BKR7hcIR3Wt6b9tjMHtNDgdpke27IgGdS59iCIiIiJdQ+/Yk4TL6eDZb89h54Fqfv6/1ew8UB3dV1xewzceWdzoMb8+bzKXzhrWncMUAepxrVrmAAAgAElEQVSmXzpM60v+99SgrtLrBxTUiYiISNdRUJdEpgzJYcqQHO6dX8DiLfu58bkVGEO0HPwtZ05g3uQBlNf4OOvehT1yKpskBxu+9NoS1LmcPTOo+96/PwMg3aPplyIiItI1FNQloRPG9uOFz4p4d30xxRW1bCmpAiAvO4WhuemUVYV62dme9/5YkkSwDdMvI5wOB/4eGNQ5jGFQr1TG5GXGeigiIiKSoDQfKAndeMZ4Pr35VD69+VT6Z6VS5QsAdcVUCL+R7nlvjyVZRIO6NkR1rvD0y0DQdjjLXFbl443Vu/Efplrsmp3lXPPYEp5evK3ZYyyWL04dhGlD1lFERESkLRTUJTm3y1DjDQV1zrakRUS6UCTh1pZAyOkwbC2tZPKtbzD2Z69xz9sb233+372xjmseW8onm0tbPO7d9cW8sXoPDyzY3Owx/oDFpf9bIiIi0oUU1CU5t9NBdTRTF3rjGXkfbTX/UmIkkqlztmVNncOwvbQ6ej1vLK5o0zkra/3c9PwKXl+1m6L9oUJC+yprW3yMPxAa5+a9lWwvrWq0P9JuwaX2ISIiItKFtKYuybkdDipqQq0MnA698ZSeoX1r6hoe3JopmKt3lvHdf3+G1x+MBnLPLCnipHF5ANz12jruf38zfTI8/OPrM0h1Nyx2EgjWneOBBZu449wjGuyPrPFzK1MnIiIiXUjv4pOc22WoDk+/jLzx1NtPibXI9Mu2VL88Y/JApg7pxdxx/RjbPxNfIEhlrZ/73tvEX98tYH+lt9FjVu8sZ/PeSiYP6sWFRw3B43TgMOAPB2uTB/fC5TAsLChhR702IBGBetnsZVsPsGZnOXe/uZ4VRQcA8IXX5ClTJyIiIl1Jmbok53Y6OFgb6qMVyXRE1jFp9qXESjAc1bWltshXZ+Xz1Vn5AFxw30d4A0E+2FjCb19fB8CqHWXc97WjGjwm0gLhl1+axIBeqYwfmM3tL6/hvfV7OWJwL/5++QxeX7WLax9fRq2vcebPH7SkuBycNC6P11fv5sx7PwDg5RW7uHzOMLzhoC4ytVlERESkKyioS3JXHjuCN3vvITPFxeTBvWI9HElSu8qqOf9vH3HHuZM5ZUL/6AcKbcnU1edxOjhYG+BAVV12bv2exmvs/NFMWug8l87KZ0xeJoGgZUz/UAuClPCUyxp/oNHjA+EiKDedOR63y0FhyUFqfUE2Fh/kly+tiR43OCetXd+HiIiISGt0KKgzxvweOBvwApuAK6y1B8L7bgKuAgLA96y1b4S3zwPuAZzAP6y1d3VkDNIxZ08dxNlTBzXYFnkbbdXUQLpJQfFBdpXV8MiHWzhlQv+6QintXIuWkeLk4837WL49NA1y9shcdpfVNDrOF4iseQtNj0x1OzlhbL8Gx6S4QvuKyxsXTfEHLU6HYVifDP58yXQgVBylrNqHtaG2IE6HoVeau13fh4iIiEhrdHShx1vAZGvtFGADcBOAMWYicDEwCZgH/M0Y4zTGOIG/AmcAE4FLwseKSJLZVVbNmp3lrNlZTkHxQQA27z1IjS8QnRLc3tZuN585ga/PGRa9n5nibrIxeWT6pbOF6ZF5WSkAvLF6d6N9Qdu4sqUxhpx0D70zPORmeBTQiYiISJfrUKbOWvtmvbufAF8O3z4HeMpaWwsUGmMKgJnhfQXW2s0AxpinwseuQXqMupYGsR2HJK6yKh/H//bdRoHWzrIaxv/89eh9TzsLjIzsl8mvzpnM4i37KTlYS3aai0DQ8vqq3cwakUvvDA8AvnBBlJb6yI3Oy6J3upsPC0r47r8/48enjSO/TzpQl6kTERERiaXOXFN3JfB0+PZgQkFeRFF4G8D2Q7bP6sQxSCdSTCddZX+VF3/QcsWxw5k1IpddZTXc/eYGKsIZup/OG09GipMTx/U7zDO17OXvHgfALf9dya6yGq59fCkXHjWE3184FajrM+c+TPB41LDevL22mJeW72TjngqG9E7H4zK8vaaYnHRl4kRERCS2DhvUGWPeBgY0sesWa+3/wsfcAviBJzprYMaYq4GrAfLz8zvraaUVjJoaSBeLFB05engu8yYPBOCCo4Ywf+0e8nPTOWpYbqecxxHOotXPpv1naRGpbieVtX7W7CoPHXeYS/6vlx5JcXktt7+8hqL91WwvrYoWXok0OxcRERGJlcMGddbaU1vab4z5BvBF4BRroxP2dgBD6x02JLyNFrYfet4HgQcBZsyYoaRRN9L0S+lsK4oO8PyyHVw2ZxjV3gCLCksBSHXXZciyU92cN31Il5zf5WiYiXvsk60ADM1N49QJ/aNtPJqT4nIyNDedBy+fAUCV18/EX7wBwLfnjuqCEYuIiIi0XkerX84DfgKcaK2tqrfrReBJY8zdwCBgDLCIUGHFMcaYEYSCuYuBr3ZkDCLS8/3r4608u7SIf360pcH2FJezW85fP1M3eXA2A7JT+ctXjyTV3b7zp9V73LnTBrdwpIiIiEjX6+iaur8AKcBb4U+6P7HWXmutXW2MeYZQARQ/cL21NgBgjPkO8AahlgYPW2tXd3AM0kXU0kA6S2V4rdyhIr3gulqkEEqKy8HL3z2+w89njOF3F0whYC2D1INOREREYqyj1S9Ht7Dv18Cvm9j+KvBqR84r3UPTL6UzfLJ5H5v2HmTa0Bwe/+YsPt28j6seXcJ50weTl5XaLWOIZOram5lrykVHDz38QSIiIiLdoDOrX0qCaG9vMJFDWWu54pHFVPsCfGnqIDJTXJw8Po/7Lj2SWSP7dNs4JgzMxuUwHD28cwqwiIiIiPQkCuqkEVW/lM7yhzc3UO0L8L1TxvC9k0OJfWMMZxwxsFvHcfbUQZw9dVC3nlNERESku7Svs6+IyGE8vXgbf3m3AIC54/rhamcjcRERERFpmd5lSSN1LQ20qE7a7zevrgPg+euO4cj83jEejYiIiEjiUlAnzVJMJx1R6w9w9QkjFdCJiIiIdDEFddKIVtRJRwWDlhpfsEE/NxERERHpGgrqpFlK1El7vbJyFwDpHgV1IiIiIl1NQZ00YtTTQDpo9c5yAM7s5iqXIiIiIslIQZ00EgnptKZO2qvGFyAr1cXQ3PRYD0VEREQk4SmoE5FOV+sPkKr1dCIiIiLdQs3HpZFoSwOtqpM2CgYtf323gMVb9pPq1mdGIiIiIt1B77qkWZp+KW1VuK+SP7y1gaL9VRw9LDfWwxERERFJCsrUSSMqlCLt5Q+EPgm4+6JpKpIiIiIi0k2UqZNmKVEnbRUIhq4ahz4YEBEREek2CupEpNNEgjqnQ0GdiIiISHdRUCdNMgYtqpM2C9hIUBfjgYiIiIgkEb31kmYppJO20vRLERERke6noE6apLfk0h5Bq+mXIiIiIt1NQZ00S7Mvpa2ia+qUqRMRERHpNmppIE1qqa3Bqh1lfLCxBIDjx/Rl8uBe3TUs6eGCKpQiIiIi0u0U1EmTDGCbWVX3uzfWs2DDXgA+3tyPf105sxtHJj2ZX0GdiIiISLdTUCfNam76ZWWtn9kjcwlaqPEFundQ0iNVef1U1Pij1S8dCupEREREuo2COmlS/dmX1d4A/mCQrFQ3EArkctJS8QaCHKz1x2iE0lO8smIX1z+5DIAjwlNxtaZOREREpPsoqJNmRRJ1F//9E/aW1/DRTaewq6ya1TvLGd43g2Ct5WCNn7P/vJB9B2ujj0vzOPnnFTMZmpsem4FLt9paWhm9vXJHGQBZqfrTIiIiItJd9M5LmmTqNTVYvv1A9PY9b28EYEhOGoUllWwtrcLrDzJrRC75uensq/TyzrpiNu09qKAuSUSm6b79oxMorqglO9XNyH6ZsR2UiIiISBJRSwNpmml6TV2lN0BWioufzhuP2+nA6w8CcNVxI/j9hVP5zsmjATUuTyaRNgbD+2RwzChVQxURERHpbgrqpFkWy8srdjbY5vMHGZiTisNhcDnrsnnpnlDS19Q9WJJEQBUvRURERGJKQZ00KfL2fEVRWYPtvkAQjyt02fTPTo1uH9ArdDvS3665dgiSeILWYkzLvQ1FREREpOtoTZ00zxKdXhnJwngDQdzOUFD303njuXRWPukeF/2yUoB6mTpJGoGgVbVLERERkRhSUCdNirxHrw0HdYGgZd3ucsqrfaS4nUAo0BvWJ6PJxzXX404ST8Ba9aUTERERiSFNv5RmWeoydQDz/vQBy4vKyEpp/rOASNVMBXXxZf7aPTy0sDC6Pq4tgsrUiYiIiMSUMnXSJIPBWsvKHQfIy0rhtnMmR9/wT8/Paf5xkUxddwyyh7PWxs06s6seXQLArBG5ba5eGbSgRJ2IiIhI7ChTJ02KxCL+gKXGF2De5AGcNWUgZ00ZyKCctMM+3iZhqm71zjLeWL0bgN+8upYRN73K+xv2xnhUbVPrD7S4PxC0vLJiF9v2VTXYpumXIiIiIrGjoE6aZW2osuHccXmtfkyyZuqstZx170KueWwp+yu9fLZtPwAbdlfEeGRt4ws0/Zur8QX4qKCERz4s5Ponl/H9pz+L7gtaq3YGIiIiIjGk6ZfSpMhbdF/ARlsYtO5xybmm7vllO6K3j7zjLVLCP7OKWn+PnIbpDwR5aGEhJ43PY2z/rOh2XyDY6NiC4gq+9JcPqfLWZfE+23YgelvVL0VERERiS5k6aZalYQuD1jBJ2H28sKSSG/6zHIDzjxyMtVDjCwVH987fyJhbXmN7aVVLT9HtVu8s587X1vGTZ1c0mCrbVFB3zWNLowHds9fOYebwXACm3/Ymx971Di98tkPTL0VERERiSJk6aZIF/vXxllCmztn2N+zJlKm75rFQkZFrThjJ12YPa5C1+9LUQby4fCf//GgLP//ixGafIxi0bCutIhj+wQ3slUaax9llYz5Y6wfg8+0HGlS8bGr6ZUWNP3p7xvBc/vLV6fxp/sYGlVGPzO/dZWMVERERkZYpqJMm1Z9q155MXRLFdGwJFw35v9PHsb/SG91+yvg87r1kOi8u38lDCwtbDOruX7CJ372+Pnr/mFF9ePJbszt9rAdr/TiNYXlR3fTJL9//cfT2NY8t5dlr5zAjnI2D0Hq6YX3SuemM8QDkZafym/OO6PSxiYiIiEj7KKiTwxqdl9nqY5NyTZ2Fa08chdvpiDZmh7pg+OTxebyzrhh/IIirmQC5pMJLisvB7748hSc/3cbiLaX42jj1tSX3vbeJBxZs4kCVr8H2AdmpeP1BRvbNYHNJJQAvr9jFjOG5fFRQwrPLijhY6+drs4cxb/LAThmLiIiIiHQuBXXSogcuO4rTJw1o9fF1mbrkiOqstfiCQdzhKaqZKS6OzM9h2bYDjO0fCoaPG92Xd9YV88Sn2/j6McObfJ6gtaS6nZwzbTBrd1XwaWEpP31uBXdfNK1Txvlp4T4cxnDFscPJy0rF5TDMHJHL1KENew7OuONtvOF1df/8aAvvri9maG46R4/IbeppRURERKQHUFAnLUppQ+VLqKuamSyZukDQYm1dVs7pMDx/3bGhipDh4iGRwOmB9zc1G9T5g8Ho8decMJL7399EcXltp45zeJ90bj17UovHpbgc1HgD/OODzazeWc70/N48c82cThuHiIiIiHQ+Vb+UFrkcbQzq4mhNXUFxBcXlNR16Dn+4yIjrkGIy9fu2HTWsN5fMzMfbTA84oEEQ2DvDw+yRuQ0KkXSUP2Bb9btMcTlYtbOMO15Zy66yaqbn5xz2MSIiIiISW8rUSYva3lQ6sqau54d1p969gAkDs3nt+8e3+zkiLQDchwmYUt0OanyBZvcf2uvN43JSVu1r9vi2qh80tsTjcrBhT6hh+lNXz2Gmpl2KiIiI9HgK6qRFh2agDideelBHyviv3VXe7udYtm0/b63ZAxz+55TqdkbbCDTFf0jQ5XE6OjdTFwyS4j78f/drTxzFu+uLyUp1MWVIr047v4iIiIh0HQV10qK2ZuriZU3dHa+sid6+7omlXDhjKCeNy2vTc9z12joWFZbichhG9M1o8djImrs7X1vLTWdMaLQ/GLQNAkOPy7C3ooa/L9hMeoqTi2YM7VAlzEDQ4mhFxH3u9MGcO31wu88jIiIiIt1Pa+qkRa62BnXhwKGnVr8s2l/FVf9czCMfbgGgT4aHt9cU89SibdFjdpVV8/2nPmPNzuazeGt3lbOosJQzjxjAhjvOYO5hAsKvzcoH4KlF25vc7z9k+uXIvpmUHPTy61fXcssLq1hcWMo76/bwzJLtrNpR1tpvNypgbZt/lyIiIiISH5SpkxYlUqautNLLX9/dxPx1xQCM7JfBOzfM5Yt//gBfvSImCzbs5X+f7yTd4+TO86c0+VxvrN4NwKkT+uNoxc8oLzuVK44dzrNLiwB4c/VuivZXA6GfccnB2gY/6xtOG8u1c0exfncFF9z3Ef9YWMg74XGPzsvk7R+d2Kbv3R9o3Zo6EREREYk/CuqkSV+Y2J8NeyoYnJPWpsdFq1/2wKDuoYWb+Xe9jNwp40PZNbfTgS8Q5M3Vu/nv5zt4dWUoYHt15e5mg7pgeE3e+UcOafX5I+ep9ga45vGljX5G4wdkRW8bY8hMcZGXlQIQDehOHp/HhwUlWGujWdHDOVjrZ1tpFSP7tTxFVERERETik4I6adLfL5/RrseZSPXLzhxMC6y1bN1XRY0/QLU3wKi8TLJT3U0eW1btIyfdzQc/OYk0txNXeI2ax+mg1h/koYWFfFpYGj0+Erg1JWjbnsV0Ow2+gKXK68dauPGM8VxydD5XPbqY5UUHmDy4cWGSvOyUBvcDQUutP8jXH1nMv66c2arzXvC3j6jyBkhrRaEUEREREYk/epcnnaouU9c9Yd1Hm/Zx6T8+jd7/1vEjuOWsiU0eu3VfFZkpLrIOCfo8LgcHa/0Eg5YTxvbjDxdO5YH3N/FkvazeoQLW0tbZjG6ng0DQUh1ubZCT5qZXuptnv31Ms49JcTn5yoyhPL1kOw4D+ypDDckXbNjLY59s5bLZw/hg415eWr6TWSP6cMFRjTOHOw9UM3dcP34yb1zbBiwiIiIicUGFUqRLdFemrrTSC8AvvhgK5B7+cAtXPLKo0XHF5TV8sLEEj6vxJe9xOvhs2wGqfQHS3U76ZaXgdjmiPeiaEmxlNcn6ItUrK2tDQV2q29mqx6W4Q49zOR0cUS+bd/97myiuqOGRD7fwzJIi7pm/sdFjrbVUev1MGpRN/+zUNo1XREREROKDgjrpVNE4p5uiumA4I3jiuH488o2jmTy4F++u38v20ioe+3gLTy/eRpXXz6srdwFwxbEjGj2HLzzNcsOeg6R5QoGWx+nAF7DNTsFsbTPv+tzhlgXXPr4UgJQmAsymeOpNE73xjAk8euVMvj13FDsOVHPK/3s/2tQ82ER29KNN+whaSPcoKS8iIiKSqPROTzpVd7c0iDQRdxrDSePzWLWjjOXbD/Ctfy1h3e6K0D6Hg0pvKPD5chOFTWaNyGXBhr1AXfXOSEbPFwyS4micUQtaGrQgaI2Tx+fx+fYD+AKWIwb3Ysbw3FY9LjIWp8PQK83NiWP7cWR+Dnsranl2aVH0ewscEoDW+AJ889ElAJw4tl+bxioiIiIi8UNBnXSq7m5pEA3qwlmzSKC0eW8lw/uks2VfFTc/v5LZo/rgMEQzcfWl19s2c0To8ZHs2F/f3cSPvjC20WOC1tLGmI7ReVn87dKj2vYgiFbAHNirbvpkVqqbCQOzAThY4wMaB3XLtu6n2hdg0qDsJouwiIiIiEhiUFAnnSpaKKWbzheZchjpFZeb4QHAGwiSl53KkN7pLCwoYcGGvfROb7oqZv1gKSMl9F/i2NF9Abh3/kb+vmAzGSkuXv7ucQwIH9ue6Zftdfmc4Zw0Po+8rIZr4iLTNw/W+qNjqq8qnMG78/wjumGUIiIiIhIrWlMnnSra0qDb1tSFvkamQg7pncb4AVnkZaVw/Oi+PP7NWVxw5BDG5GVyzYmjmnyO0ycN4PZzJnHWlIHMCmfqJg7K5uRwH7tqX4CSg7UU7a+qd97uC+ocDsOwPhmNsoyRoK6sOpypO+SHXuMPBXVprSzIIiIiIiLxSZk66VR1mbruXVMXia8yUly8/oMTGhzzh4umtvgcxhgumzOcy+YMb7C9yhvKgM0emcsnm0vxBeq+p2Abmn93lb7haZk1vmD4a4AbnlnO9PwczjxiIDc9txJofZVNEREREYlPCuqkU3X3mrpDp1926nOHOxqMH5DNJ5tL8QfrWhwEgrbNhVI629yx/Zh/w4nU+oI8tXgb//p4K88tK+K5ZUUs336Ailo/A3ulNmpgLiIiIiKJRUGddK5uXlNXv/plpz93OGDMSg39N/HXy9QFgnTb9MvmGGMY1S8TaDzF8j9LiwB48luzSXEpUyciIiKSyBTUSacy0aiue8K6yJq6rsjUzZs0gKVb9zOyXwYAP/vvqmjz7xVFB3A6YxvU1dfc95/RRLVPEREREUksCuqkU3V79ctD1tR1pm+dMJKvHzOcwpJKAHYcqMYfDJKT5iEr1c3xY/p2/knbyVXvB+BxOvAGQlNFM1P1X1xEREQk0ekdn3Sqbu9TZxv2qetsHpcDV72M3P+dNo4LZwztknN1RLqn7r/y89cdw57yGnpneBpsFxEREZHEpHd80qkiFSFtN0V1+6u8ADi6sGjJoF5p0dseV8/sAnLZnGGM6JtBRopTzcZFREREkkzPfIcqcSsSWv3ypTVsL61q8diOqvYGeOD9zUDD6YedrX5/OI+zZ/6XyUxxMW/yAI4f0y/mrRZEREREpHv1zHeoErd6pbmZnp8DwIqisi49V0VtqOn22VMH4eqmYKunZupEREREJHnpHap0KofD8LsLpgBd34A80jZuzsg+XXoegPRwti5N1SRFREREpIfRmjrpdJHpf8EuXlZXVySla88D8Pg3Z1Gw5yBHD8/t+pOJiIiIiLSBgjrpdI5oq7rWRXXWWgpLKgmGj8/NSCE3w3PYx9W1M+j6NWRH5vfmyPzeXX4eEREREZG26lBQZ4y5HTgHCALFwDestTtNKFVzD3AmUBXeviz8mK8DPws/xR3W2kc7MgbpeRzRTF3rgronPt3Gz/67Kno/K8XFZ7/4wmHXyfnDQZ2rBzUBFxERERHpbh2duPZ7a+0Ua+004GXgF+HtZwBjwv+uBu4DMMbkArcCs4CZwK3GGKU/Ekw0qAu27vi9FbUA3HvJdM6bPpiKWj+1/sM/ONCNmToRERERkZ6qQ0Gdtba83t0MiFbGOAf4lw35BMgxxgwETgfestaWWmv3A28B8zoyBul5IjFWc5m6ZxZv56L7P2Z3WQ0A/mAQp8PwpamDmDIk1F/NFzh8UBfs4sbjIiIiIiLxoMNr6owxvwYuB8qAk8KbBwPb6x1WFN7W3HZJIA5HpAF50/v/8NZ69pTXsnZXOQN6peIP2GifuUjLAG8bMnVOZepEREREJIkdNqgzxrwNDGhi1y3W2v9Za28BbjHG3AR8h9D0yg4zxlxNaOom+fn5nfGU0k0cTWTq/vDmev78TkGD47zhbJw3EIw29XaHv3oDQXyBYDQwdDlMNFiMiE6/VKZORERERJLYYYM6a+2prXyuJ4BXCQV1O4Ch9fYNCW/bAcw9ZPt7zZz3QeBBgBkzZnRxcXzpTI4mWhqs311B30wPXn+Q8ho/UDfF0h+w0WInKeFM3W0vreHNNXsaPO93Tx7NwF5pfHVWKMiPBHUuBXUiIiIiksQ6tKbOGDOm3t1zgHXh2y8Cl5uQ2UCZtXYX8AZwmjGmd7hAymnhbZJAmlpTF7SWvKzUaEAH9YK6YDBa6TIvKxWAN9fsIdXt4Menj+PY0aHm4n9+p4CbX1jJgSovUNenTpk6EREREUlmHV1Td5cxZhyhlgZbgWvD218l1M6ggFBLgysArLWl4TYIi8PH3WatLe3gGKSHiWTqrLUEghZDKGt3aEETnz8UlC0sKCGyZ86oPswY1pslW/eTk+bh+pNG4zCGDwv2RR8XWW+3YMNeQJk6EREREUluHQrqrLUXNLPdAtc3s+9h4OGOnFd6tkiIVVB8kFE3v8qgXqmMysvk0Njrhc92cKDaS06ah73+2uj2CQOzWbJ1P73S3ACkuRsmlCNr8SprQ1k/NQUXERERkWTW4eqXIoeKZOoe/XgrADvLahjcO63BNMmR/TL4bPt+Pt68j76ZKRw1LCe67+oTRpKfm870/NC29JSGl6kvYKNfs1NdZKToMhYRERGR5KV3w9LpmmoG7vUHo5UtAd7+4Yn8b/kOfvj0ckoraxvsG5qbzrdOGBm9f9rE/pTMG4e18Ps31uMLBNlSUsn+Km+0BYKIiIiISLJSUCedztSLs3IzPJRWevEGLCmuumDP4TBkpoSmVwYtLQZnOekerps7mrfC1TCXbNnPzS+sBGBgr9Qu+A5EREREROKH0hzS6epn6tLcTgC8/gCOQ662qUN7RW97nIe/FNM9oeeKBHRAgwyfiIiIiEgy0jti6XT1C6Kkhouc+AK2UfXLvKxUvnX8CKCuP11LZo7I5Z6Lp3Hn+UdEg8BIfzsRERERkWSl6ZfS6Rpk6sLZNV8g2ORau6/NHkaq28k50wYf9nndTkf0uE837+O/n++MZu9ERERERJKVgjrpdPWDt3R36BLz+kNB3bfnjmLNzvLo/mF9MrjhtHFtPseVx40gxeXk+pNGd3zAIiIiIiJxTEGddDqPy8Fd5x/BzrIaslNdLNpSijcQxOkw/HTe+E45x5QhOUz5cs7hDxQRERERSXAK6qRLXDwzH4D/fb4DqMvUiYiIiIhI51KhFOlSkeIotf4gKlQpIiIiItL5lKmTLjVxYDaTBmVT4wtw/Jh+sR6OiIiIiEjCUVAnXWpkv0xe+d7xsR6GiIiIiEjC0oQ4ERERERGROKagTkREREREJI4pqBMREREREYljCupERERERETimII6ERERERGROKagTkREREREJI4pqBMREYZkCXIAAAXhSURBVBEREYljCupERERERETimII6ERERERGROKagTkREREREJI4pqBMREREREYljCupERERERETimII6ERERERGROKagTkREREREJI4pqBMREREREYljCupERERERETimII6ERERERGROKagTkREREREJI4pqBMREREREYljCupERERERETimII6ERERERGROKagTkREREREJI4pqBMREREREYljxlob6zEcljFmL7A11uNoQl+gJNaDkISj60q6gq4r6Qq6rqQr6LqSrpAI19Uwa22/pnbERVDXUxljllhrZ8R6HJJYdF1JV9B1JV1B15V0BV1X0hUS/brS9EsREREREZE4pqBOREREREQkjimo65gHYz0ASUi6rqQr6LqSrqDrSrqCrivpCgl9XWlNnYiIiIiISBxTpk5ERERERCSOKahrJ2PMPGPMemNMgTHmxliPR3o2Y8zDxphiY8yqettyjTFvGWM2hr/2Dm83xph7w9fWCmPMkfUe8/Xw8RuNMV+PxfciPYcxZqgx5l1jzBpjzGpjzPfD23VtSbsZY1KNMYuMMcvD19WvwttHGGM+DV8/TxtjPOHtKeH7BeH9w+s9103h7euNMafH5juSnsIY4zTGfGaMeTl8X9eUdJgxZosxZqUx5nNjzJLwtqR7HVRQ1w7GGCfwV+AMYCJwiTFmYmxHJT3cP4F5h2y7EZhvrR0DzA/fh9B1NSb872rgPgj9gQJuBWYBM4FbI3+kJGn5gRustROB2cD14b9FurakI2qBk621U4FpwDxjzGzgt8AfrbWjgf3AVeHjrwL2h7f/MXwc4WvxYmASob9/fwu/fkry+j6wtt59XVPSWU6y1k6r17Ig6V4HFdS1z0ygwFq72VrrBZ4CzonxmKQHs9YuAEoP2XwO8Gj49qPAufW2/8uGfALkGGMGAqcDb1lrS621+4G3aBwoShKx1u6y1i4L364g9GZpMLq2pAPC18fB8F13+J8FTgaeDW8/9LqKXG/PAqcYY0x4+1PW2lprbSFQQOj1U5KQMWYIcBbwj/B9g64p6TpJ9zqooK59BgPb690vCm8TaYv+1tpd4du7gf7h281dX7rupFnh6UnTgU/RtSUdFJ4m9zlQTOjNzSbggLXWHz6k/jUSvX7C+8uAPui6kob+BPwECIbv90HXlHQOC7xpjFlqjLk6vC3pXgddsR6AiIQ+GTfGqBSttIsxJhN4DviBtbY89IF2iK4taQ9rbQCYZozJAV4Axsd4SBLHjDFfBIqttUuNMXNjPR5JOMdZa3cYY/KAt4wx6+rvTJbXQWXq2mcHMLTe/SHhbSJtsSec8if8tTi8vbnrS9edNGKMcRMK6J6w1j4f3qxrSzqFtfYA8C4wh9A0pciHwfWvkej1E97fC9iHriupcyzwJWPMFkJLVk4G7kHXlHQCa+2O8NdiQh9CzSQJXwcV1LXPYmBMuGqTh9Ci3RdjPCaJPy8CkepKXwf+V2/75eEKTbOBsvAUgjeA04wxvcOLd08Lb5MkFV5j8hCw1lp7d71durak3Ywx/cIZOowxacAXCK3XfBf4cviwQ6+ryPX2ZeAdG2qC+yJwcbiS4QhChQkWdc93IT2JtfYma+0Qa+1wQu+Z3rHWXoquKekgY0yGMSYrcpvQ69cqkvB1UNMv28Fa6zfGfIfQL9sJPGytXR3jYUkPZoz5NzAX6GuMKSJUYeku4BljzFXAVuCi8OGvAmcSWgBeBVwBYK0tNcbcTuhDBYDbrLWHFl+R5HIscBmwMrz+CeBmdG1JxwwEHg1XFXQAz1hrXzbGrAGeMsbcAXxG6AMFwl8fM8YUECoIdTGAtXa1MeYZYA2hSq3Xh6d1ikT8FF1T0jH9gRfCyw5cwJPW2teNMYtJstdBE/rgQ0REREREROKRpl+KiIiIiIjEMQV1IiIiIiIicUxBnYiIiIiISBxTUCciIiIiIhLHFNSJiIiIiIjEMQV1IiIiIiIicUxBnYiIiIiISBxTUCciIiIiIhLH/j9T57ex/hwHPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etQxrM9nyNj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a31b385c-6baf-4598-eb8a-0296483b8f76"
      },
      "source": [
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]),                   \n",
        "    tf.keras.layers.Dense(units=128, activation='elu',kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(units=64, activation='elu',kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(units=32, activation='elu',kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer= keras.optimizers.SGD(lr=0.01, momentum=0.9),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=64, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "  1/782 [..............................] - ETA: 0s - loss: 0.1928 - mean_absolute_error: 0.3752WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_train_batch_end` time: 0.0423s). Check your callbacks.\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.0150 - mean_absolute_error: 0.0333 - val_loss: 3.6317e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 2/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 2.0614e-04 - mean_absolute_error: 0.0106 - val_loss: 2.8277e-04 - val_mean_absolute_error: 0.0106\n",
            "Epoch 3/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.7704e-04 - mean_absolute_error: 0.0098 - val_loss: 2.9103e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 4/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.6104e-04 - mean_absolute_error: 0.0094 - val_loss: 2.3707e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 5/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.4763e-04 - mean_absolute_error: 0.0090 - val_loss: 2.2119e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 6/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.3446e-04 - mean_absolute_error: 0.0085 - val_loss: 1.8648e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 7/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.2631e-04 - mean_absolute_error: 0.0083 - val_loss: 1.9071e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 8/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.1867e-04 - mean_absolute_error: 0.0080 - val_loss: 1.6902e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 9/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.0760e-04 - mean_absolute_error: 0.0076 - val_loss: 1.8137e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 10/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.1053e-04 - mean_absolute_error: 0.0077 - val_loss: 1.6073e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 11/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.0653e-04 - mean_absolute_error: 0.0076 - val_loss: 1.5771e-04 - val_mean_absolute_error: 0.0070\n",
            "Epoch 12/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.0095e-04 - mean_absolute_error: 0.0074 - val_loss: 1.5978e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 13/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 9.5355e-05 - mean_absolute_error: 0.0072 - val_loss: 1.3699e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 14/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.8268e-05 - mean_absolute_error: 0.0069 - val_loss: 1.2685e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 15/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.8222e-05 - mean_absolute_error: 0.0069 - val_loss: 2.1523e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 16/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.9032e-05 - mean_absolute_error: 0.0069 - val_loss: 1.4259e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 17/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.4466e-05 - mean_absolute_error: 0.0068 - val_loss: 1.4331e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 18/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.3285e-05 - mean_absolute_error: 0.0067 - val_loss: 1.1120e-04 - val_mean_absolute_error: 0.0057\n",
            "Epoch 19/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.3746e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9565e-04 - val_mean_absolute_error: 0.0109\n",
            "Epoch 20/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 8.0922e-05 - mean_absolute_error: 0.0066 - val_loss: 1.1271e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 21/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 7.9429e-05 - mean_absolute_error: 0.0066 - val_loss: 1.0362e-04 - val_mean_absolute_error: 0.0055\n",
            "Epoch 22/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 7.5867e-05 - mean_absolute_error: 0.0064 - val_loss: 1.0694e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 23/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 7.0346e-05 - mean_absolute_error: 0.0061 - val_loss: 1.0111e-04 - val_mean_absolute_error: 0.0055\n",
            "Epoch 24/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 7.2687e-05 - mean_absolute_error: 0.0063 - val_loss: 1.2393e-04 - val_mean_absolute_error: 0.0068\n",
            "Epoch 25/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 7.3840e-05 - mean_absolute_error: 0.0063 - val_loss: 9.3602e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 26/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 7.3489e-05 - mean_absolute_error: 0.0063 - val_loss: 9.4466e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 27/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.8454e-05 - mean_absolute_error: 0.0061 - val_loss: 9.0346e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 28/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.4303e-05 - mean_absolute_error: 0.0058 - val_loss: 9.4494e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 29/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.3386e-05 - mean_absolute_error: 0.0058 - val_loss: 8.6709e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 30/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.4604e-05 - mean_absolute_error: 0.0059 - val_loss: 9.4000e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 31/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.3571e-05 - mean_absolute_error: 0.0058 - val_loss: 1.5181e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 32/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.4354e-05 - mean_absolute_error: 0.0059 - val_loss: 8.7193e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 33/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.9675e-05 - mean_absolute_error: 0.0056 - val_loss: 8.7338e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 34/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.1160e-05 - mean_absolute_error: 0.0057 - val_loss: 1.2008e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 35/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.1519e-05 - mean_absolute_error: 0.0057 - val_loss: 8.7093e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 36/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.1796e-05 - mean_absolute_error: 0.0057 - val_loss: 1.0531e-04 - val_mean_absolute_error: 0.0065\n",
            "Epoch 37/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.2099e-05 - mean_absolute_error: 0.0058 - val_loss: 7.7957e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 38/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 6.0669e-05 - mean_absolute_error: 0.0057 - val_loss: 7.6206e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 39/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.9834e-05 - mean_absolute_error: 0.0057 - val_loss: 1.2380e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 40/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.5886e-05 - mean_absolute_error: 0.0054 - val_loss: 8.0864e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 41/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.8989e-05 - mean_absolute_error: 0.0056 - val_loss: 7.3901e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 42/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.8841e-05 - mean_absolute_error: 0.0056 - val_loss: 7.2167e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 43/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.4042e-05 - mean_absolute_error: 0.0053 - val_loss: 8.2581e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 44/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.5403e-05 - mean_absolute_error: 0.0054 - val_loss: 2.0521e-04 - val_mean_absolute_error: 0.0124\n",
            "Epoch 45/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.1694e-05 - mean_absolute_error: 0.0052 - val_loss: 7.6385e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 46/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.8408e-05 - mean_absolute_error: 0.0056 - val_loss: 7.1310e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 47/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.3692e-05 - mean_absolute_error: 0.0053 - val_loss: 6.8924e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 48/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.1366e-05 - mean_absolute_error: 0.0052 - val_loss: 1.2840e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 49/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.2919e-05 - mean_absolute_error: 0.0053 - val_loss: 7.9886e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 50/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.2698e-05 - mean_absolute_error: 0.0053 - val_loss: 6.5706e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 51/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.2613e-05 - mean_absolute_error: 0.0053 - val_loss: 6.8201e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 52/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9302e-05 - mean_absolute_error: 0.0051 - val_loss: 6.6974e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 53/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.8938e-05 - mean_absolute_error: 0.0050 - val_loss: 7.0579e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 54/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9274e-05 - mean_absolute_error: 0.0051 - val_loss: 6.7471e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 55/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9978e-05 - mean_absolute_error: 0.0051 - val_loss: 9.0123e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 56/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0659e-05 - mean_absolute_error: 0.0052 - val_loss: 7.5115e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 57/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9843e-05 - mean_absolute_error: 0.0051 - val_loss: 8.5195e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 58/150\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 5.1398e-05 - mean_absolute_error: 0.0052 - val_loss: 7.9458e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 59/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.3315e-05 - mean_absolute_error: 0.0053 - val_loss: 6.2513e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 60/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7848e-05 - mean_absolute_error: 0.0050 - val_loss: 6.3329e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 61/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7426e-05 - mean_absolute_error: 0.0050 - val_loss: 5.9637e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 62/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.8858e-05 - mean_absolute_error: 0.0051 - val_loss: 6.0627e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 63/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7796e-05 - mean_absolute_error: 0.0050 - val_loss: 5.8917e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 64/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5232e-05 - mean_absolute_error: 0.0048 - val_loss: 6.3263e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 65/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6257e-05 - mean_absolute_error: 0.0049 - val_loss: 7.9029e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 66/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5512e-05 - mean_absolute_error: 0.0048 - val_loss: 5.8117e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 67/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6504e-05 - mean_absolute_error: 0.0049 - val_loss: 5.6986e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 68/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5346e-05 - mean_absolute_error: 0.0048 - val_loss: 6.8927e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 69/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4005e-05 - mean_absolute_error: 0.0048 - val_loss: 7.1883e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 70/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6905e-05 - mean_absolute_error: 0.0050 - val_loss: 5.5995e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 71/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5082e-05 - mean_absolute_error: 0.0048 - val_loss: 5.9878e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 72/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4302e-05 - mean_absolute_error: 0.0048 - val_loss: 1.1307e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 73/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5741e-05 - mean_absolute_error: 0.0049 - val_loss: 5.4647e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 74/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3634e-05 - mean_absolute_error: 0.0047 - val_loss: 5.5563e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 75/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5048e-05 - mean_absolute_error: 0.0048 - val_loss: 5.5667e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 76/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1635e-05 - mean_absolute_error: 0.0046 - val_loss: 7.3155e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 77/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4037e-05 - mean_absolute_error: 0.0048 - val_loss: 6.8413e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 78/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3938e-05 - mean_absolute_error: 0.0048 - val_loss: 5.4553e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 79/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6287e-05 - mean_absolute_error: 0.0049 - val_loss: 5.7018e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 80/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2942e-05 - mean_absolute_error: 0.0047 - val_loss: 5.8202e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 81/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1329e-05 - mean_absolute_error: 0.0046 - val_loss: 5.3753e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 82/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4828e-05 - mean_absolute_error: 0.0049 - val_loss: 6.3892e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 83/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1307e-05 - mean_absolute_error: 0.0046 - val_loss: 5.1299e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 84/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3164e-05 - mean_absolute_error: 0.0047 - val_loss: 5.3069e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 85/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1674e-05 - mean_absolute_error: 0.0046 - val_loss: 5.2252e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 86/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1468e-05 - mean_absolute_error: 0.0046 - val_loss: 7.1886e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 87/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.0367e-05 - mean_absolute_error: 0.0045 - val_loss: 5.0772e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 88/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1669e-05 - mean_absolute_error: 0.0046 - val_loss: 6.2947e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 89/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1214e-05 - mean_absolute_error: 0.0046 - val_loss: 5.5225e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 90/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1387e-05 - mean_absolute_error: 0.0046 - val_loss: 7.5065e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 91/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1106e-05 - mean_absolute_error: 0.0046 - val_loss: 5.0740e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 92/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1713e-05 - mean_absolute_error: 0.0046 - val_loss: 5.0047e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 93/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.0540e-05 - mean_absolute_error: 0.0045 - val_loss: 4.9569e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 94/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.9879e-05 - mean_absolute_error: 0.0045 - val_loss: 4.8926e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 95/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.0965e-05 - mean_absolute_error: 0.0046 - val_loss: 4.8154e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 96/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.0208e-05 - mean_absolute_error: 0.0045 - val_loss: 5.1507e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 97/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.0101e-05 - mean_absolute_error: 0.0045 - val_loss: 6.6529e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 98/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.8007e-05 - mean_absolute_error: 0.0044 - val_loss: 6.3973e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 99/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2691e-05 - mean_absolute_error: 0.0047 - val_loss: 6.3053e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 100/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.9529e-05 - mean_absolute_error: 0.0045 - val_loss: 4.7936e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 101/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1202e-05 - mean_absolute_error: 0.0047 - val_loss: 7.4212e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 102/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1857e-05 - mean_absolute_error: 0.0047 - val_loss: 4.6873e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 103/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1594e-05 - mean_absolute_error: 0.0047 - val_loss: 8.2231e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 104/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.1410e-05 - mean_absolute_error: 0.0046 - val_loss: 1.0599e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 105/150\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.9824e-05 - mean_absolute_error: 0.0045 - val_loss: 5.0900e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 106/150\n",
            "473/782 [=================>............] - ETA: 0s - loss: 3.8101e-05 - mean_absolute_error: 0.0044"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-219a1c3397cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m history = model.fit(X_train, y_train, epochs=150, batch_size=32, \n\u001b[1;32m     39\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS1jibCdEo78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "644c52ff-794e-479a-dce1-7edb33c50d54"
      },
      "source": [
        "\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=32,initial_epoch=151, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 152/300\n",
            "  1/782 [..............................] - ETA: 0s - loss: 2.6468e-05 - mean_absolute_error: 0.0041WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_train_batch_end` time: 0.0187s). Check your callbacks.\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.1202e-05 - mean_absolute_error: 0.0052 - val_loss: 8.2797e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 153/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0655e-05 - mean_absolute_error: 0.0052 - val_loss: 8.1941e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 154/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0607e-05 - mean_absolute_error: 0.0052 - val_loss: 8.2236e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 155/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0381e-05 - mean_absolute_error: 0.0052 - val_loss: 8.3664e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 156/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0184e-05 - mean_absolute_error: 0.0052 - val_loss: 8.1985e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 157/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0087e-05 - mean_absolute_error: 0.0052 - val_loss: 8.0978e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 158/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0159e-05 - mean_absolute_error: 0.0052 - val_loss: 8.0733e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 159/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 5.0224e-05 - mean_absolute_error: 0.0052 - val_loss: 8.0415e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 160/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9895e-05 - mean_absolute_error: 0.0052 - val_loss: 8.0306e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 161/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9684e-05 - mean_absolute_error: 0.0051 - val_loss: 8.1285e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 162/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9816e-05 - mean_absolute_error: 0.0052 - val_loss: 8.0293e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 163/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9570e-05 - mean_absolute_error: 0.0051 - val_loss: 7.9764e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 164/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9056e-05 - mean_absolute_error: 0.0051 - val_loss: 7.9677e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 165/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9376e-05 - mean_absolute_error: 0.0051 - val_loss: 8.1105e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 166/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9031e-05 - mean_absolute_error: 0.0051 - val_loss: 7.9113e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 167/300\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.8930e-05 - mean_absolute_error: 0.0051 - val_loss: 7.9820e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 168/300\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.8865e-05 - mean_absolute_error: 0.0051 - val_loss: 7.8924e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 169/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.9068e-05 - mean_absolute_error: 0.0051 - val_loss: 7.8782e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 170/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.8463e-05 - mean_absolute_error: 0.0051 - val_loss: 8.3639e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 171/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.8419e-05 - mean_absolute_error: 0.0051 - val_loss: 7.8645e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 172/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.8153e-05 - mean_absolute_error: 0.0050 - val_loss: 7.8881e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 173/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7990e-05 - mean_absolute_error: 0.0050 - val_loss: 7.9747e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 174/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7994e-05 - mean_absolute_error: 0.0050 - val_loss: 8.2650e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 175/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7935e-05 - mean_absolute_error: 0.0050 - val_loss: 7.8434e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 176/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7811e-05 - mean_absolute_error: 0.0050 - val_loss: 7.8307e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 177/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7672e-05 - mean_absolute_error: 0.0050 - val_loss: 7.9531e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 178/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7568e-05 - mean_absolute_error: 0.0050 - val_loss: 7.7099e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 179/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7535e-05 - mean_absolute_error: 0.0050 - val_loss: 7.8998e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 180/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7349e-05 - mean_absolute_error: 0.0050 - val_loss: 7.7161e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 181/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7194e-05 - mean_absolute_error: 0.0050 - val_loss: 7.6440e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 182/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7012e-05 - mean_absolute_error: 0.0050 - val_loss: 7.6411e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 183/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.7317e-05 - mean_absolute_error: 0.0050 - val_loss: 7.6487e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 184/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6917e-05 - mean_absolute_error: 0.0050 - val_loss: 7.9769e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 185/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6654e-05 - mean_absolute_error: 0.0050 - val_loss: 7.8590e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 186/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6794e-05 - mean_absolute_error: 0.0050 - val_loss: 8.1113e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 187/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6624e-05 - mean_absolute_error: 0.0050 - val_loss: 7.5622e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 188/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6493e-05 - mean_absolute_error: 0.0049 - val_loss: 7.5129e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 189/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6466e-05 - mean_absolute_error: 0.0049 - val_loss: 7.5345e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 190/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6189e-05 - mean_absolute_error: 0.0049 - val_loss: 7.5204e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 191/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6187e-05 - mean_absolute_error: 0.0049 - val_loss: 7.5332e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 192/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6138e-05 - mean_absolute_error: 0.0049 - val_loss: 7.4709e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 193/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.6159e-05 - mean_absolute_error: 0.0049 - val_loss: 7.5440e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 194/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5983e-05 - mean_absolute_error: 0.0049 - val_loss: 7.5018e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 195/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5864e-05 - mean_absolute_error: 0.0049 - val_loss: 7.4353e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 196/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5805e-05 - mean_absolute_error: 0.0049 - val_loss: 7.4093e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 197/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5652e-05 - mean_absolute_error: 0.0049 - val_loss: 7.3943e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 198/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5562e-05 - mean_absolute_error: 0.0049 - val_loss: 7.4181e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 199/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5336e-05 - mean_absolute_error: 0.0049 - val_loss: 7.9386e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 200/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5453e-05 - mean_absolute_error: 0.0049 - val_loss: 7.3442e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 201/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5143e-05 - mean_absolute_error: 0.0049 - val_loss: 7.3524e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 202/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5188e-05 - mean_absolute_error: 0.0049 - val_loss: 7.4524e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 203/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5068e-05 - mean_absolute_error: 0.0049 - val_loss: 7.7630e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 204/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.5084e-05 - mean_absolute_error: 0.0049 - val_loss: 7.2877e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 205/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4813e-05 - mean_absolute_error: 0.0048 - val_loss: 7.3683e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 206/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4998e-05 - mean_absolute_error: 0.0049 - val_loss: 7.2730e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 207/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4936e-05 - mean_absolute_error: 0.0049 - val_loss: 7.2390e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 208/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4654e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2515e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 209/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4519e-05 - mean_absolute_error: 0.0048 - val_loss: 7.5458e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 210/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4421e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2092e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 211/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4643e-05 - mean_absolute_error: 0.0048 - val_loss: 8.0979e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 212/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4309e-05 - mean_absolute_error: 0.0048 - val_loss: 7.4610e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 213/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4060e-05 - mean_absolute_error: 0.0048 - val_loss: 7.1929e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 214/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4381e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2023e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 215/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4054e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2017e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 216/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3777e-05 - mean_absolute_error: 0.0048 - val_loss: 7.1852e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 217/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3824e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2359e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 218/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.4079e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2035e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 219/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3613e-05 - mean_absolute_error: 0.0048 - val_loss: 7.1491e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 220/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3674e-05 - mean_absolute_error: 0.0048 - val_loss: 7.1214e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 221/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3623e-05 - mean_absolute_error: 0.0048 - val_loss: 7.0673e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 222/300\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.3491e-05 - mean_absolute_error: 0.0048 - val_loss: 7.2716e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 223/300\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.3584e-05 - mean_absolute_error: 0.0048 - val_loss: 7.1371e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 224/300\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.3398e-05 - mean_absolute_error: 0.0047 - val_loss: 7.0256e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 225/300\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.3344e-05 - mean_absolute_error: 0.0048 - val_loss: 7.0028e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 226/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3326e-05 - mean_absolute_error: 0.0048 - val_loss: 7.0020e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 227/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2994e-05 - mean_absolute_error: 0.0047 - val_loss: 7.4886e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 228/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.3222e-05 - mean_absolute_error: 0.0047 - val_loss: 7.0139e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 229/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2968e-05 - mean_absolute_error: 0.0047 - val_loss: 7.0233e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 230/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2847e-05 - mean_absolute_error: 0.0047 - val_loss: 6.9734e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 231/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2979e-05 - mean_absolute_error: 0.0047 - val_loss: 7.0360e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 232/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2672e-05 - mean_absolute_error: 0.0047 - val_loss: 6.9951e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 233/300\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 4.2772e-05 - mean_absolute_error: 0.0047 - val_loss: 7.0826e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 234/300\n",
            "590/782 [=====================>........] - ETA: 0s - loss: 4.0865e-05 - mean_absolute_error: 0.0047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-9ce1266049fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(X_train, y_train, epochs=300, batch_size=32,initial_epoch=151, \n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKTQ1BMNHPt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf37c15f-8f8a-4b0e-a1a0-bff796e0d263"
      },
      "source": [
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]), \n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"relu\"),\n",
        "\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"prelu.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=500, batch_size=128, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "  2/196 [..............................] - ETA: 10s - loss: 0.6117 - mean_absolute_error: 0.6116WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.0917s). Check your callbacks.\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.0277 - mean_absolute_error: 0.0990 - val_loss: 0.0038 - val_mean_absolute_error: 0.0469\n",
            "Epoch 2/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0035 - mean_absolute_error: 0.0457 - val_loss: 0.0022 - val_mean_absolute_error: 0.0374\n",
            "Epoch 3/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.0024 - mean_absolute_error: 0.0389 - val_loss: 0.0016 - val_mean_absolute_error: 0.0302\n",
            "Epoch 4/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.0019 - mean_absolute_error: 0.0339 - val_loss: 0.0014 - val_mean_absolute_error: 0.0269\n",
            "Epoch 5/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.0014 - mean_absolute_error: 0.0297 - val_loss: 0.0012 - val_mean_absolute_error: 0.0230\n",
            "Epoch 6/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0016 - mean_absolute_error: 0.0315 - val_loss: 0.0014 - val_mean_absolute_error: 0.0279\n",
            "Epoch 7/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0013 - mean_absolute_error: 0.0280 - val_loss: 0.0014 - val_mean_absolute_error: 0.0268\n",
            "Epoch 8/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.0013 - mean_absolute_error: 0.0289 - val_loss: 0.0011 - val_mean_absolute_error: 0.0223\n",
            "Epoch 9/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.0010 - mean_absolute_error: 0.0254 - val_loss: 6.7000e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 10/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0011 - mean_absolute_error: 0.0256 - val_loss: 0.0011 - val_mean_absolute_error: 0.0258\n",
            "Epoch 11/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0011 - mean_absolute_error: 0.0265 - val_loss: 6.5082e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 12/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 9.2775e-04 - mean_absolute_error: 0.0241 - val_loss: 4.4147e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 13/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 8.5957e-04 - mean_absolute_error: 0.0231 - val_loss: 5.7936e-04 - val_mean_absolute_error: 0.0171\n",
            "Epoch 14/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 9.8603e-04 - mean_absolute_error: 0.0248 - val_loss: 4.3534e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 15/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 4.0779e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 16/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 7.8265e-04 - mean_absolute_error: 0.0221 - val_loss: 3.3666e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 17/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 9.0611e-04 - mean_absolute_error: 0.0237 - val_loss: 4.0368e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 18/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 7.3383e-04 - mean_absolute_error: 0.0211 - val_loss: 3.7775e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 19/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 7.7506e-04 - mean_absolute_error: 0.0218 - val_loss: 2.7167e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 20/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 8.6582e-04 - mean_absolute_error: 0.0233 - val_loss: 3.3183e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 21/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 6.4375e-04 - mean_absolute_error: 0.0201 - val_loss: 5.1708e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 22/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 7.1194e-04 - mean_absolute_error: 0.0211 - val_loss: 7.0981e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 23/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 8.6360e-04 - mean_absolute_error: 0.0231 - val_loss: 3.3475e-04 - val_mean_absolute_error: 0.0128\n",
            "Epoch 24/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 6.9748e-04 - mean_absolute_error: 0.0211 - val_loss: 4.2229e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 25/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 7.3832e-04 - mean_absolute_error: 0.0215 - val_loss: 2.6970e-04 - val_mean_absolute_error: 0.0124\n",
            "Epoch 26/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 6.0179e-04 - mean_absolute_error: 0.0194 - val_loss: 2.9352e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 27/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 6.3984e-04 - mean_absolute_error: 0.0200 - val_loss: 3.9609e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 28/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 6.1378e-04 - mean_absolute_error: 0.0195 - val_loss: 2.9829e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 29/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 5.8564e-04 - mean_absolute_error: 0.0192 - val_loss: 2.1582e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 30/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 5.4043e-04 - mean_absolute_error: 0.0183 - val_loss: 2.8842e-04 - val_mean_absolute_error: 0.0128\n",
            "Epoch 31/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 5.8519e-04 - mean_absolute_error: 0.0191 - val_loss: 1.9347e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 32/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 5.8054e-04 - mean_absolute_error: 0.0191 - val_loss: 3.3508e-04 - val_mean_absolute_error: 0.0120\n",
            "Epoch 33/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.7822e-04 - mean_absolute_error: 0.0171 - val_loss: 1.8825e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 34/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 5.5584e-04 - mean_absolute_error: 0.0185 - val_loss: 3.1393e-04 - val_mean_absolute_error: 0.0149\n",
            "Epoch 35/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 6.3021e-04 - mean_absolute_error: 0.0199 - val_loss: 2.0157e-04 - val_mean_absolute_error: 0.0108\n",
            "Epoch 36/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 5.4100e-04 - mean_absolute_error: 0.0184 - val_loss: 2.0358e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 37/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.6146e-04 - mean_absolute_error: 0.0169 - val_loss: 2.2353e-04 - val_mean_absolute_error: 0.0109\n",
            "Epoch 38/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 5.1163e-04 - mean_absolute_error: 0.0182 - val_loss: 2.1058e-04 - val_mean_absolute_error: 0.0104\n",
            "Epoch 39/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 5.4845e-04 - mean_absolute_error: 0.0185 - val_loss: 3.7421e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 40/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 5.5639e-04 - mean_absolute_error: 0.0184 - val_loss: 2.2033e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 41/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.5157e-04 - mean_absolute_error: 0.0166 - val_loss: 1.9485e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 42/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 5.0299e-04 - mean_absolute_error: 0.0177 - val_loss: 3.9554e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 43/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.8527e-04 - mean_absolute_error: 0.0174 - val_loss: 6.1762e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 44/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.1619e-04 - mean_absolute_error: 0.0162 - val_loss: 2.9004e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 45/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.4835e-04 - mean_absolute_error: 0.0167 - val_loss: 1.9495e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 46/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.4403e-04 - mean_absolute_error: 0.0167 - val_loss: 2.0498e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 47/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.6660e-04 - mean_absolute_error: 0.0171 - val_loss: 2.6818e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 48/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.8246e-04 - mean_absolute_error: 0.0175 - val_loss: 1.8951e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 49/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.3689e-04 - mean_absolute_error: 0.0165 - val_loss: 2.8098e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 50/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.3080e-04 - mean_absolute_error: 0.0166 - val_loss: 1.3517e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 51/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.5696e-04 - mean_absolute_error: 0.0168 - val_loss: 1.8000e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 52/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.9198e-04 - mean_absolute_error: 0.0174 - val_loss: 2.2984e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 53/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.1134e-04 - mean_absolute_error: 0.0160 - val_loss: 1.6667e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 54/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.8107e-04 - mean_absolute_error: 0.0155 - val_loss: 1.8565e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 55/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.5269e-04 - mean_absolute_error: 0.0169 - val_loss: 3.8987e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 56/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.1413e-04 - mean_absolute_error: 0.0163 - val_loss: 2.7058e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 57/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.8044e-04 - mean_absolute_error: 0.0171 - val_loss: 2.3793e-04 - val_mean_absolute_error: 0.0124\n",
            "Epoch 58/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.4593e-04 - mean_absolute_error: 0.0166 - val_loss: 1.4396e-04 - val_mean_absolute_error: 0.0066\n",
            "Epoch 59/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.4339e-04 - mean_absolute_error: 0.0166 - val_loss: 1.6721e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 60/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.9782e-04 - mean_absolute_error: 0.0158 - val_loss: 2.4156e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 61/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.3271e-04 - mean_absolute_error: 0.0162 - val_loss: 1.6760e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 62/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.9417e-04 - mean_absolute_error: 0.0158 - val_loss: 1.3383e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 63/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.0066e-04 - mean_absolute_error: 0.0156 - val_loss: 1.4798e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 64/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.8307e-04 - mean_absolute_error: 0.0156 - val_loss: 2.2095e-04 - val_mean_absolute_error: 0.0114\n",
            "Epoch 65/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.5664e-04 - mean_absolute_error: 0.0169 - val_loss: 1.7552e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 66/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.3577e-04 - mean_absolute_error: 0.0165 - val_loss: 1.8301e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 67/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.2934e-04 - mean_absolute_error: 0.0163 - val_loss: 2.0980e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 68/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.8614e-04 - mean_absolute_error: 0.0155 - val_loss: 3.0627e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 69/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.4559e-04 - mean_absolute_error: 0.0148 - val_loss: 1.6883e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 70/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 4.3674e-04 - mean_absolute_error: 0.0166 - val_loss: 1.1840e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 71/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.6345e-04 - mean_absolute_error: 0.0152 - val_loss: 1.4626e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 72/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.8454e-04 - mean_absolute_error: 0.0156 - val_loss: 1.7124e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 73/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.0507e-04 - mean_absolute_error: 0.0160 - val_loss: 1.5927e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 74/500\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.2101e-04 - mean_absolute_error: 0.0162 - val_loss: 1.5696e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 75/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.8719e-04 - mean_absolute_error: 0.0158 - val_loss: 2.7873e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 76/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.3941e-04 - mean_absolute_error: 0.0147 - val_loss: 2.1418e-04 - val_mean_absolute_error: 0.0114\n",
            "Epoch 77/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.4191e-04 - mean_absolute_error: 0.0144 - val_loss: 1.9084e-04 - val_mean_absolute_error: 0.0099\n",
            "Epoch 78/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.2000e-04 - mean_absolute_error: 0.0139 - val_loss: 1.9904e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 79/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.5686e-04 - mean_absolute_error: 0.0150 - val_loss: 2.9765e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 80/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.6520e-04 - mean_absolute_error: 0.0151 - val_loss: 2.9399e-04 - val_mean_absolute_error: 0.0109\n",
            "Epoch 81/500\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.2705e-04 - mean_absolute_error: 0.0162 - val_loss: 1.3849e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 82/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.8826e-04 - mean_absolute_error: 0.0156 - val_loss: 3.3211e-04 - val_mean_absolute_error: 0.0154\n",
            "Epoch 83/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.5581e-04 - mean_absolute_error: 0.0150 - val_loss: 1.4103e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 84/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.8681e-04 - mean_absolute_error: 0.0155 - val_loss: 2.9128e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 85/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.6825e-04 - mean_absolute_error: 0.0152 - val_loss: 1.5938e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 86/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.0125e-04 - mean_absolute_error: 0.0137 - val_loss: 2.5673e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 87/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.3546e-04 - mean_absolute_error: 0.0145 - val_loss: 1.3776e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 88/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.7037e-04 - mean_absolute_error: 0.0153 - val_loss: 1.9454e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 89/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.6934e-04 - mean_absolute_error: 0.0149 - val_loss: 2.7981e-04 - val_mean_absolute_error: 0.0104\n",
            "Epoch 90/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.2950e-04 - mean_absolute_error: 0.0161 - val_loss: 1.2548e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 91/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.1916e-04 - mean_absolute_error: 0.0143 - val_loss: 2.0294e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 92/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.8885e-04 - mean_absolute_error: 0.0157 - val_loss: 2.3793e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 93/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.6631e-04 - mean_absolute_error: 0.0148 - val_loss: 1.2472e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 94/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.6197e-04 - mean_absolute_error: 0.0149 - val_loss: 1.9961e-04 - val_mean_absolute_error: 0.0099\n",
            "Epoch 95/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.4715e-04 - mean_absolute_error: 0.0147 - val_loss: 1.5383e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 96/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.4464e-04 - mean_absolute_error: 0.0145 - val_loss: 1.5175e-04 - val_mean_absolute_error: 0.0066\n",
            "Epoch 97/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.0098e-04 - mean_absolute_error: 0.0137 - val_loss: 1.6332e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 98/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.4454e-04 - mean_absolute_error: 0.0145 - val_loss: 1.6517e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 99/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.7365e-04 - mean_absolute_error: 0.0152 - val_loss: 1.3990e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 100/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7518e-04 - mean_absolute_error: 0.0131 - val_loss: 1.2442e-04 - val_mean_absolute_error: 0.0065\n",
            "Epoch 101/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.4670e-04 - mean_absolute_error: 0.0148 - val_loss: 1.5422e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 102/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 4.0770e-04 - mean_absolute_error: 0.0159 - val_loss: 2.1951e-04 - val_mean_absolute_error: 0.0120\n",
            "Epoch 103/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.5007e-04 - mean_absolute_error: 0.0147 - val_loss: 1.5759e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 104/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.2472e-04 - mean_absolute_error: 0.0141 - val_loss: 2.0942e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 105/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.9879e-04 - mean_absolute_error: 0.0135 - val_loss: 1.1916e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 106/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7368e-04 - mean_absolute_error: 0.0130 - val_loss: 1.2313e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 107/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.2815e-04 - mean_absolute_error: 0.0144 - val_loss: 1.6515e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 108/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6994e-04 - mean_absolute_error: 0.0130 - val_loss: 3.2684e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 109/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.0729e-04 - mean_absolute_error: 0.0140 - val_loss: 1.4930e-04 - val_mean_absolute_error: 0.0077\n",
            "Epoch 110/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.5647e-04 - mean_absolute_error: 0.0150 - val_loss: 2.7038e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 111/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.9330e-04 - mean_absolute_error: 0.0134 - val_loss: 3.5745e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 112/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.2091e-04 - mean_absolute_error: 0.0141 - val_loss: 1.5091e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 113/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.0502e-04 - mean_absolute_error: 0.0138 - val_loss: 3.0242e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 114/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.0362e-04 - mean_absolute_error: 0.0138 - val_loss: 3.2115e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 115/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.9656e-04 - mean_absolute_error: 0.0136 - val_loss: 2.2436e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 116/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6814e-04 - mean_absolute_error: 0.0130 - val_loss: 3.1342e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 117/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.8588e-04 - mean_absolute_error: 0.0134 - val_loss: 2.0600e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 118/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.1422e-04 - mean_absolute_error: 0.0141 - val_loss: 2.0902e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 119/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.9865e-04 - mean_absolute_error: 0.0135 - val_loss: 1.9394e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 120/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7654e-04 - mean_absolute_error: 0.0132 - val_loss: 3.0578e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 121/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.1101e-04 - mean_absolute_error: 0.0140 - val_loss: 3.5486e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 122/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.9753e-04 - mean_absolute_error: 0.0136 - val_loss: 2.0239e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 123/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.4286e-04 - mean_absolute_error: 0.0143 - val_loss: 3.3410e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 124/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.3988e-04 - mean_absolute_error: 0.0147 - val_loss: 3.5202e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 125/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 3.3365e-04 - mean_absolute_error: 0.0144 - val_loss: 3.4538e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 126/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.8734e-04 - mean_absolute_error: 0.0132 - val_loss: 2.8245e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 127/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 3.1437e-04 - mean_absolute_error: 0.0139 - val_loss: 1.9652e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 128/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.7223e-04 - mean_absolute_error: 0.0130 - val_loss: 2.2167e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 129/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.7303e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6255e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 130/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6595e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4931e-04 - val_mean_absolute_error: 0.0067\n",
            "Epoch 131/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7743e-04 - mean_absolute_error: 0.0131 - val_loss: 2.9564e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 132/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.8244e-04 - mean_absolute_error: 0.0134 - val_loss: 3.6204e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 133/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.5465e-04 - mean_absolute_error: 0.0125 - val_loss: 1.7205e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 134/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6682e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5164e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 135/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6947e-04 - mean_absolute_error: 0.0128 - val_loss: 2.1100e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 136/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.8588e-04 - mean_absolute_error: 0.0133 - val_loss: 1.7400e-04 - val_mean_absolute_error: 0.0077\n",
            "Epoch 137/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.8769e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4855e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 138/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.8793e-04 - mean_absolute_error: 0.0133 - val_loss: 2.2857e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 139/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7255e-04 - mean_absolute_error: 0.0130 - val_loss: 2.1440e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 140/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6323e-04 - mean_absolute_error: 0.0127 - val_loss: 2.2342e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 141/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7705e-04 - mean_absolute_error: 0.0131 - val_loss: 1.7423e-04 - val_mean_absolute_error: 0.0070\n",
            "Epoch 142/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.7363e-04 - mean_absolute_error: 0.0132 - val_loss: 2.1664e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 143/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.4730e-04 - mean_absolute_error: 0.0124 - val_loss: 1.5620e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 144/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.8307e-04 - mean_absolute_error: 0.0133 - val_loss: 2.8108e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 145/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3347e-04 - mean_absolute_error: 0.0120 - val_loss: 1.4311e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 146/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6501e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3546e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 147/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6686e-04 - mean_absolute_error: 0.0128 - val_loss: 2.3685e-04 - val_mean_absolute_error: 0.0118\n",
            "Epoch 148/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2028e-04 - mean_absolute_error: 0.0116 - val_loss: 1.5354e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 149/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.6916e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6981e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 150/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3918e-04 - mean_absolute_error: 0.0122 - val_loss: 1.5054e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 151/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.5100e-04 - mean_absolute_error: 0.0124 - val_loss: 1.7983e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 152/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0567e-04 - mean_absolute_error: 0.0113 - val_loss: 1.8641e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 153/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2844e-04 - mean_absolute_error: 0.0119 - val_loss: 1.3248e-04 - val_mean_absolute_error: 0.0067\n",
            "Epoch 154/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9803e-04 - mean_absolute_error: 0.0111 - val_loss: 2.1380e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 155/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.5345e-04 - mean_absolute_error: 0.0127 - val_loss: 4.5627e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 156/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.5666e-04 - mean_absolute_error: 0.0125 - val_loss: 1.8203e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 157/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3459e-04 - mean_absolute_error: 0.0120 - val_loss: 1.7439e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 158/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2628e-04 - mean_absolute_error: 0.0118 - val_loss: 1.3248e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 159/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.1403e-04 - mean_absolute_error: 0.0115 - val_loss: 1.4687e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 160/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2106e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1733e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 161/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1912e-04 - mean_absolute_error: 0.0116 - val_loss: 1.3292e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 162/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3500e-04 - mean_absolute_error: 0.0121 - val_loss: 1.2603e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 163/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0693e-04 - mean_absolute_error: 0.0114 - val_loss: 1.4929e-04 - val_mean_absolute_error: 0.0066\n",
            "Epoch 164/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0832e-04 - mean_absolute_error: 0.0112 - val_loss: 1.3463e-04 - val_mean_absolute_error: 0.0065\n",
            "Epoch 165/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3129e-04 - mean_absolute_error: 0.0119 - val_loss: 1.5764e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 166/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0998e-04 - mean_absolute_error: 0.0112 - val_loss: 1.4360e-04 - val_mean_absolute_error: 0.0062\n",
            "Epoch 167/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2665e-04 - mean_absolute_error: 0.0117 - val_loss: 1.6650e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 168/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9551e-04 - mean_absolute_error: 0.0110 - val_loss: 1.8029e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 169/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8692e-04 - mean_absolute_error: 0.0107 - val_loss: 1.3256e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 170/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0716e-04 - mean_absolute_error: 0.0112 - val_loss: 1.9581e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 171/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0926e-04 - mean_absolute_error: 0.0113 - val_loss: 1.9120e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 172/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3125e-04 - mean_absolute_error: 0.0119 - val_loss: 3.3264e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 173/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1091e-04 - mean_absolute_error: 0.0116 - val_loss: 1.4774e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 174/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8488e-04 - mean_absolute_error: 0.0107 - val_loss: 1.3722e-04 - val_mean_absolute_error: 0.0057\n",
            "Epoch 175/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.8234e-04 - mean_absolute_error: 0.0106 - val_loss: 2.1993e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 176/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7514e-04 - mean_absolute_error: 0.0102 - val_loss: 2.3788e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 177/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0096e-04 - mean_absolute_error: 0.0110 - val_loss: 1.6690e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 178/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1692e-04 - mean_absolute_error: 0.0117 - val_loss: 1.3430e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 179/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.4311e-04 - mean_absolute_error: 0.0121 - val_loss: 2.0707e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 180/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0632e-04 - mean_absolute_error: 0.0113 - val_loss: 1.5689e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 181/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8568e-04 - mean_absolute_error: 0.0107 - val_loss: 2.1022e-04 - val_mean_absolute_error: 0.0099\n",
            "Epoch 182/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9454e-04 - mean_absolute_error: 0.0110 - val_loss: 1.2886e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 183/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9337e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0714e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 184/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8942e-04 - mean_absolute_error: 0.0108 - val_loss: 1.3676e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 185/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8022e-04 - mean_absolute_error: 0.0105 - val_loss: 1.1690e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 186/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9446e-04 - mean_absolute_error: 0.0109 - val_loss: 2.1687e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 187/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9584e-04 - mean_absolute_error: 0.0110 - val_loss: 1.4168e-04 - val_mean_absolute_error: 0.0065\n",
            "Epoch 188/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1851e-04 - mean_absolute_error: 0.0117 - val_loss: 1.4423e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 189/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.4945e-04 - mean_absolute_error: 0.0124 - val_loss: 1.5640e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 190/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3669e-04 - mean_absolute_error: 0.0120 - val_loss: 1.7767e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 191/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7840e-04 - mean_absolute_error: 0.0105 - val_loss: 1.9818e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 192/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7283e-04 - mean_absolute_error: 0.0102 - val_loss: 1.4740e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 193/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7859e-04 - mean_absolute_error: 0.0104 - val_loss: 1.6390e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 194/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8395e-04 - mean_absolute_error: 0.0106 - val_loss: 1.7035e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 195/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7156e-04 - mean_absolute_error: 0.0103 - val_loss: 1.0646e-04 - val_mean_absolute_error: 0.0062\n",
            "Epoch 196/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6818e-04 - mean_absolute_error: 0.0101 - val_loss: 1.1059e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 197/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7986e-04 - mean_absolute_error: 0.0105 - val_loss: 1.5997e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 198/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7230e-04 - mean_absolute_error: 0.0103 - val_loss: 1.0899e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 199/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5271e-04 - mean_absolute_error: 0.0096 - val_loss: 1.5956e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 200/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7795e-04 - mean_absolute_error: 0.0105 - val_loss: 1.2205e-04 - val_mean_absolute_error: 0.0062\n",
            "Epoch 201/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5407e-04 - mean_absolute_error: 0.0098 - val_loss: 1.1135e-04 - val_mean_absolute_error: 0.0059\n",
            "Epoch 202/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7450e-04 - mean_absolute_error: 0.0102 - val_loss: 1.6282e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 203/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1484e-04 - mean_absolute_error: 0.0112 - val_loss: 1.2200e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 204/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9993e-04 - mean_absolute_error: 0.0111 - val_loss: 1.1045e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 205/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7457e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0226e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 206/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7636e-04 - mean_absolute_error: 0.0103 - val_loss: 2.6729e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 207/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9604e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0789e-04 - val_mean_absolute_error: 0.0057\n",
            "Epoch 208/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7395e-04 - mean_absolute_error: 0.0102 - val_loss: 1.3430e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 209/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7606e-04 - mean_absolute_error: 0.0104 - val_loss: 1.4937e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 210/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5996e-04 - mean_absolute_error: 0.0099 - val_loss: 1.2457e-04 - val_mean_absolute_error: 0.0067\n",
            "Epoch 211/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5994e-04 - mean_absolute_error: 0.0099 - val_loss: 1.4538e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 212/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6810e-04 - mean_absolute_error: 0.0101 - val_loss: 9.8795e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 213/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9212e-04 - mean_absolute_error: 0.0108 - val_loss: 5.0044e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 214/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9106e-04 - mean_absolute_error: 0.0107 - val_loss: 1.3489e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 215/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0414e-04 - mean_absolute_error: 0.0112 - val_loss: 1.5344e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 216/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6197e-04 - mean_absolute_error: 0.0100 - val_loss: 1.6355e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 217/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7148e-04 - mean_absolute_error: 0.0101 - val_loss: 9.1698e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 218/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7939e-04 - mean_absolute_error: 0.0105 - val_loss: 2.6383e-04 - val_mean_absolute_error: 0.0114\n",
            "Epoch 219/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0717e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1260e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 220/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7534e-04 - mean_absolute_error: 0.0103 - val_loss: 1.8080e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 221/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9864e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0950e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 222/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7508e-04 - mean_absolute_error: 0.0102 - val_loss: 1.5370e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 223/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7759e-04 - mean_absolute_error: 0.0105 - val_loss: 1.4639e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 224/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7796e-04 - mean_absolute_error: 0.0105 - val_loss: 2.0228e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 225/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0335e-04 - mean_absolute_error: 0.0112 - val_loss: 1.2932e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 226/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6317e-04 - mean_absolute_error: 0.0099 - val_loss: 1.5231e-04 - val_mean_absolute_error: 0.0068\n",
            "Epoch 227/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8739e-04 - mean_absolute_error: 0.0107 - val_loss: 3.1048e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 228/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7544e-04 - mean_absolute_error: 0.0104 - val_loss: 1.3653e-04 - val_mean_absolute_error: 0.0068\n",
            "Epoch 229/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5345e-04 - mean_absolute_error: 0.0096 - val_loss: 1.1814e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 230/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6908e-04 - mean_absolute_error: 0.0101 - val_loss: 1.1413e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 231/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7188e-04 - mean_absolute_error: 0.0102 - val_loss: 1.1988e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 232/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7528e-04 - mean_absolute_error: 0.0102 - val_loss: 8.7323e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 233/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6739e-04 - mean_absolute_error: 0.0100 - val_loss: 9.7145e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 234/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5071e-04 - mean_absolute_error: 0.0097 - val_loss: 1.0710e-04 - val_mean_absolute_error: 0.0062\n",
            "Epoch 235/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7615e-04 - mean_absolute_error: 0.0104 - val_loss: 8.6645e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 236/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9052e-04 - mean_absolute_error: 0.0107 - val_loss: 8.3168e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 237/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8459e-04 - mean_absolute_error: 0.0106 - val_loss: 7.4457e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 238/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5228e-04 - mean_absolute_error: 0.0096 - val_loss: 9.5120e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 239/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5551e-04 - mean_absolute_error: 0.0097 - val_loss: 1.6224e-04 - val_mean_absolute_error: 0.0106\n",
            "Epoch 240/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6095e-04 - mean_absolute_error: 0.0100 - val_loss: 8.5427e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 241/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7859e-04 - mean_absolute_error: 0.0104 - val_loss: 6.8984e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 242/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6934e-04 - mean_absolute_error: 0.0101 - val_loss: 1.7782e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 243/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5536e-04 - mean_absolute_error: 0.0098 - val_loss: 1.1394e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 244/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6265e-04 - mean_absolute_error: 0.0099 - val_loss: 9.4103e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 245/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5529e-04 - mean_absolute_error: 0.0097 - val_loss: 7.8917e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 246/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9124e-04 - mean_absolute_error: 0.0108 - val_loss: 9.3474e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 247/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5048e-04 - mean_absolute_error: 0.0096 - val_loss: 8.0316e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 248/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6647e-04 - mean_absolute_error: 0.0101 - val_loss: 1.0356e-04 - val_mean_absolute_error: 0.0065\n",
            "Epoch 249/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8031e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1719e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 250/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9836e-04 - mean_absolute_error: 0.0111 - val_loss: 1.8757e-04 - val_mean_absolute_error: 0.0114\n",
            "Epoch 251/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6988e-04 - mean_absolute_error: 0.0103 - val_loss: 1.4486e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 252/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7697e-04 - mean_absolute_error: 0.0105 - val_loss: 1.1329e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 253/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5255e-04 - mean_absolute_error: 0.0098 - val_loss: 1.4338e-04 - val_mean_absolute_error: 0.0099\n",
            "Epoch 254/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5500e-04 - mean_absolute_error: 0.0097 - val_loss: 1.2072e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 255/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8840e-04 - mean_absolute_error: 0.0106 - val_loss: 1.5178e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 256/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4752e-04 - mean_absolute_error: 0.0096 - val_loss: 9.9038e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 257/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6282e-04 - mean_absolute_error: 0.0099 - val_loss: 7.7621e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 258/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6188e-04 - mean_absolute_error: 0.0099 - val_loss: 9.9388e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 259/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6063e-04 - mean_absolute_error: 0.0098 - val_loss: 9.5942e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 260/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5760e-04 - mean_absolute_error: 0.0099 - val_loss: 9.3822e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 261/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6337e-04 - mean_absolute_error: 0.0100 - val_loss: 2.0083e-04 - val_mean_absolute_error: 0.0120\n",
            "Epoch 262/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7068e-04 - mean_absolute_error: 0.0103 - val_loss: 1.4514e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 263/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5832e-04 - mean_absolute_error: 0.0099 - val_loss: 1.0468e-04 - val_mean_absolute_error: 0.0070\n",
            "Epoch 264/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3824e-04 - mean_absolute_error: 0.0092 - val_loss: 7.7170e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 265/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3841e-04 - mean_absolute_error: 0.0092 - val_loss: 1.4750e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 266/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3755e-04 - mean_absolute_error: 0.0091 - val_loss: 9.3730e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 267/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6311e-04 - mean_absolute_error: 0.0102 - val_loss: 1.4383e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 268/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5301e-04 - mean_absolute_error: 0.0096 - val_loss: 1.1238e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 269/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4316e-04 - mean_absolute_error: 0.0093 - val_loss: 8.1080e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 270/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4122e-04 - mean_absolute_error: 0.0092 - val_loss: 9.6226e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 271/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4576e-04 - mean_absolute_error: 0.0095 - val_loss: 1.9394e-04 - val_mean_absolute_error: 0.0116\n",
            "Epoch 272/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3152e-04 - mean_absolute_error: 0.0090 - val_loss: 1.4784e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 273/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4399e-04 - mean_absolute_error: 0.0094 - val_loss: 8.3989e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 274/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1875e-04 - mean_absolute_error: 0.0085 - val_loss: 1.1302e-04 - val_mean_absolute_error: 0.0066\n",
            "Epoch 275/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3501e-04 - mean_absolute_error: 0.0090 - val_loss: 1.6512e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 276/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4856e-04 - mean_absolute_error: 0.0094 - val_loss: 1.9878e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 277/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7748e-04 - mean_absolute_error: 0.0105 - val_loss: 1.7550e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 278/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5504e-04 - mean_absolute_error: 0.0096 - val_loss: 1.2609e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 279/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5701e-04 - mean_absolute_error: 0.0094 - val_loss: 8.1389e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 280/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6286e-04 - mean_absolute_error: 0.0099 - val_loss: 9.3690e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 281/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3522e-04 - mean_absolute_error: 0.0090 - val_loss: 9.6785e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 282/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6311e-04 - mean_absolute_error: 0.0098 - val_loss: 8.8386e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 283/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5517e-04 - mean_absolute_error: 0.0097 - val_loss: 7.6825e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 284/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4356e-04 - mean_absolute_error: 0.0094 - val_loss: 8.4016e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 285/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4940e-04 - mean_absolute_error: 0.0095 - val_loss: 8.5323e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 286/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.2549e-04 - mean_absolute_error: 0.0088 - val_loss: 9.6506e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 287/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6294e-04 - mean_absolute_error: 0.0100 - val_loss: 1.2971e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 288/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6419e-04 - mean_absolute_error: 0.0100 - val_loss: 1.7290e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 289/500\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2919e-04 - mean_absolute_error: 0.0089 - val_loss: 1.0725e-04 - val_mean_absolute_error: 0.0070\n",
            "Epoch 290/500\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.4656e-04 - mean_absolute_error: 0.0093 - val_loss: 9.4375e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 291/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8413e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0726e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 292/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5500e-04 - mean_absolute_error: 0.0097 - val_loss: 1.2779e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 293/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4896e-04 - mean_absolute_error: 0.0094 - val_loss: 1.1251e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 294/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6037e-04 - mean_absolute_error: 0.0098 - val_loss: 9.3857e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 295/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5206e-04 - mean_absolute_error: 0.0097 - val_loss: 8.9697e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 296/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4128e-04 - mean_absolute_error: 0.0092 - val_loss: 1.1429e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 297/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5607e-04 - mean_absolute_error: 0.0096 - val_loss: 9.4321e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 298/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4560e-04 - mean_absolute_error: 0.0095 - val_loss: 1.2259e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 299/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2724e-04 - mean_absolute_error: 0.0088 - val_loss: 2.6917e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 300/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3273e-04 - mean_absolute_error: 0.0090 - val_loss: 2.5494e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 301/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2084e-04 - mean_absolute_error: 0.0085 - val_loss: 1.4324e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 302/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6203e-04 - mean_absolute_error: 0.0098 - val_loss: 1.5739e-04 - val_mean_absolute_error: 0.0067\n",
            "Epoch 303/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2922e-04 - mean_absolute_error: 0.0088 - val_loss: 2.0931e-04 - val_mean_absolute_error: 0.0054\n",
            "Epoch 304/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3664e-04 - mean_absolute_error: 0.0090 - val_loss: 2.0189e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 305/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2597e-04 - mean_absolute_error: 0.0086 - val_loss: 2.3238e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 306/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3063e-04 - mean_absolute_error: 0.0090 - val_loss: 2.2196e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 307/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2627e-04 - mean_absolute_error: 0.0087 - val_loss: 1.9552e-04 - val_mean_absolute_error: 0.0053\n",
            "Epoch 308/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4002e-04 - mean_absolute_error: 0.0092 - val_loss: 2.6530e-04 - val_mean_absolute_error: 0.0053\n",
            "Epoch 309/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3311e-04 - mean_absolute_error: 0.0090 - val_loss: 2.3598e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 310/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2734e-04 - mean_absolute_error: 0.0088 - val_loss: 2.4120e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 311/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5172e-04 - mean_absolute_error: 0.0095 - val_loss: 1.9554e-04 - val_mean_absolute_error: 0.0055\n",
            "Epoch 312/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2320e-04 - mean_absolute_error: 0.0086 - val_loss: 2.1284e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 313/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4802e-04 - mean_absolute_error: 0.0096 - val_loss: 2.7854e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 314/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3735e-04 - mean_absolute_error: 0.0091 - val_loss: 2.0362e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 315/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5791e-04 - mean_absolute_error: 0.0098 - val_loss: 1.9289e-04 - val_mean_absolute_error: 0.0077\n",
            "Epoch 316/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3384e-04 - mean_absolute_error: 0.0090 - val_loss: 1.9257e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 317/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2171e-04 - mean_absolute_error: 0.0086 - val_loss: 2.1283e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 318/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.2823e-04 - mean_absolute_error: 0.0089 - val_loss: 2.0318e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 319/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3727e-04 - mean_absolute_error: 0.0092 - val_loss: 1.6516e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 320/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2268e-04 - mean_absolute_error: 0.0087 - val_loss: 2.1424e-04 - val_mean_absolute_error: 0.0052\n",
            "Epoch 321/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2893e-04 - mean_absolute_error: 0.0087 - val_loss: 1.2729e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 322/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2820e-04 - mean_absolute_error: 0.0088 - val_loss: 1.6229e-04 - val_mean_absolute_error: 0.0070\n",
            "Epoch 323/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2840e-04 - mean_absolute_error: 0.0088 - val_loss: 1.9274e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 324/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3580e-04 - mean_absolute_error: 0.0092 - val_loss: 2.0389e-04 - val_mean_absolute_error: 0.0077\n",
            "Epoch 325/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5068e-04 - mean_absolute_error: 0.0095 - val_loss: 1.8808e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 326/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3070e-04 - mean_absolute_error: 0.0089 - val_loss: 1.8557e-04 - val_mean_absolute_error: 0.0052\n",
            "Epoch 327/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1266e-04 - mean_absolute_error: 0.0083 - val_loss: 4.3261e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 328/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5490e-04 - mean_absolute_error: 0.0097 - val_loss: 2.6355e-04 - val_mean_absolute_error: 0.0068\n",
            "Epoch 329/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5166e-04 - mean_absolute_error: 0.0095 - val_loss: 2.2328e-04 - val_mean_absolute_error: 0.0058\n",
            "Epoch 330/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2595e-04 - mean_absolute_error: 0.0088 - val_loss: 3.5853e-04 - val_mean_absolute_error: 0.0108\n",
            "Epoch 331/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3791e-04 - mean_absolute_error: 0.0091 - val_loss: 3.1535e-04 - val_mean_absolute_error: 0.0062\n",
            "Epoch 332/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2921e-04 - mean_absolute_error: 0.0089 - val_loss: 3.9619e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 333/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3428e-04 - mean_absolute_error: 0.0090 - val_loss: 2.8313e-04 - val_mean_absolute_error: 0.0057\n",
            "Epoch 334/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2103e-04 - mean_absolute_error: 0.0085 - val_loss: 3.5630e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 335/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2729e-04 - mean_absolute_error: 0.0088 - val_loss: 3.5659e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 336/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4047e-04 - mean_absolute_error: 0.0093 - val_loss: 3.8800e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 337/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0914e-04 - mean_absolute_error: 0.0081 - val_loss: 3.3401e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 338/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3729e-04 - mean_absolute_error: 0.0092 - val_loss: 3.3276e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 339/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.3969e-04 - mean_absolute_error: 0.0091 - val_loss: 2.6871e-04 - val_mean_absolute_error: 0.0064\n",
            "Epoch 340/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3503e-04 - mean_absolute_error: 0.0090 - val_loss: 2.8323e-04 - val_mean_absolute_error: 0.0066\n",
            "Epoch 341/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2341e-04 - mean_absolute_error: 0.0086 - val_loss: 2.5620e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 342/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3886e-04 - mean_absolute_error: 0.0092 - val_loss: 3.5611e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 343/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2579e-04 - mean_absolute_error: 0.0087 - val_loss: 3.1124e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 344/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2492e-04 - mean_absolute_error: 0.0087 - val_loss: 2.8506e-04 - val_mean_absolute_error: 0.0052\n",
            "Epoch 345/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2114e-04 - mean_absolute_error: 0.0087 - val_loss: 2.0900e-04 - val_mean_absolute_error: 0.0055\n",
            "Epoch 346/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2431e-04 - mean_absolute_error: 0.0086 - val_loss: 2.1043e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 347/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1584e-04 - mean_absolute_error: 0.0083 - val_loss: 2.2895e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 348/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8969e-04 - mean_absolute_error: 0.0108 - val_loss: 3.5203e-04 - val_mean_absolute_error: 0.0066\n",
            "Epoch 349/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3899e-04 - mean_absolute_error: 0.0091 - val_loss: 3.9683e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 350/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3965e-04 - mean_absolute_error: 0.0092 - val_loss: 2.8026e-04 - val_mean_absolute_error: 0.0059\n",
            "Epoch 351/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3633e-04 - mean_absolute_error: 0.0091 - val_loss: 4.2411e-04 - val_mean_absolute_error: 0.0059\n",
            "Epoch 352/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2865e-04 - mean_absolute_error: 0.0087 - val_loss: 6.2533e-04 - val_mean_absolute_error: 0.0059\n",
            "Epoch 353/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3706e-04 - mean_absolute_error: 0.0090 - val_loss: 5.5285e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 354/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2438e-04 - mean_absolute_error: 0.0087 - val_loss: 7.8628e-04 - val_mean_absolute_error: 0.0072\n",
            "Epoch 355/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4033e-04 - mean_absolute_error: 0.0091 - val_loss: 0.0039 - val_mean_absolute_error: 0.0079\n",
            "Epoch 356/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2619e-04 - mean_absolute_error: 0.0089 - val_loss: 0.0266 - val_mean_absolute_error: 0.0138\n",
            "Epoch 357/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3608e-04 - mean_absolute_error: 0.0091 - val_loss: 0.0719 - val_mean_absolute_error: 0.0153\n",
            "Epoch 358/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4222e-04 - mean_absolute_error: 0.0093 - val_loss: 0.1182 - val_mean_absolute_error: 0.0236\n",
            "Epoch 359/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1529e-04 - mean_absolute_error: 0.0083 - val_loss: 0.1397 - val_mean_absolute_error: 0.0222\n",
            "Epoch 360/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2809e-04 - mean_absolute_error: 0.0087 - val_loss: 0.3081 - val_mean_absolute_error: 0.0292\n",
            "Epoch 361/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3829e-04 - mean_absolute_error: 0.0091 - val_loss: 0.1751 - val_mean_absolute_error: 0.0217\n",
            "Epoch 362/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4576e-04 - mean_absolute_error: 0.0094 - val_loss: 0.1397 - val_mean_absolute_error: 0.0198\n",
            "Epoch 363/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1999e-04 - mean_absolute_error: 0.0085 - val_loss: 0.1448 - val_mean_absolute_error: 0.0203\n",
            "Epoch 364/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2681e-04 - mean_absolute_error: 0.0086 - val_loss: 0.1485 - val_mean_absolute_error: 0.0201\n",
            "Epoch 365/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3330e-04 - mean_absolute_error: 0.0090 - val_loss: 0.1992 - val_mean_absolute_error: 0.0226\n",
            "Epoch 366/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2151e-04 - mean_absolute_error: 0.0085 - val_loss: 0.1338 - val_mean_absolute_error: 0.0189\n",
            "Epoch 367/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.1770e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0424 - val_mean_absolute_error: 0.0133\n",
            "Epoch 368/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2231e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0415 - val_mean_absolute_error: 0.0140\n",
            "Epoch 369/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1274e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0124 - val_mean_absolute_error: 0.0095\n",
            "Epoch 370/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2107e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0139 - val_mean_absolute_error: 0.0104\n",
            "Epoch 371/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4663e-04 - mean_absolute_error: 0.0093 - val_loss: 0.0165 - val_mean_absolute_error: 0.0107\n",
            "Epoch 372/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1927e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0098 - val_mean_absolute_error: 0.0093\n",
            "Epoch 373/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5658e-04 - mean_absolute_error: 0.0098 - val_loss: 0.0067 - val_mean_absolute_error: 0.0107\n",
            "Epoch 374/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0356e-04 - mean_absolute_error: 0.0079 - val_loss: 0.0115 - val_mean_absolute_error: 0.0121\n",
            "Epoch 375/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.1678e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0108 - val_mean_absolute_error: 0.0106\n",
            "Epoch 376/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4602e-04 - mean_absolute_error: 0.0094 - val_loss: 0.0067 - val_mean_absolute_error: 0.0095\n",
            "Epoch 377/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3193e-04 - mean_absolute_error: 0.0088 - val_loss: 0.0091 - val_mean_absolute_error: 0.0096\n",
            "Epoch 378/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1044e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0095 - val_mean_absolute_error: 0.0148\n",
            "Epoch 379/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0839e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0093 - val_mean_absolute_error: 0.0092\n",
            "Epoch 380/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1848e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0078 - val_mean_absolute_error: 0.0105\n",
            "Epoch 381/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1453e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0078 - val_mean_absolute_error: 0.0088\n",
            "Epoch 382/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1514e-04 - mean_absolute_error: 0.0083 - val_loss: 0.0159 - val_mean_absolute_error: 0.0105\n",
            "Epoch 383/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3200e-04 - mean_absolute_error: 0.0089 - val_loss: 0.0117 - val_mean_absolute_error: 0.0126\n",
            "Epoch 384/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1521e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0174 - val_mean_absolute_error: 0.0103\n",
            "Epoch 385/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2565e-04 - mean_absolute_error: 0.0087 - val_loss: 0.0459 - val_mean_absolute_error: 0.0137\n",
            "Epoch 386/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2849e-04 - mean_absolute_error: 0.0089 - val_loss: 0.0380 - val_mean_absolute_error: 0.0139\n",
            "Epoch 387/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3435e-04 - mean_absolute_error: 0.0090 - val_loss: 0.0540 - val_mean_absolute_error: 0.0154\n",
            "Epoch 388/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0827e-04 - mean_absolute_error: 0.0081 - val_loss: 0.0407 - val_mean_absolute_error: 0.0154\n",
            "Epoch 389/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2276e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0694 - val_mean_absolute_error: 0.0153\n",
            "Epoch 390/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2005e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0291 - val_mean_absolute_error: 0.0138\n",
            "Epoch 391/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1721e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0380 - val_mean_absolute_error: 0.0127\n",
            "Epoch 392/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0952e-04 - mean_absolute_error: 0.0081 - val_loss: 0.0415 - val_mean_absolute_error: 0.0132\n",
            "Epoch 393/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1947e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0466 - val_mean_absolute_error: 0.0169\n",
            "Epoch 394/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1551e-04 - mean_absolute_error: 0.0083 - val_loss: 0.0332 - val_mean_absolute_error: 0.0151\n",
            "Epoch 395/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3033e-04 - mean_absolute_error: 0.0088 - val_loss: 0.0441 - val_mean_absolute_error: 0.0139\n",
            "Epoch 396/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2472e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0398 - val_mean_absolute_error: 0.0124\n",
            "Epoch 397/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.0557e-04 - mean_absolute_error: 0.0080 - val_loss: 0.0351 - val_mean_absolute_error: 0.0124\n",
            "Epoch 398/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4313e-04 - mean_absolute_error: 0.0093 - val_loss: 0.0897 - val_mean_absolute_error: 0.0188\n",
            "Epoch 399/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2346e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0322 - val_mean_absolute_error: 0.0129\n",
            "Epoch 400/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.1075e-04 - mean_absolute_error: 0.0080 - val_loss: 0.0225 - val_mean_absolute_error: 0.0114\n",
            "Epoch 401/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1235e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0214 - val_mean_absolute_error: 0.0152\n",
            "Epoch 402/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0127e-04 - mean_absolute_error: 0.0078 - val_loss: 0.0239 - val_mean_absolute_error: 0.0113\n",
            "Epoch 403/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4216e-04 - mean_absolute_error: 0.0093 - val_loss: 0.0336 - val_mean_absolute_error: 0.0127\n",
            "Epoch 404/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1107e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0448 - val_mean_absolute_error: 0.0143\n",
            "Epoch 405/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1515e-04 - mean_absolute_error: 0.0083 - val_loss: 0.0325 - val_mean_absolute_error: 0.0120\n",
            "Epoch 406/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0852e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0284 - val_mean_absolute_error: 0.0123\n",
            "Epoch 407/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1813e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0345 - val_mean_absolute_error: 0.0150\n",
            "Epoch 408/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1363e-04 - mean_absolute_error: 0.0083 - val_loss: 0.0305 - val_mean_absolute_error: 0.0120\n",
            "Epoch 409/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3753e-04 - mean_absolute_error: 0.0091 - val_loss: 0.1414 - val_mean_absolute_error: 0.0201\n",
            "Epoch 410/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2909e-04 - mean_absolute_error: 0.0088 - val_loss: 0.1319 - val_mean_absolute_error: 0.0234\n",
            "Epoch 411/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2526e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0730 - val_mean_absolute_error: 0.0151\n",
            "Epoch 412/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1901e-04 - mean_absolute_error: 0.0085 - val_loss: 0.1127 - val_mean_absolute_error: 0.0190\n",
            "Epoch 413/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1934e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0865 - val_mean_absolute_error: 0.0191\n",
            "Epoch 414/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1144e-04 - mean_absolute_error: 0.0082 - val_loss: 0.1340 - val_mean_absolute_error: 0.0220\n",
            "Epoch 415/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2754e-04 - mean_absolute_error: 0.0087 - val_loss: 0.0962 - val_mean_absolute_error: 0.0227\n",
            "Epoch 416/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2986e-04 - mean_absolute_error: 0.0088 - val_loss: 0.1296 - val_mean_absolute_error: 0.0216\n",
            "Epoch 417/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3030e-04 - mean_absolute_error: 0.0088 - val_loss: 0.1081 - val_mean_absolute_error: 0.0190\n",
            "Epoch 418/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1597e-04 - mean_absolute_error: 0.0083 - val_loss: 0.1067 - val_mean_absolute_error: 0.0220\n",
            "Epoch 419/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2518e-04 - mean_absolute_error: 0.0087 - val_loss: 0.3869 - val_mean_absolute_error: 0.0305\n",
            "Epoch 420/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2014e-04 - mean_absolute_error: 0.0086 - val_loss: 0.4660 - val_mean_absolute_error: 0.0323\n",
            "Epoch 421/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0996e-04 - mean_absolute_error: 0.0082 - val_loss: 0.1882 - val_mean_absolute_error: 0.0219\n",
            "Epoch 422/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0729e-04 - mean_absolute_error: 0.0080 - val_loss: 0.2556 - val_mean_absolute_error: 0.0269\n",
            "Epoch 423/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3212e-04 - mean_absolute_error: 0.0090 - val_loss: 0.2061 - val_mean_absolute_error: 0.0231\n",
            "Epoch 424/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1633e-04 - mean_absolute_error: 0.0084 - val_loss: 0.2238 - val_mean_absolute_error: 0.0280\n",
            "Epoch 425/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3538e-04 - mean_absolute_error: 0.0091 - val_loss: 0.0787 - val_mean_absolute_error: 0.0208\n",
            "Epoch 426/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2052e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0693 - val_mean_absolute_error: 0.0172\n",
            "Epoch 427/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1207e-04 - mean_absolute_error: 0.0081 - val_loss: 0.0723 - val_mean_absolute_error: 0.0167\n",
            "Epoch 428/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1094e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0858 - val_mean_absolute_error: 0.0238\n",
            "Epoch 429/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1297e-04 - mean_absolute_error: 0.0083 - val_loss: 0.0484 - val_mean_absolute_error: 0.0149\n",
            "Epoch 430/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1176e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0839 - val_mean_absolute_error: 0.0175\n",
            "Epoch 431/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2092e-04 - mean_absolute_error: 0.0086 - val_loss: 0.0618 - val_mean_absolute_error: 0.0161\n",
            "Epoch 432/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2145e-04 - mean_absolute_error: 0.0085 - val_loss: 0.0659 - val_mean_absolute_error: 0.0161\n",
            "Epoch 433/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3678e-04 - mean_absolute_error: 0.0091 - val_loss: 0.0908 - val_mean_absolute_error: 0.0188\n",
            "Epoch 434/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1580e-04 - mean_absolute_error: 0.0082 - val_loss: 0.1072 - val_mean_absolute_error: 0.0178\n",
            "Epoch 435/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2624e-04 - mean_absolute_error: 0.0088 - val_loss: 0.0867 - val_mean_absolute_error: 0.0176\n",
            "Epoch 436/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1650e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0753 - val_mean_absolute_error: 0.0157\n",
            "Epoch 437/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0804e-04 - mean_absolute_error: 0.0081 - val_loss: 0.1325 - val_mean_absolute_error: 0.0205\n",
            "Epoch 438/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1099e-04 - mean_absolute_error: 0.0083 - val_loss: 0.1331 - val_mean_absolute_error: 0.0202\n",
            "Epoch 439/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2430e-04 - mean_absolute_error: 0.0086 - val_loss: 0.1471 - val_mean_absolute_error: 0.0208\n",
            "Epoch 440/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1135e-04 - mean_absolute_error: 0.0081 - val_loss: 0.2140 - val_mean_absolute_error: 0.0231\n",
            "Epoch 441/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1029e-04 - mean_absolute_error: 0.0082 - val_loss: 0.2320 - val_mean_absolute_error: 0.0245\n",
            "Epoch 442/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3667e-04 - mean_absolute_error: 0.0090 - val_loss: 0.1429 - val_mean_absolute_error: 0.0224\n",
            "Epoch 443/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2983e-04 - mean_absolute_error: 0.0089 - val_loss: 0.1143 - val_mean_absolute_error: 0.0194\n",
            "Epoch 444/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0871e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0681 - val_mean_absolute_error: 0.0209\n",
            "Epoch 445/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1519e-04 - mean_absolute_error: 0.0084 - val_loss: 0.0020 - val_mean_absolute_error: 0.0077\n",
            "Epoch 446/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1109e-04 - mean_absolute_error: 0.0083 - val_loss: 0.0464 - val_mean_absolute_error: 0.0206\n",
            "Epoch 447/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0460e-04 - mean_absolute_error: 0.0078 - val_loss: 0.0140 - val_mean_absolute_error: 0.0102\n",
            "Epoch 448/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0363e-04 - mean_absolute_error: 0.0079 - val_loss: 0.0094 - val_mean_absolute_error: 0.0139\n",
            "Epoch 449/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5637e-04 - mean_absolute_error: 0.0099 - val_loss: 0.0805 - val_mean_absolute_error: 0.0169\n",
            "Epoch 450/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 9.8799e-05 - mean_absolute_error: 0.0077 - val_loss: 0.2172 - val_mean_absolute_error: 0.0265\n",
            "Epoch 451/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1343e-04 - mean_absolute_error: 0.0082 - val_loss: 0.2368 - val_mean_absolute_error: 0.0269\n",
            "Epoch 452/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0595e-04 - mean_absolute_error: 0.0080 - val_loss: 0.1303 - val_mean_absolute_error: 0.0209\n",
            "Epoch 453/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2848e-04 - mean_absolute_error: 0.0087 - val_loss: 0.0392 - val_mean_absolute_error: 0.0164\n",
            "Epoch 454/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2805e-04 - mean_absolute_error: 0.0088 - val_loss: 0.0623 - val_mean_absolute_error: 0.0160\n",
            "Epoch 455/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1394e-04 - mean_absolute_error: 0.0084 - val_loss: 0.1124 - val_mean_absolute_error: 0.0223\n",
            "Epoch 456/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0714e-04 - mean_absolute_error: 0.0080 - val_loss: 0.0722 - val_mean_absolute_error: 0.0196\n",
            "Epoch 457/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1040e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0494 - val_mean_absolute_error: 0.0146\n",
            "Epoch 458/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3048e-04 - mean_absolute_error: 0.0087 - val_loss: 0.0294 - val_mean_absolute_error: 0.0124\n",
            "Epoch 459/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1623e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0452 - val_mean_absolute_error: 0.0139\n",
            "Epoch 460/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1411e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0732 - val_mean_absolute_error: 0.0163\n",
            "Epoch 461/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1868e-04 - mean_absolute_error: 0.0086 - val_loss: 0.1748 - val_mean_absolute_error: 0.0236\n",
            "Epoch 462/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.0679e-04 - mean_absolute_error: 0.0080 - val_loss: 0.1984 - val_mean_absolute_error: 0.0235\n",
            "Epoch 463/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0966e-04 - mean_absolute_error: 0.0081 - val_loss: 0.1058 - val_mean_absolute_error: 0.0195\n",
            "Epoch 464/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0474e-04 - mean_absolute_error: 0.0079 - val_loss: 0.0709 - val_mean_absolute_error: 0.0153\n",
            "Epoch 465/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 9.5319e-05 - mean_absolute_error: 0.0075 - val_loss: 0.1221 - val_mean_absolute_error: 0.0204\n",
            "Epoch 466/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1159e-04 - mean_absolute_error: 0.0081 - val_loss: 0.0759 - val_mean_absolute_error: 0.0166\n",
            "Epoch 467/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2706e-04 - mean_absolute_error: 0.0088 - val_loss: 0.1098 - val_mean_absolute_error: 0.0206\n",
            "Epoch 468/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2462e-04 - mean_absolute_error: 0.0088 - val_loss: 0.1399 - val_mean_absolute_error: 0.0204\n",
            "Epoch 469/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.0952e-04 - mean_absolute_error: 0.0082 - val_loss: 0.2896 - val_mean_absolute_error: 0.0272\n",
            "Epoch 470/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1603e-04 - mean_absolute_error: 0.0085 - val_loss: 0.2703 - val_mean_absolute_error: 0.0283\n",
            "Epoch 471/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1415e-04 - mean_absolute_error: 0.0083 - val_loss: 0.1370 - val_mean_absolute_error: 0.0206\n",
            "Epoch 472/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1936e-04 - mean_absolute_error: 0.0085 - val_loss: 0.1678 - val_mean_absolute_error: 0.0265\n",
            "Epoch 473/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.0658e-04 - mean_absolute_error: 0.0081 - val_loss: 0.2208 - val_mean_absolute_error: 0.0264\n",
            "Epoch 474/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0960e-04 - mean_absolute_error: 0.0081 - val_loss: 0.2898 - val_mean_absolute_error: 0.0275\n",
            "Epoch 475/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0556e-04 - mean_absolute_error: 0.0080 - val_loss: 0.1131 - val_mean_absolute_error: 0.0191\n",
            "Epoch 476/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.0471e-04 - mean_absolute_error: 0.0079 - val_loss: 0.1291 - val_mean_absolute_error: 0.0220\n",
            "Epoch 477/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1994e-04 - mean_absolute_error: 0.0085 - val_loss: 0.1712 - val_mean_absolute_error: 0.0295\n",
            "Epoch 478/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.3526e-04 - mean_absolute_error: 0.0089 - val_loss: 0.1885 - val_mean_absolute_error: 0.0231\n",
            "Epoch 479/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1811e-04 - mean_absolute_error: 0.0084 - val_loss: 0.1689 - val_mean_absolute_error: 0.0223\n",
            "Epoch 480/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0830e-04 - mean_absolute_error: 0.0080 - val_loss: 0.1332 - val_mean_absolute_error: 0.0204\n",
            "Epoch 481/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1321e-04 - mean_absolute_error: 0.0082 - val_loss: 0.3528 - val_mean_absolute_error: 0.0296\n",
            "Epoch 482/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3753e-04 - mean_absolute_error: 0.0091 - val_loss: 0.4182 - val_mean_absolute_error: 0.0369\n",
            "Epoch 483/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 9.8595e-05 - mean_absolute_error: 0.0076 - val_loss: 0.2306 - val_mean_absolute_error: 0.0241\n",
            "Epoch 484/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 9.3393e-05 - mean_absolute_error: 0.0075 - val_loss: 0.1844 - val_mean_absolute_error: 0.0240\n",
            "Epoch 485/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1991e-04 - mean_absolute_error: 0.0085 - val_loss: 0.1500 - val_mean_absolute_error: 0.0236\n",
            "Epoch 486/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.2419e-04 - mean_absolute_error: 0.0086 - val_loss: 0.1815 - val_mean_absolute_error: 0.0223\n",
            "Epoch 487/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1030e-04 - mean_absolute_error: 0.0082 - val_loss: 0.1605 - val_mean_absolute_error: 0.0212\n",
            "Epoch 488/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1543e-04 - mean_absolute_error: 0.0084 - val_loss: 0.2328 - val_mean_absolute_error: 0.0247\n",
            "Epoch 489/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1443e-04 - mean_absolute_error: 0.0084 - val_loss: 0.2508 - val_mean_absolute_error: 0.0310\n",
            "Epoch 490/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0196e-04 - mean_absolute_error: 0.0079 - val_loss: 0.1356 - val_mean_absolute_error: 0.0194\n",
            "Epoch 491/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1493e-04 - mean_absolute_error: 0.0083 - val_loss: 0.1114 - val_mean_absolute_error: 0.0185\n",
            "Epoch 492/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 9.8646e-05 - mean_absolute_error: 0.0077 - val_loss: 0.0729 - val_mean_absolute_error: 0.0201\n",
            "Epoch 493/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 9.4439e-05 - mean_absolute_error: 0.0076 - val_loss: 0.0745 - val_mean_absolute_error: 0.0200\n",
            "Epoch 494/500\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0207e-04 - mean_absolute_error: 0.0078 - val_loss: 0.1037 - val_mean_absolute_error: 0.0181\n",
            "Epoch 495/500\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.0070e-04 - mean_absolute_error: 0.0077 - val_loss: 0.0743 - val_mean_absolute_error: 0.0161\n",
            "Epoch 496/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.0431e-04 - mean_absolute_error: 0.0079 - val_loss: 0.0451 - val_mean_absolute_error: 0.0162\n",
            "Epoch 497/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.1139e-04 - mean_absolute_error: 0.0082 - val_loss: 0.0169 - val_mean_absolute_error: 0.0113\n",
            "Epoch 498/500\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 9.4373e-05 - mean_absolute_error: 0.0075 - val_loss: 0.0235 - val_mean_absolute_error: 0.0134\n",
            "Epoch 499/500\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0968e-04 - mean_absolute_error: 0.0081 - val_loss: 0.0292 - val_mean_absolute_error: 0.0123\n",
            "Epoch 500/500\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 9.8473e-05 - mean_absolute_error: 0.0078 - val_loss: 0.0054 - val_mean_absolute_error: 0.0079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY1lwqUMkTz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75fdc819-444e-4797-c6a1-9c585959691b"
      },
      "source": [
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "# loss: 2.8008e-05 - mean_absolute_error: 0.0033  sklearn mae： 3.7761397\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]),                   \n",
        "    tf.keras.layers.Dense(units=128, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dense(units=64, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dense(units=32, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"prelu.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=180, batch_size=64, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/180\n",
            "  2/391 [..............................] - ETA: 21s - loss: 0.1537 - mean_absolute_error: 0.3538WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0056s vs `on_train_batch_end` time: 0.1062s). Check your callbacks.\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0019 - mean_absolute_error: 0.0207 - val_loss: 2.3933e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 2/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.5890e-04 - mean_absolute_error: 0.0098 - val_loss: 1.5236e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 3/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.1718e-04 - mean_absolute_error: 0.0084 - val_loss: 1.2247e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 4/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.0123e-04 - mean_absolute_error: 0.0077 - val_loss: 9.3364e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 5/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 8.8629e-05 - mean_absolute_error: 0.0072 - val_loss: 7.1169e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 6/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 9.4016e-05 - mean_absolute_error: 0.0074 - val_loss: 7.0475e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 7/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 6.5018e-05 - mean_absolute_error: 0.0061 - val_loss: 1.8656e-04 - val_mean_absolute_error: 0.0120\n",
            "Epoch 8/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 6.0864e-05 - mean_absolute_error: 0.0059 - val_loss: 5.3668e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 9/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 6.1887e-05 - mean_absolute_error: 0.0059 - val_loss: 4.9732e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 10/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 5.7982e-05 - mean_absolute_error: 0.0057 - val_loss: 4.3445e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 11/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.4101e-05 - mean_absolute_error: 0.0049 - val_loss: 6.0674e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 12/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.5760e-05 - mean_absolute_error: 0.0050 - val_loss: 3.8949e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 13/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 5.4218e-05 - mean_absolute_error: 0.0056 - val_loss: 5.6220e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 14/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.0363e-05 - mean_absolute_error: 0.0047 - val_loss: 4.0887e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 15/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 5.5772e-05 - mean_absolute_error: 0.0055 - val_loss: 4.0640e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 16/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.6689e-05 - mean_absolute_error: 0.0045 - val_loss: 6.8760e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 17/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.8737e-05 - mean_absolute_error: 0.0046 - val_loss: 3.6036e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 18/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.4789e-05 - mean_absolute_error: 0.0049 - val_loss: 3.2245e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 19/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.9697e-05 - mean_absolute_error: 0.0052 - val_loss: 3.1940e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 20/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.7527e-05 - mean_absolute_error: 0.0044 - val_loss: 3.2425e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 21/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.9601e-05 - mean_absolute_error: 0.0047 - val_loss: 7.6014e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 22/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.5220e-05 - mean_absolute_error: 0.0043 - val_loss: 3.4043e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 23/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.6529e-05 - mean_absolute_error: 0.0044 - val_loss: 4.1018e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 24/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.3725e-05 - mean_absolute_error: 0.0042 - val_loss: 3.3666e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 25/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.8951e-05 - mean_absolute_error: 0.0046 - val_loss: 6.7485e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 26/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.0175e-05 - mean_absolute_error: 0.0047 - val_loss: 4.2953e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 27/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.5496e-05 - mean_absolute_error: 0.0044 - val_loss: 3.5138e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 28/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.9237e-05 - mean_absolute_error: 0.0045 - val_loss: 2.8302e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 29/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6883e-05 - mean_absolute_error: 0.0037 - val_loss: 3.2461e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 30/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.1885e-05 - mean_absolute_error: 0.0041 - val_loss: 3.3604e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 31/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.1221e-05 - mean_absolute_error: 0.0041 - val_loss: 4.5937e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 32/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.3976e-05 - mean_absolute_error: 0.0042 - val_loss: 3.0237e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 33/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8408e-05 - mean_absolute_error: 0.0038 - val_loss: 2.8523e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 34/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 5.3982e-05 - mean_absolute_error: 0.0048 - val_loss: 3.4166e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 35/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.6013e-05 - mean_absolute_error: 0.0043 - val_loss: 4.6449e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 36/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.9172e-05 - mean_absolute_error: 0.0039 - val_loss: 2.7417e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 37/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.9303e-05 - mean_absolute_error: 0.0038 - val_loss: 3.1938e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 38/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8681e-05 - mean_absolute_error: 0.0039 - val_loss: 2.8914e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 39/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8007e-05 - mean_absolute_error: 0.0038 - val_loss: 3.6298e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 40/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6529e-05 - mean_absolute_error: 0.0036 - val_loss: 3.4090e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 41/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.7090e-05 - mean_absolute_error: 0.0037 - val_loss: 2.9523e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 42/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6263e-05 - mean_absolute_error: 0.0036 - val_loss: 3.5849e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 43/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.2925e-05 - mean_absolute_error: 0.0041 - val_loss: 2.8390e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 44/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.0463e-05 - mean_absolute_error: 0.0040 - val_loss: 2.6777e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 45/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5870e-05 - mean_absolute_error: 0.0036 - val_loss: 2.8162e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 46/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5241e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8986e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 47/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8541e-05 - mean_absolute_error: 0.0038 - val_loss: 8.3917e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 48/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8200e-05 - mean_absolute_error: 0.0038 - val_loss: 2.8068e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 49/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8526e-05 - mean_absolute_error: 0.0038 - val_loss: 3.1344e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 50/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8385e-05 - mean_absolute_error: 0.0038 - val_loss: 2.8863e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 51/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6171e-05 - mean_absolute_error: 0.0036 - val_loss: 3.6935e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 52/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8557e-05 - mean_absolute_error: 0.0039 - val_loss: 5.3655e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 53/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6894e-05 - mean_absolute_error: 0.0037 - val_loss: 5.1500e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 54/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6070e-05 - mean_absolute_error: 0.0036 - val_loss: 2.9721e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 55/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8370e-05 - mean_absolute_error: 0.0038 - val_loss: 3.1729e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 56/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.2547e-04 - mean_absolute_error: 0.0078 - val_loss: 3.7537e-04 - val_mean_absolute_error: 0.0167\n",
            "Epoch 57/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 4.2121e-05 - mean_absolute_error: 0.0047 - val_loss: 3.4903e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 58/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.7042e-05 - mean_absolute_error: 0.0037 - val_loss: 3.3613e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 59/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8360e-05 - mean_absolute_error: 0.0038 - val_loss: 3.0111e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 60/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5811e-05 - mean_absolute_error: 0.0036 - val_loss: 4.1656e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 61/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8739e-05 - mean_absolute_error: 0.0038 - val_loss: 3.4640e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 62/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.1476e-05 - mean_absolute_error: 0.0041 - val_loss: 3.4813e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 63/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.0970e-05 - mean_absolute_error: 0.0040 - val_loss: 5.2556e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 64/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5376e-05 - mean_absolute_error: 0.0036 - val_loss: 3.0871e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 65/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8894e-05 - mean_absolute_error: 0.0039 - val_loss: 3.1506e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 66/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6518e-05 - mean_absolute_error: 0.0037 - val_loss: 3.7407e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 67/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8059e-05 - mean_absolute_error: 0.0038 - val_loss: 3.7103e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 68/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.9806e-05 - mean_absolute_error: 0.0039 - val_loss: 3.0108e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 69/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8154e-05 - mean_absolute_error: 0.0038 - val_loss: 3.0287e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 70/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6032e-05 - mean_absolute_error: 0.0036 - val_loss: 4.2092e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 71/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.7420e-05 - mean_absolute_error: 0.0038 - val_loss: 2.7592e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 72/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5719e-05 - mean_absolute_error: 0.0036 - val_loss: 2.8000e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 73/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5436e-05 - mean_absolute_error: 0.0036 - val_loss: 5.2448e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 74/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5658e-05 - mean_absolute_error: 0.0036 - val_loss: 3.0443e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 75/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8114e-05 - mean_absolute_error: 0.0038 - val_loss: 2.6453e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 76/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8136e-05 - mean_absolute_error: 0.0038 - val_loss: 2.8043e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 77/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4656e-05 - mean_absolute_error: 0.0035 - val_loss: 5.3798e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 78/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.8869e-05 - mean_absolute_error: 0.0039 - val_loss: 3.6250e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 79/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4924e-05 - mean_absolute_error: 0.0035 - val_loss: 2.7424e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 80/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6241e-05 - mean_absolute_error: 0.0036 - val_loss: 2.9787e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 81/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 3.1401e-05 - mean_absolute_error: 0.0038 - val_loss: 2.8712e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 82/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3508e-05 - mean_absolute_error: 0.0034 - val_loss: 3.2104e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 83/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4554e-05 - mean_absolute_error: 0.0035 - val_loss: 3.5053e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 84/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5100e-05 - mean_absolute_error: 0.0036 - val_loss: 4.1663e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 85/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5089e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8951e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 86/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1289e-05 - mean_absolute_error: 0.0032 - val_loss: 6.7339e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 87/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5136e-05 - mean_absolute_error: 0.0036 - val_loss: 3.0885e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 88/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3367e-05 - mean_absolute_error: 0.0034 - val_loss: 2.6577e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 89/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.9525e-05 - mean_absolute_error: 0.0038 - val_loss: 3.2500e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 90/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3095e-05 - mean_absolute_error: 0.0033 - val_loss: 2.5181e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 91/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0858e-05 - mean_absolute_error: 0.0031 - val_loss: 2.7089e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 92/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4318e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8091e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 93/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2088e-05 - mean_absolute_error: 0.0033 - val_loss: 2.6661e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 94/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5468e-05 - mean_absolute_error: 0.0036 - val_loss: 5.6051e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 95/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2246e-05 - mean_absolute_error: 0.0033 - val_loss: 3.4510e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 96/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1641e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7296e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 97/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4097e-05 - mean_absolute_error: 0.0034 - val_loss: 2.6662e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 98/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.6633e-05 - mean_absolute_error: 0.0036 - val_loss: 2.8983e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 99/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2285e-05 - mean_absolute_error: 0.0033 - val_loss: 2.7142e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 100/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4857e-05 - mean_absolute_error: 0.0035 - val_loss: 6.1543e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 101/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3537e-05 - mean_absolute_error: 0.0034 - val_loss: 4.1687e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 102/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.5498e-05 - mean_absolute_error: 0.0036 - val_loss: 2.8836e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 103/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1675e-05 - mean_absolute_error: 0.0032 - val_loss: 3.7761e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 104/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2042e-05 - mean_absolute_error: 0.0032 - val_loss: 2.8512e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 105/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0894e-05 - mean_absolute_error: 0.0031 - val_loss: 3.1182e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 106/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3403e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4935e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 107/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1862e-05 - mean_absolute_error: 0.0032 - val_loss: 3.3100e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 108/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2845e-05 - mean_absolute_error: 0.0034 - val_loss: 4.0549e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 109/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1862e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6233e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 110/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2479e-05 - mean_absolute_error: 0.0033 - val_loss: 2.8101e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 111/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3553e-05 - mean_absolute_error: 0.0034 - val_loss: 2.7015e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 112/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1120e-05 - mean_absolute_error: 0.0032 - val_loss: 2.5765e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 113/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2421e-05 - mean_absolute_error: 0.0033 - val_loss: 3.3000e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 114/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2224e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9618e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 115/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0635e-05 - mean_absolute_error: 0.0031 - val_loss: 2.8734e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 116/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3255e-05 - mean_absolute_error: 0.0034 - val_loss: 2.6378e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 117/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1298e-05 - mean_absolute_error: 0.0032 - val_loss: 3.6255e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 118/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0832e-05 - mean_absolute_error: 0.0031 - val_loss: 2.5861e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 119/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2105e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7204e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 120/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1935e-05 - mean_absolute_error: 0.0033 - val_loss: 2.5675e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 121/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2392e-05 - mean_absolute_error: 0.0033 - val_loss: 3.4482e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 122/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3288e-05 - mean_absolute_error: 0.0034 - val_loss: 3.0572e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 123/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0555e-05 - mean_absolute_error: 0.0031 - val_loss: 2.5970e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 124/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0860e-05 - mean_absolute_error: 0.0031 - val_loss: 2.5834e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 125/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0750e-05 - mean_absolute_error: 0.0031 - val_loss: 3.2548e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 126/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0343e-05 - mean_absolute_error: 0.0031 - val_loss: 2.6778e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 127/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2955e-05 - mean_absolute_error: 0.0033 - val_loss: 4.9057e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 128/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1526e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7914e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 129/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1728e-05 - mean_absolute_error: 0.0033 - val_loss: 3.0205e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 130/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1152e-05 - mean_absolute_error: 0.0032 - val_loss: 2.5647e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 131/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2509e-05 - mean_absolute_error: 0.0033 - val_loss: 3.2717e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 132/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2363e-05 - mean_absolute_error: 0.0033 - val_loss: 2.6332e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 133/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1670e-05 - mean_absolute_error: 0.0032 - val_loss: 4.2280e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 134/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1162e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7635e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 135/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1101e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6995e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 136/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0853e-05 - mean_absolute_error: 0.0031 - val_loss: 2.3994e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 137/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.3182e-05 - mean_absolute_error: 0.0034 - val_loss: 3.5953e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 138/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2608e-05 - mean_absolute_error: 0.0033 - val_loss: 2.4624e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 139/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0788e-05 - mean_absolute_error: 0.0031 - val_loss: 3.2527e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 140/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2538e-05 - mean_absolute_error: 0.0033 - val_loss: 3.8933e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 141/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0402e-05 - mean_absolute_error: 0.0031 - val_loss: 2.5436e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 142/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9876e-05 - mean_absolute_error: 0.0030 - val_loss: 3.3314e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 143/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0906e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4216e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 144/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1496e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7518e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 145/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2420e-05 - mean_absolute_error: 0.0033 - val_loss: 3.8335e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 146/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0466e-05 - mean_absolute_error: 0.0031 - val_loss: 3.8919e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 147/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0610e-05 - mean_absolute_error: 0.0031 - val_loss: 3.0463e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 148/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9410e-05 - mean_absolute_error: 0.0030 - val_loss: 3.4471e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 149/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0427e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4573e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 150/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1717e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6824e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 151/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1508e-05 - mean_absolute_error: 0.0032 - val_loss: 2.5551e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 152/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1023e-05 - mean_absolute_error: 0.0032 - val_loss: 3.2869e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 153/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1824e-05 - mean_absolute_error: 0.0032 - val_loss: 5.0178e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 154/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9992e-05 - mean_absolute_error: 0.0030 - val_loss: 2.4214e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 155/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.2348e-05 - mean_absolute_error: 0.0033 - val_loss: 2.5384e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 156/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0630e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4449e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 157/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1600e-05 - mean_absolute_error: 0.0032 - val_loss: 2.6708e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 158/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9866e-05 - mean_absolute_error: 0.0030 - val_loss: 2.4503e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 159/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0457e-05 - mean_absolute_error: 0.0031 - val_loss: 2.7950e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 160/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1216e-05 - mean_absolute_error: 0.0032 - val_loss: 3.2090e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 161/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0877e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4428e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 162/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1114e-05 - mean_absolute_error: 0.0031 - val_loss: 2.6072e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 163/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0342e-05 - mean_absolute_error: 0.0031 - val_loss: 3.3135e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 164/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0869e-05 - mean_absolute_error: 0.0031 - val_loss: 3.8690e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 165/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1101e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7083e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 166/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1575e-05 - mean_absolute_error: 0.0032 - val_loss: 2.4564e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 167/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9494e-05 - mean_absolute_error: 0.0030 - val_loss: 4.8275e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 168/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0582e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4145e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 169/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.1709e-05 - mean_absolute_error: 0.0032 - val_loss: 2.7904e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 170/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0724e-05 - mean_absolute_error: 0.0031 - val_loss: 2.9853e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 171/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9677e-05 - mean_absolute_error: 0.0030 - val_loss: 4.3505e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 172/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9805e-05 - mean_absolute_error: 0.0030 - val_loss: 3.6938e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 173/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0661e-05 - mean_absolute_error: 0.0031 - val_loss: 2.5566e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 174/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9411e-05 - mean_absolute_error: 0.0030 - val_loss: 2.7444e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 175/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9830e-05 - mean_absolute_error: 0.0030 - val_loss: 2.6370e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 176/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0443e-05 - mean_absolute_error: 0.0031 - val_loss: 2.7474e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 177/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0289e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4773e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 178/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0705e-05 - mean_absolute_error: 0.0031 - val_loss: 2.6433e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 179/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.0343e-05 - mean_absolute_error: 0.0031 - val_loss: 2.4404e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 180/180\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.9804e-05 - mean_absolute_error: 0.0030 - val_loss: 2.8540e-05 - val_mean_absolute_error: 0.0031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGpyd-WgkTxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "9c54629c-3cb0-4d8f-dd6f-0ae486198bcd"
      },
      "source": [
        "\n",
        "\n",
        "ytrue=denorm(y_test,df.target)\n",
        "yhat=denorm(model.predict(X_test),df.target)\n",
        "\n",
        "model.evaluate(X_test,y_test)\n",
        "print(\"sklearn mae：\",sklearn.metrics.mean_absolute_error(ytrue,yhat))\n",
        "\n",
        "gene_hist(ytrue,yhat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 0s 2ms/step - loss: 3.0100e-05 - mean_absolute_error: 0.0034\n",
            "sklearn mae： 3.8299403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_wB1lcdWuEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ded1182-e1d0-4994-8b29-62a5db1f0384"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fbf6c073550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE5lId6JWuMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "f4f011a7-1a38-4b81-fef4-e16b76180628"
      },
      "source": [
        "model2=keras.models.load_model(\"selu.h5\")\n",
        "model2\n",
        "\n",
        "ytrue=denorm(y_test,df.target)\n",
        "yhat=denorm(model2.predict(X_test),df.target)\n",
        "\n",
        "model2.evaluate(X_test,y_test)\n",
        "print(\"sklearn mae：\",sklearn.metrics.mean_absolute_error(ytrue,yhat))\n",
        "\n",
        "gene_hist(ytrue,yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 1s 5ms/step - loss: 2.0539e-04 - mean_absolute_error: 0.0102\n",
            "sklearn mae： 11.569531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leCncZRtWuJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mgW8A9aWuHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U1lmrthWuBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSi2lS6ZejYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78522487-f56b-4608-e44f-974119232bef"
      },
      "source": [
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def build_model(n_hidden=3, n_neurons=32):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = tf.optimizers.Adam()\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "\n",
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_val, y_val),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 8.6404e-04 - val_loss: 1.6326e-04\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 8.4414e-05 - val_loss: 6.5059e-05\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 6.3840e-05 - val_loss: 5.0656e-05\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 6.5160e-05 - val_loss: 8.9418e-05\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.3961e-05 - val_loss: 8.5155e-05\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.9222e-05 - val_loss: 7.4206e-05\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.2295e-05 - val_loss: 4.6107e-05\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.1609e-05 - val_loss: 3.6892e-05\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 3.8421e-05 - val_loss: 7.9892e-05\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.7023e-05 - val_loss: 3.8274e-05\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.8854e-05 - val_loss: 3.8713e-05\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 3.6059e-05 - val_loss: 5.7552e-05\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 3.4940e-05 - val_loss: 7.1024e-05\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.9255e-05 - val_loss: 6.5168e-05\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 3.2738e-05 - val_loss: 9.7967e-05\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.3043e-05 - val_loss: 2.6479e-05\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.3698e-05 - val_loss: 3.0872e-05\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 3.3127e-05 - val_loss: 4.6058e-05\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.2164e-05 - val_loss: 5.6871e-05\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7957e-05 - val_loss: 3.4443e-05\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.2034e-05 - val_loss: 2.3021e-05\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7572e-05 - val_loss: 3.0517e-05\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.2866e-05 - val_loss: 5.2713e-05\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 3.4824e-05 - val_loss: 2.3536e-05\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6307e-05 - val_loss: 2.4593e-05\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.8481e-05 - val_loss: 2.4255e-05\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6803e-05 - val_loss: 2.8087e-05\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 2.8111e-05 - val_loss: 2.8000e-05\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 2.6017e-05 - val_loss: 2.9194e-05\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 2.7223e-05 - val_loss: 2.4496e-05\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 2.8356e-05 - val_loss: 2.8905e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f23bb031c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mv-rM0ukB8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5bdf22f-caaf-4ffa-c9df-cfe1ca0b18f0"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [2,3,4],\n",
        "    \"n_neurons\": np.arange(40, 60),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=70,\n",
        "                  validation_data=(X_val, y_val),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] n_neurons=58, n_hidden=2 ........................................\n",
            "Epoch 1/70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 1.6230e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.3258e-04 - val_loss: 9.6111e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.0876e-05 - val_loss: 1.1476e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8611e-05 - val_loss: 5.3631e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.7003e-05 - val_loss: 4.5929e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4258e-05 - val_loss: 4.2850e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.3287e-05 - val_loss: 5.7165e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0594e-05 - val_loss: 6.9305e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.8380e-05 - val_loss: 1.2623e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3668e-05 - val_loss: 4.1222e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0672e-05 - val_loss: 3.7432e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6377e-05 - val_loss: 3.1782e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5404e-05 - val_loss: 1.1132e-04\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7984e-05 - val_loss: 7.1028e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1549e-05 - val_loss: 3.3517e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7886e-05 - val_loss: 1.0412e-04\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8832e-05 - val_loss: 4.1280e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2740e-05 - val_loss: 8.8004e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1384e-05 - val_loss: 1.3923e-04\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3048e-05 - val_loss: 3.4263e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3786e-05 - val_loss: 2.9577e-04\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1947e-05 - val_loss: 7.2627e-05\n",
            "261/261 [==============================] - 0s 841us/step - loss: 1.6806e-04\n",
            "[CV] ......................... n_neurons=58, n_hidden=2, total=  19.3s\n",
            "[CV] n_neurons=58, n_hidden=2 ........................................\n",
            "Epoch 1/70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 2.2348e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.7584e-04 - val_loss: 1.0594e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.0946e-04 - val_loss: 7.8860e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.1003e-04 - val_loss: 7.7343e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.2603e-05 - val_loss: 7.5378e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.4885e-05 - val_loss: 6.3131e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.8873e-05 - val_loss: 6.6009e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.7400e-05 - val_loss: 6.0237e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.6950e-05 - val_loss: 6.3576e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.8502e-05 - val_loss: 4.0697e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1580e-05 - val_loss: 3.8643e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1136e-05 - val_loss: 5.1452e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7107e-05 - val_loss: 3.6948e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2812e-05 - val_loss: 6.4593e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2225e-05 - val_loss: 8.1795e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1011e-05 - val_loss: 4.8892e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8856e-05 - val_loss: 3.5788e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7736e-05 - val_loss: 8.1990e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1516e-05 - val_loss: 3.7744e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7711e-05 - val_loss: 3.4619e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1149e-05 - val_loss: 6.1690e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5942e-05 - val_loss: 7.7474e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9423e-05 - val_loss: 4.3290e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9865e-05 - val_loss: 2.8437e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9031e-05 - val_loss: 2.6822e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6665e-05 - val_loss: 7.4036e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8698e-05 - val_loss: 4.4217e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4602e-05 - val_loss: 3.9112e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1953e-05 - val_loss: 3.5582e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1874e-05 - val_loss: 4.6917e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3115e-05 - val_loss: 5.8580e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4159e-05 - val_loss: 3.2337e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5890e-05 - val_loss: 2.4439e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8080e-05 - val_loss: 2.7178e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0325e-05 - val_loss: 2.9815e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2639e-05 - val_loss: 3.9402e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8770e-05 - val_loss: 4.1210e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1202e-05 - val_loss: 6.5922e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6966e-05 - val_loss: 2.3595e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6272e-05 - val_loss: 2.8838e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6990e-05 - val_loss: 2.4467e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9750e-05 - val_loss: 3.5224e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0502e-05 - val_loss: 2.5956e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1947e-05 - val_loss: 2.4481e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6358e-05 - val_loss: 2.4592e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5406e-05 - val_loss: 2.4129e-05\n",
            "Epoch 47/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9714e-05 - val_loss: 5.6756e-05\n",
            "Epoch 48/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4247e-05 - val_loss: 3.7737e-05\n",
            "Epoch 49/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5020e-05 - val_loss: 2.3606e-05\n",
            "261/261 [==============================] - 0s 871us/step - loss: 2.0403e-05\n",
            "[CV] ......................... n_neurons=58, n_hidden=2, total=  43.6s\n",
            "[CV] n_neurons=58, n_hidden=2 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.4866e-04 - val_loss: 2.8843e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.0885e-04 - val_loss: 1.0547e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.7393e-05 - val_loss: 2.7795e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.3678e-05 - val_loss: 5.2915e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.2414e-05 - val_loss: 4.7631e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1048e-05 - val_loss: 6.0355e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.3590e-05 - val_loss: 7.1923e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1755e-05 - val_loss: 6.4588e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6994e-05 - val_loss: 1.4610e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.3152e-05 - val_loss: 1.1623e-04\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1744e-05 - val_loss: 1.0376e-04\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1248e-05 - val_loss: 7.4619e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3682e-05 - val_loss: 3.9896e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9978e-05 - val_loss: 4.3454e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8790e-05 - val_loss: 4.2749e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3284e-05 - val_loss: 3.5772e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6599e-05 - val_loss: 3.6696e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2479e-05 - val_loss: 4.4338e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8604e-05 - val_loss: 3.5705e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0564e-05 - val_loss: 6.2110e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2666e-05 - val_loss: 6.1568e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3061e-05 - val_loss: 5.0580e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8769e-05 - val_loss: 3.9721e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5037e-05 - val_loss: 4.5065e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5462e-05 - val_loss: 6.1406e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4074e-05 - val_loss: 1.7814e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3403e-05 - val_loss: 5.3280e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4194e-05 - val_loss: 4.2307e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6152e-05 - val_loss: 3.9299e-05\n",
            "261/261 [==============================] - 0s 1ms/step - loss: 2.8757e-05\n",
            "[CV] ......................... n_neurons=58, n_hidden=2, total=  26.1s\n",
            "[CV] n_neurons=45, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8871e-04 - val_loss: 9.9157e-05\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.5307e-05 - val_loss: 7.2560e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9752e-05 - val_loss: 5.5280e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.3175e-05 - val_loss: 4.9136e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8804e-05 - val_loss: 4.9867e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9745e-05 - val_loss: 4.8312e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8890e-05 - val_loss: 4.7470e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9081e-05 - val_loss: 3.6154e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7663e-05 - val_loss: 1.0831e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9438e-05 - val_loss: 4.8486e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2331e-05 - val_loss: 5.4879e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7485e-05 - val_loss: 1.0812e-04\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7609e-05 - val_loss: 5.9485e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1453e-05 - val_loss: 3.8813e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3272e-05 - val_loss: 3.4059e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7999e-05 - val_loss: 3.4889e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4401e-05 - val_loss: 4.8489e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2765e-05 - val_loss: 4.8703e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0173e-05 - val_loss: 3.3491e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1907e-05 - val_loss: 3.3575e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1502e-05 - val_loss: 4.6294e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5227e-05 - val_loss: 6.3064e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1538e-05 - val_loss: 3.1632e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2987e-05 - val_loss: 3.5366e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3700e-05 - val_loss: 4.1630e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9723e-05 - val_loss: 2.9757e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7823e-05 - val_loss: 6.3952e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9264e-05 - val_loss: 2.6959e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3337e-05 - val_loss: 2.7685e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7481e-05 - val_loss: 2.5232e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0104e-05 - val_loss: 3.1174e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9622e-05 - val_loss: 3.0956e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8980e-05 - val_loss: 2.9510e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1537e-05 - val_loss: 2.8789e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1044e-05 - val_loss: 3.1124e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7133e-05 - val_loss: 2.6309e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6949e-05 - val_loss: 3.1911e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9090e-05 - val_loss: 5.5954e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9087e-05 - val_loss: 1.0078e-04\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8739e-05 - val_loss: 2.9687e-05\n",
            "261/261 [==============================] - 0s 887us/step - loss: 2.7394e-05\n",
            "[CV] ......................... n_neurons=45, n_hidden=4, total=  40.1s\n",
            "[CV] n_neurons=45, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.6970e-04 - val_loss: 1.0179e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.8151e-05 - val_loss: 1.7708e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.2879e-05 - val_loss: 8.5673e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1248e-05 - val_loss: 5.0448e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.4556e-05 - val_loss: 4.4404e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1277e-05 - val_loss: 4.7643e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3339e-05 - val_loss: 3.8304e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9494e-05 - val_loss: 4.8104e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6757e-05 - val_loss: 3.9646e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.7273e-05 - val_loss: 4.1156e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0897e-05 - val_loss: 3.2738e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2742e-05 - val_loss: 3.4450e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2073e-05 - val_loss: 3.5268e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1988e-05 - val_loss: 7.1171e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4748e-05 - val_loss: 5.5222e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4383e-05 - val_loss: 3.2927e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1887e-05 - val_loss: 4.6451e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3634e-05 - val_loss: 2.7113e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7870e-05 - val_loss: 1.1324e-04\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4204e-05 - val_loss: 2.6076e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6995e-05 - val_loss: 2.6872e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4919e-05 - val_loss: 3.5654e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4564e-05 - val_loss: 2.5212e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3662e-05 - val_loss: 2.5712e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5928e-05 - val_loss: 2.9343e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6640e-05 - val_loss: 1.5426e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2365e-05 - val_loss: 6.3264e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7207e-05 - val_loss: 2.6546e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4864e-05 - val_loss: 2.8599e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3202e-05 - val_loss: 2.6286e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6683e-05 - val_loss: 3.4126e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5356e-05 - val_loss: 3.0735e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 2.8943e-05 - val_loss: 4.9121e-05\n",
            "261/261 [==============================] - 0s 1ms/step - loss: 3.4681e-05\n",
            "[CV] ......................... n_neurons=45, n_hidden=4, total=  35.0s\n",
            "[CV] n_neurons=45, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 2s 3ms/step - loss: 0.0011 - val_loss: 9.8385e-05\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9815e-05 - val_loss: 9.7012e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 6.4191e-05 - val_loss: 8.0720e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0099e-05 - val_loss: 5.8592e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 7.4564e-05 - val_loss: 5.3677e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8689e-05 - val_loss: 4.6473e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4829e-05 - val_loss: 4.6664e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 4.7899e-05 - val_loss: 4.4769e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 4.2739e-05 - val_loss: 1.8392e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3856e-05 - val_loss: 5.5298e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7235e-05 - val_loss: 5.9676e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6751e-05 - val_loss: 3.7731e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0671e-05 - val_loss: 3.7268e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3443e-05 - val_loss: 7.3101e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7911e-05 - val_loss: 3.4171e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4646e-05 - val_loss: 3.9594e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6787e-05 - val_loss: 3.6122e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4877e-05 - val_loss: 3.1837e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3335e-05 - val_loss: 3.3479e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1072e-05 - val_loss: 5.1464e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3679e-05 - val_loss: 3.7867e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9884e-05 - val_loss: 3.3233e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4065e-05 - val_loss: 3.9764e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6039e-05 - val_loss: 4.1774e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8516e-05 - val_loss: 4.0144e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2414e-05 - val_loss: 1.3534e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1108e-05 - val_loss: 6.6004e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5551e-05 - val_loss: 3.4311e-05\n",
            "261/261 [==============================] - 0s 933us/step - loss: 2.8339e-05\n",
            "[CV] ......................... n_neurons=45, n_hidden=4, total=  32.0s\n",
            "[CV] n_neurons=47, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 1.3105e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.0732e-05 - val_loss: 8.8863e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.3201e-05 - val_loss: 5.9793e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0636e-05 - val_loss: 4.6020e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4424e-05 - val_loss: 4.7289e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0015e-05 - val_loss: 4.2532e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5054e-05 - val_loss: 4.5332e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0727e-05 - val_loss: 3.4325e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6053e-05 - val_loss: 1.2800e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7805e-05 - val_loss: 4.9495e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4569e-05 - val_loss: 4.2093e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7361e-05 - val_loss: 4.5402e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6917e-05 - val_loss: 3.0505e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3487e-05 - val_loss: 3.3432e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5270e-05 - val_loss: 3.3144e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2424e-05 - val_loss: 3.3464e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8313e-05 - val_loss: 4.7170e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5384e-05 - val_loss: 5.7616e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8252e-05 - val_loss: 2.7739e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1502e-05 - val_loss: 3.3542e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1776e-05 - val_loss: 4.2048e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3991e-05 - val_loss: 2.9590e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2962e-05 - val_loss: 2.8788e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3131e-05 - val_loss: 2.6054e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1436e-05 - val_loss: 4.1464e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0810e-05 - val_loss: 2.5679e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6840e-05 - val_loss: 3.8695e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8141e-05 - val_loss: 2.7617e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3337e-05 - val_loss: 2.7368e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6577e-05 - val_loss: 2.7148e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8067e-05 - val_loss: 3.0009e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3350e-05 - val_loss: 3.3391e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.5476e-05 - val_loss: 2.7351e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8888e-05 - val_loss: 3.0694e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0865e-05 - val_loss: 4.2531e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6873e-05 - val_loss: 3.2255e-05\n",
            "261/261 [==============================] - 0s 889us/step - loss: 3.5616e-05\n",
            "[CV] ......................... n_neurons=47, n_hidden=4, total=  35.7s\n",
            "[CV] n_neurons=47, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 1.0420e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.1946e-05 - val_loss: 1.5150e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.5012e-05 - val_loss: 6.5743e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.5812e-05 - val_loss: 5.6288e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 7.8698e-05 - val_loss: 2.1299e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 2s 3ms/step - loss: 6.0427e-05 - val_loss: 5.5738e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 4.9367e-05 - val_loss: 4.3990e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 5.7287e-05 - val_loss: 4.2346e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6586e-05 - val_loss: 4.6994e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.8280e-05 - val_loss: 5.6252e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3094e-05 - val_loss: 4.5658e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0607e-05 - val_loss: 3.8187e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4614e-05 - val_loss: 3.9629e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7942e-05 - val_loss: 5.4686e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4331e-05 - val_loss: 8.9768e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9134e-05 - val_loss: 4.0963e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2118e-05 - val_loss: 4.7313e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1114e-05 - val_loss: 4.1355e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7496e-05 - val_loss: 1.0656e-04\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1705e-05 - val_loss: 3.8560e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1506e-05 - val_loss: 3.7705e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9927e-05 - val_loss: 3.7909e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3417e-05 - val_loss: 3.1548e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1779e-05 - val_loss: 4.3814e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8017e-05 - val_loss: 3.9356e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3778e-05 - val_loss: 1.2075e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7337e-05 - val_loss: 5.4276e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9320e-05 - val_loss: 4.2067e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3833e-05 - val_loss: 3.6961e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1816e-05 - val_loss: 3.3197e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4689e-05 - val_loss: 4.8547e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4286e-05 - val_loss: 5.9553e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8023e-05 - val_loss: 5.5780e-05\n",
            "261/261 [==============================] - 0s 941us/step - loss: 3.6693e-05\n",
            "[CV] ......................... n_neurons=47, n_hidden=4, total=  35.2s\n",
            "[CV] n_neurons=47, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0140e-04 - val_loss: 1.1896e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.2730e-05 - val_loss: 8.4701e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.7150e-05 - val_loss: 4.2136e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.9611e-05 - val_loss: 5.8398e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.6021e-05 - val_loss: 1.0473e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.6044e-05 - val_loss: 4.3428e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.3914e-05 - val_loss: 5.1516e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.4826e-05 - val_loss: 5.0569e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8204e-05 - val_loss: 1.7957e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1102e-05 - val_loss: 6.6878e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.3851e-05 - val_loss: 6.1706e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9929e-05 - val_loss: 1.2386e-04\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9987e-05 - val_loss: 7.0845e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0407e-05 - val_loss: 1.9997e-04\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9794e-05 - val_loss: 5.2818e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4492e-05 - val_loss: 6.8253e-05\n",
            "261/261 [==============================] - 0s 876us/step - loss: 4.9342e-05\n",
            "[CV] ......................... n_neurons=47, n_hidden=4, total=  16.4s\n",
            "[CV] n_neurons=48, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.7502e-04 - val_loss: 1.0078e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.9704e-05 - val_loss: 9.1383e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8875e-05 - val_loss: 5.6756e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9727e-05 - val_loss: 6.2822e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3121e-05 - val_loss: 3.7188e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6841e-05 - val_loss: 4.8039e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4604e-05 - val_loss: 4.3854e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7586e-05 - val_loss: 1.0166e-04\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0459e-05 - val_loss: 1.4579e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9151e-05 - val_loss: 6.9121e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9793e-05 - val_loss: 8.0499e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6820e-05 - val_loss: 3.9779e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7408e-05 - val_loss: 3.1820e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9511e-05 - val_loss: 3.6108e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4221e-05 - val_loss: 4.7276e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7566e-05 - val_loss: 3.0737e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5664e-05 - val_loss: 4.5911e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1963e-05 - val_loss: 5.9707e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8663e-05 - val_loss: 3.3593e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3659e-05 - val_loss: 3.0045e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1505e-05 - val_loss: 2.8988e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1092e-05 - val_loss: 3.6581e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2357e-05 - val_loss: 2.6362e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4473e-05 - val_loss: 4.3080e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0764e-05 - val_loss: 3.5286e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0247e-05 - val_loss: 2.7829e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7412e-05 - val_loss: 6.2670e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9349e-05 - val_loss: 2.6368e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2249e-05 - val_loss: 3.1121e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7253e-05 - val_loss: 3.5442e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8123e-05 - val_loss: 3.3723e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1653e-05 - val_loss: 3.3768e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6594e-05 - val_loss: 3.8133e-05\n",
            "261/261 [==============================] - 0s 902us/step - loss: 2.7351e-05\n",
            "[CV] ......................... n_neurons=48, n_hidden=4, total=  32.2s\n",
            "[CV] n_neurons=48, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0013e-04 - val_loss: 1.3192e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.9280e-05 - val_loss: 1.8514e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.6873e-05 - val_loss: 8.0516e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.6249e-05 - val_loss: 7.0790e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0352e-05 - val_loss: 1.7601e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7005e-05 - val_loss: 4.3965e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5262e-05 - val_loss: 4.0076e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3789e-05 - val_loss: 6.4179e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0909e-05 - val_loss: 3.8733e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.6318e-05 - val_loss: 5.2588e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0339e-05 - val_loss: 3.8914e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2360e-05 - val_loss: 4.7769e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0900e-05 - val_loss: 3.9340e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5598e-05 - val_loss: 1.8143e-04\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9590e-05 - val_loss: 3.9400e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9324e-05 - val_loss: 3.5872e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4513e-05 - val_loss: 4.3116e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3215e-05 - val_loss: 3.1010e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8819e-05 - val_loss: 9.9547e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4277e-05 - val_loss: 2.8216e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1518e-05 - val_loss: 2.8075e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2571e-05 - val_loss: 2.6254e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2161e-05 - val_loss: 2.7161e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3662e-05 - val_loss: 2.4823e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1398e-05 - val_loss: 2.6905e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5149e-05 - val_loss: 1.2577e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8845e-05 - val_loss: 5.6809e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5451e-05 - val_loss: 2.7945e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5905e-05 - val_loss: 2.3490e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3389e-05 - val_loss: 2.6053e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5109e-05 - val_loss: 2.6699e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4980e-05 - val_loss: 4.1693e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8842e-05 - val_loss: 6.8023e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4426e-05 - val_loss: 2.2530e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3019e-05 - val_loss: 3.2331e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0476e-05 - val_loss: 2.3827e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9124e-05 - val_loss: 4.4661e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1480e-05 - val_loss: 4.4848e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3481e-05 - val_loss: 2.5959e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4908e-05 - val_loss: 2.2881e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1301e-05 - val_loss: 4.3460e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1350e-05 - val_loss: 5.5115e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9825e-05 - val_loss: 2.6446e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0442e-05 - val_loss: 2.4450e-05\n",
            "261/261 [==============================] - 0s 885us/step - loss: 3.2337e-05\n",
            "[CV] ......................... n_neurons=48, n_hidden=4, total=  43.2s\n",
            "[CV] n_neurons=48, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 1.4102e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.5774e-05 - val_loss: 1.1046e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.3462e-05 - val_loss: 6.3397e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5068e-05 - val_loss: 5.6714e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8483e-05 - val_loss: 4.8028e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9879e-05 - val_loss: 4.5239e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3590e-05 - val_loss: 7.9439e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4844e-05 - val_loss: 4.2520e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3116e-05 - val_loss: 1.6288e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.2053e-05 - val_loss: 3.5422e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5541e-05 - val_loss: 6.8290e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7992e-05 - val_loss: 4.4387e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0278e-05 - val_loss: 3.7669e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0605e-05 - val_loss: 7.5356e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1894e-05 - val_loss: 3.0731e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0356e-05 - val_loss: 2.9241e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3035e-05 - val_loss: 4.7879e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1344e-05 - val_loss: 3.3354e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8734e-05 - val_loss: 4.2692e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5354e-05 - val_loss: 8.5423e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2197e-05 - val_loss: 2.9542e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0301e-05 - val_loss: 2.7771e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9951e-05 - val_loss: 3.3306e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3111e-05 - val_loss: 3.9445e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0403e-05 - val_loss: 3.1755e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7702e-05 - val_loss: 1.3202e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4659e-05 - val_loss: 7.4828e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1771e-05 - val_loss: 3.3435e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6546e-05 - val_loss: 2.6647e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2236e-05 - val_loss: 3.2685e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7775e-05 - val_loss: 2.6395e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1801e-05 - val_loss: 6.7338e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0835e-05 - val_loss: 2.6766e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2115e-05 - val_loss: 2.5784e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3502e-05 - val_loss: 3.5046e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1520e-05 - val_loss: 2.8876e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1778e-05 - val_loss: 2.5750e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1511e-05 - val_loss: 3.0688e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0011e-05 - val_loss: 3.4766e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0399e-05 - val_loss: 2.4406e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8385e-05 - val_loss: 4.8104e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7779e-05 - val_loss: 8.8672e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1363e-05 - val_loss: 3.5285e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7377e-05 - val_loss: 3.9213e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0302e-05 - val_loss: 3.2349e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2708e-05 - val_loss: 2.6920e-05\n",
            "Epoch 47/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8266e-05 - val_loss: 2.5685e-05\n",
            "Epoch 48/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8252e-05 - val_loss: 2.6580e-05\n",
            "Epoch 49/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8962e-05 - val_loss: 2.7551e-05\n",
            "Epoch 50/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6349e-05 - val_loss: 2.6765e-05\n",
            "261/261 [==============================] - 0s 903us/step - loss: 2.4540e-05\n",
            "[CV] ......................... n_neurons=48, n_hidden=4, total=  48.5s\n",
            "[CV] n_neurons=44, n_hidden=2 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 1.6727e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 1.4224e-04 - val_loss: 1.1004e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 1.1754e-04 - val_loss: 9.8450e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.1472e-05 - val_loss: 6.0058e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.7346e-05 - val_loss: 4.5722e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6920e-05 - val_loss: 5.2143e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.4930e-05 - val_loss: 4.6278e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3245e-05 - val_loss: 8.1209e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1698e-05 - val_loss: 8.3487e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3791e-05 - val_loss: 7.2383e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5489e-05 - val_loss: 4.3854e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8134e-05 - val_loss: 3.4746e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5304e-05 - val_loss: 5.6026e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5894e-05 - val_loss: 8.8151e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1344e-05 - val_loss: 2.9535e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3521e-05 - val_loss: 7.7153e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6132e-05 - val_loss: 6.6565e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5240e-05 - val_loss: 3.7553e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1915e-05 - val_loss: 4.7314e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 4.2975e-05 - val_loss: 3.3036e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 4.4367e-05 - val_loss: 1.2146e-04\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 4.4180e-05 - val_loss: 4.1457e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3062e-05 - val_loss: 2.7137e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 3.9165e-05 - val_loss: 3.1925e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2001e-05 - val_loss: 2.8115e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8020e-05 - val_loss: 4.3972e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5832e-05 - val_loss: 2.7265e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5931e-05 - val_loss: 3.1209e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5809e-05 - val_loss: 5.7924e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8526e-05 - val_loss: 4.6081e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2398e-05 - val_loss: 2.6856e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3655e-05 - val_loss: 2.7762e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4154e-05 - val_loss: 2.7645e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9373e-05 - val_loss: 2.5244e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3700e-05 - val_loss: 2.6737e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3249e-05 - val_loss: 2.4872e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8372e-05 - val_loss: 3.3366e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4734e-05 - val_loss: 7.8145e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0898e-05 - val_loss: 3.4906e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4903e-05 - val_loss: 4.3337e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1443e-05 - val_loss: 3.0716e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7415e-05 - val_loss: 4.1275e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6382e-05 - val_loss: 4.0832e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4484e-05 - val_loss: 3.2698e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 2.7899e-05 - val_loss: 2.6105e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 3.2920e-05 - val_loss: 5.5538e-05\n",
            "261/261 [==============================] - 0s 944us/step - loss: 9.6885e-05\n",
            "[CV] ......................... n_neurons=44, n_hidden=2, total=  38.3s\n",
            "[CV] n_neurons=44, n_hidden=2 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 2.0101e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 1.4916e-04 - val_loss: 1.5186e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.9657e-05 - val_loss: 9.2170e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.0916e-05 - val_loss: 7.2657e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1797e-05 - val_loss: 3.0780e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8634e-05 - val_loss: 4.6306e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0147e-05 - val_loss: 3.9500e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6733e-05 - val_loss: 5.8361e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4599e-05 - val_loss: 4.7568e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0325e-05 - val_loss: 4.9177e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0329e-05 - val_loss: 3.5897e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2874e-05 - val_loss: 3.9848e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5804e-05 - val_loss: 4.0609e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6091e-05 - val_loss: 1.1348e-04\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6959e-05 - val_loss: 7.4616e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8385e-05 - val_loss: 3.1111e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1135e-05 - val_loss: 4.4707e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1968e-05 - val_loss: 2.8337e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1742e-05 - val_loss: 1.0133e-04\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5952e-05 - val_loss: 3.2339e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3550e-05 - val_loss: 3.0448e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2768e-05 - val_loss: 2.8132e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8472e-05 - val_loss: 3.6389e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7609e-05 - val_loss: 2.7652e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2413e-05 - val_loss: 2.7354e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7290e-05 - val_loss: 1.4952e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0490e-05 - val_loss: 4.7109e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 3.5736e-05 - val_loss: 4.0678e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8771e-05 - val_loss: 2.6988e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7494e-05 - val_loss: 2.5456e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7362e-05 - val_loss: 3.1048e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7117e-05 - val_loss: 2.5880e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2299e-05 - val_loss: 6.2884e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5684e-05 - val_loss: 2.4055e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5592e-05 - val_loss: 2.9598e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1928e-05 - val_loss: 2.4757e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2355e-05 - val_loss: 4.8805e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4499e-05 - val_loss: 3.9085e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6470e-05 - val_loss: 2.4262e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5535e-05 - val_loss: 2.3661e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4402e-05 - val_loss: 2.7517e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 3.2080e-05 - val_loss: 3.2369e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4909e-05 - val_loss: 2.5409e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4334e-05 - val_loss: 4.4862e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0757e-05 - val_loss: 2.5472e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8619e-05 - val_loss: 3.2944e-05\n",
            "Epoch 47/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1560e-05 - val_loss: 3.1738e-05\n",
            "Epoch 48/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2336e-05 - val_loss: 2.6155e-05\n",
            "Epoch 49/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5272e-05 - val_loss: 4.7689e-05\n",
            "Epoch 50/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5757e-05 - val_loss: 2.4274e-05\n",
            "261/261 [==============================] - 0s 861us/step - loss: 2.0056e-05\n",
            "[CV] ......................... n_neurons=44, n_hidden=2, total=  45.2s\n",
            "[CV] n_neurons=44, n_hidden=2 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 2.6186e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.6107e-04 - val_loss: 1.3782e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 1.0075e-04 - val_loss: 9.9541e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.6242e-05 - val_loss: 7.8437e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8123e-05 - val_loss: 6.3518e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0508e-05 - val_loss: 5.7763e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.5867e-05 - val_loss: 5.2043e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8733e-05 - val_loss: 4.8445e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9890e-05 - val_loss: 9.7837e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.4414e-05 - val_loss: 4.6039e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7528e-05 - val_loss: 1.0374e-04\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8544e-05 - val_loss: 7.8924e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9349e-05 - val_loss: 5.1600e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9524e-05 - val_loss: 1.0573e-04\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5794e-05 - val_loss: 4.3699e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4408e-05 - val_loss: 4.0838e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7459e-05 - val_loss: 3.6746e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3766e-05 - val_loss: 3.6593e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5487e-05 - val_loss: 7.5108e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4266e-05 - val_loss: 9.1175e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9801e-05 - val_loss: 4.4558e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2515e-05 - val_loss: 5.6591e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1554e-05 - val_loss: 4.2351e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0964e-05 - val_loss: 3.3528e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 4.2234e-05 - val_loss: 3.9469e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 4.0564e-05 - val_loss: 1.2520e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9947e-05 - val_loss: 2.9578e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0597e-05 - val_loss: 6.1063e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0613e-05 - val_loss: 3.2183e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0453e-05 - val_loss: 3.7215e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 3.6991e-05 - val_loss: 4.5591e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7928e-05 - val_loss: 2.9130e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6897e-05 - val_loss: 2.8432e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9206e-05 - val_loss: 3.7386e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2136e-05 - val_loss: 2.6968e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1869e-05 - val_loss: 2.9537e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8204e-05 - val_loss: 3.5265e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7359e-05 - val_loss: 2.5779e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7134e-05 - val_loss: 2.8748e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2685e-05 - val_loss: 2.7817e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0530e-05 - val_loss: 2.6908e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0815e-05 - val_loss: 3.5462e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 1ms/step - loss: 3.5038e-05 - val_loss: 2.7606e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2306e-05 - val_loss: 4.9995e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4099e-05 - val_loss: 2.7722e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6323e-05 - val_loss: 2.6989e-05\n",
            "Epoch 47/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3072e-05 - val_loss: 4.1507e-05\n",
            "Epoch 48/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9159e-05 - val_loss: 3.2646e-05\n",
            "261/261 [==============================] - 0s 927us/step - loss: 2.8340e-05\n",
            "[CV] ......................... n_neurons=44, n_hidden=2, total=  43.3s\n",
            "[CV] n_neurons=40, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 9.5104e-04 - val_loss: 1.1430e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.3224e-05 - val_loss: 1.0235e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.7586e-05 - val_loss: 1.3078e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0167e-05 - val_loss: 7.3736e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8755e-05 - val_loss: 4.4939e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8424e-05 - val_loss: 4.2745e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3971e-05 - val_loss: 4.9996e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2338e-05 - val_loss: 4.3280e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8578e-05 - val_loss: 1.5776e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5976e-05 - val_loss: 5.7448e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2284e-05 - val_loss: 3.1195e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 3.6490e-05 - val_loss: 3.6267e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 4.0060e-05 - val_loss: 3.1768e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 4.2654e-05 - val_loss: 3.4455e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6832e-05 - val_loss: 2.8692e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1740e-05 - val_loss: 4.1024e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9798e-05 - val_loss: 5.1667e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2645e-05 - val_loss: 4.7060e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8051e-05 - val_loss: 2.7109e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1912e-05 - val_loss: 2.9676e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3046e-05 - val_loss: 3.4027e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3026e-05 - val_loss: 2.8838e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2062e-05 - val_loss: 2.9451e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1052e-05 - val_loss: 2.6715e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4539e-05 - val_loss: 2.8597e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1539e-05 - val_loss: 2.5380e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9326e-05 - val_loss: 4.2905e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9712e-05 - val_loss: 2.5805e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4298e-05 - val_loss: 3.1725e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6539e-05 - val_loss: 2.5082e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0844e-05 - val_loss: 3.1240e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2203e-05 - val_loss: 3.0118e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7412e-05 - val_loss: 2.9147e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0989e-05 - val_loss: 2.6842e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0233e-05 - val_loss: 3.4082e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7880e-05 - val_loss: 2.8170e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.5926e-05 - val_loss: 3.0912e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9815e-05 - val_loss: 5.1332e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9651e-05 - val_loss: 9.2137e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8726e-05 - val_loss: 5.3036e-05\n",
            "261/261 [==============================] - 0s 836us/step - loss: 8.0731e-05\n",
            "[CV] ......................... n_neurons=40, n_hidden=4, total=  40.7s\n",
            "[CV] n_neurons=40, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 1.3800e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.1380e-04 - val_loss: 8.1642e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0923e-05 - val_loss: 6.3454e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.3789e-05 - val_loss: 6.9789e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2324e-05 - val_loss: 2.1938e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8365e-05 - val_loss: 5.2366e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6783e-05 - val_loss: 4.6909e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9218e-05 - val_loss: 4.9037e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1913e-05 - val_loss: 4.2996e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.6823e-05 - val_loss: 4.1197e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9461e-05 - val_loss: 3.7216e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8433e-05 - val_loss: 4.7539e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7536e-05 - val_loss: 3.4832e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6330e-05 - val_loss: 9.6215e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5293e-05 - val_loss: 5.5713e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9552e-05 - val_loss: 3.0094e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2047e-05 - val_loss: 4.9557e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3178e-05 - val_loss: 2.5933e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9243e-05 - val_loss: 1.0490e-04\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3357e-05 - val_loss: 2.5978e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2624e-05 - val_loss: 4.4849e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2878e-05 - val_loss: 2.9931e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5834e-05 - val_loss: 2.6466e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2958e-05 - val_loss: 2.7116e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2170e-05 - val_loss: 2.6374e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4125e-05 - val_loss: 1.4016e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7474e-05 - val_loss: 3.3414e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6740e-05 - val_loss: 3.7818e-05\n",
            "261/261 [==============================] - 0s 904us/step - loss: 3.2829e-05\n",
            "[CV] ......................... n_neurons=40, n_hidden=4, total=  27.0s\n",
            "[CV] n_neurons=40, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 1.4810e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.4260e-05 - val_loss: 7.2811e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9694e-05 - val_loss: 1.0438e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.6257e-05 - val_loss: 1.0123e-04\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8195e-05 - val_loss: 6.8546e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.7539e-05 - val_loss: 5.1633e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6765e-05 - val_loss: 1.2094e-04\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9984e-05 - val_loss: 3.8525e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7834e-05 - val_loss: 1.8768e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1334e-05 - val_loss: 4.5348e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4874e-05 - val_loss: 4.6880e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8092e-05 - val_loss: 4.3463e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4250e-05 - val_loss: 4.3676e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2819e-05 - val_loss: 6.1548e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4097e-05 - val_loss: 3.2436e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5485e-05 - val_loss: 2.9748e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1644e-05 - val_loss: 5.4888e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1241e-05 - val_loss: 2.9876e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5144e-05 - val_loss: 3.3232e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0666e-05 - val_loss: 3.1680e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7362e-05 - val_loss: 4.5875e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9876e-05 - val_loss: 3.0633e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5785e-05 - val_loss: 2.7126e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1602e-05 - val_loss: 5.1367e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2922e-05 - val_loss: 3.0811e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2227e-05 - val_loss: 1.1793e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2453e-05 - val_loss: 4.8794e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0831e-05 - val_loss: 2.9937e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4190e-05 - val_loss: 3.1042e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3606e-05 - val_loss: 2.9853e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4668e-05 - val_loss: 2.5022e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0613e-05 - val_loss: 7.5417e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9293e-05 - val_loss: 3.2233e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1040e-05 - val_loss: 3.1484e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9204e-05 - val_loss: 2.5215e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9767e-05 - val_loss: 2.6178e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9251e-05 - val_loss: 2.7109e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1679e-05 - val_loss: 2.8593e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8920e-05 - val_loss: 3.0197e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0694e-05 - val_loss: 2.3571e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0079e-05 - val_loss: 2.4225e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0746e-05 - val_loss: 2.5023e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9033e-05 - val_loss: 2.5249e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.5702e-05 - val_loss: 2.5418e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7024e-05 - val_loss: 2.8150e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2015e-05 - val_loss: 3.6571e-05\n",
            "Epoch 47/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8009e-05 - val_loss: 2.5169e-05\n",
            "Epoch 48/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6774e-05 - val_loss: 2.9043e-05\n",
            "Epoch 49/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6111e-05 - val_loss: 2.3465e-05\n",
            "Epoch 50/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7183e-05 - val_loss: 2.8007e-05\n",
            "Epoch 51/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1275e-05 - val_loss: 5.5175e-05\n",
            "Epoch 52/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7056e-05 - val_loss: 2.6486e-05\n",
            "Epoch 53/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6378e-05 - val_loss: 5.5950e-05\n",
            "Epoch 54/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4661e-05 - val_loss: 4.2393e-05\n",
            "Epoch 55/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6266e-05 - val_loss: 5.6397e-05\n",
            "Epoch 56/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0620e-05 - val_loss: 2.4926e-05\n",
            "Epoch 57/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4539e-05 - val_loss: 2.3092e-05\n",
            "Epoch 58/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4200e-05 - val_loss: 2.8714e-05\n",
            "Epoch 59/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7307e-05 - val_loss: 3.0416e-05\n",
            "Epoch 60/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.5364e-05 - val_loss: 2.4654e-05\n",
            "Epoch 61/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.5323e-05 - val_loss: 2.5918e-05\n",
            "Epoch 62/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6393e-05 - val_loss: 2.4815e-05\n",
            "Epoch 63/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.3267e-05 - val_loss: 2.9628e-05\n",
            "Epoch 64/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6236e-05 - val_loss: 5.1419e-05\n",
            "Epoch 65/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4422e-05 - val_loss: 2.3889e-05\n",
            "Epoch 66/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6526e-05 - val_loss: 2.3412e-05\n",
            "Epoch 67/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4636e-05 - val_loss: 2.4750e-05\n",
            "261/261 [==============================] - 0s 860us/step - loss: 2.3729e-05\n",
            "[CV] ......................... n_neurons=40, n_hidden=4, total= 1.0min\n",
            "[CV] n_neurons=47, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8473e-04 - val_loss: 1.7064e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.2451e-05 - val_loss: 7.6585e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9969e-05 - val_loss: 1.4366e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9857e-05 - val_loss: 6.5780e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3030e-05 - val_loss: 6.1217e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0393e-05 - val_loss: 5.3213e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4952e-05 - val_loss: 3.9121e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8769e-05 - val_loss: 3.8021e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6579e-05 - val_loss: 1.0079e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2975e-05 - val_loss: 8.6464e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3514e-05 - val_loss: 5.2528e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7697e-05 - val_loss: 6.3596e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8737e-05 - val_loss: 3.1111e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1825e-05 - val_loss: 2.9811e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3806e-05 - val_loss: 3.4837e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8148e-05 - val_loss: 3.1554e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7234e-05 - val_loss: 6.2554e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2515e-05 - val_loss: 8.4037e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7877e-05 - val_loss: 3.6580e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1865e-05 - val_loss: 3.1412e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3111e-05 - val_loss: 6.2265e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5130e-05 - val_loss: 3.4827e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2121e-05 - val_loss: 3.0136e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1038e-05 - val_loss: 3.4679e-05\n",
            "261/261 [==============================] - 0s 884us/step - loss: 3.3181e-05\n",
            "[CV] ......................... n_neurons=47, n_hidden=3, total=  22.1s\n",
            "[CV] n_neurons=47, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.3773e-04 - val_loss: 1.1668e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.0074e-04 - val_loss: 9.2365e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8072e-05 - val_loss: 7.0586e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.1170e-05 - val_loss: 5.1805e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0162e-05 - val_loss: 1.2455e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.6349e-05 - val_loss: 4.2444e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2453e-05 - val_loss: 4.7498e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2248e-05 - val_loss: 5.0182e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6092e-05 - val_loss: 3.8965e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0149e-05 - val_loss: 3.9694e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3801e-05 - val_loss: 3.6351e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5132e-05 - val_loss: 5.9522e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4959e-05 - val_loss: 3.8808e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7075e-05 - val_loss: 1.4716e-04\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8636e-05 - val_loss: 6.9714e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2567e-05 - val_loss: 3.7930e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7887e-05 - val_loss: 4.0126e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5351e-05 - val_loss: 3.9165e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2248e-05 - val_loss: 1.6414e-04\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8825e-05 - val_loss: 3.1350e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8805e-05 - val_loss: 3.3646e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0616e-05 - val_loss: 2.8677e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2963e-05 - val_loss: 3.0020e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4222e-05 - val_loss: 3.0145e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2432e-05 - val_loss: 3.2927e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6155e-05 - val_loss: 1.9396e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5013e-05 - val_loss: 5.3348e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6851e-05 - val_loss: 5.1219e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9650e-05 - val_loss: 3.1909e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6143e-05 - val_loss: 2.8124e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6616e-05 - val_loss: 2.8132e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7950e-05 - val_loss: 3.0387e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0506e-05 - val_loss: 3.0057e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5985e-05 - val_loss: 2.6203e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3377e-05 - val_loss: 3.9496e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4889e-05 - val_loss: 3.4061e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4052e-05 - val_loss: 3.4750e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6341e-05 - val_loss: 4.2989e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8318e-05 - val_loss: 3.1773e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4250e-05 - val_loss: 3.7951e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3942e-05 - val_loss: 4.4309e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4713e-05 - val_loss: 4.8405e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1999e-05 - val_loss: 3.2177e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5217e-05 - val_loss: 4.4539e-05\n",
            "261/261 [==============================] - 0s 912us/step - loss: 2.9820e-05\n",
            "[CV] ......................... n_neurons=47, n_hidden=3, total=  40.0s\n",
            "[CV] n_neurons=47, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 1.1833e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.9319e-05 - val_loss: 9.1078e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.5054e-05 - val_loss: 7.6298e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.0393e-05 - val_loss: 6.7310e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1966e-05 - val_loss: 5.7451e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8884e-05 - val_loss: 5.9522e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5324e-05 - val_loss: 4.0938e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3356e-05 - val_loss: 4.0919e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6202e-05 - val_loss: 2.3651e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5642e-05 - val_loss: 6.0336e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7308e-05 - val_loss: 7.0981e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0671e-05 - val_loss: 6.0258e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1672e-05 - val_loss: 2.9666e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5727e-05 - val_loss: 6.7041e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0916e-05 - val_loss: 3.2859e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5437e-05 - val_loss: 3.2593e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7764e-05 - val_loss: 4.4114e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8600e-05 - val_loss: 4.1519e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8217e-05 - val_loss: 2.8828e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9814e-05 - val_loss: 7.0826e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4109e-05 - val_loss: 4.8060e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5691e-05 - val_loss: 3.8062e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9191e-05 - val_loss: 3.0620e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4374e-05 - val_loss: 4.6211e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0205e-05 - val_loss: 3.9672e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8205e-05 - val_loss: 3.5965e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2953e-05 - val_loss: 3.1446e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3381e-05 - val_loss: 3.3314e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5566e-05 - val_loss: 2.6153e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0074e-05 - val_loss: 2.9035e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5435e-05 - val_loss: 2.7591e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9749e-05 - val_loss: 3.6019e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9627e-05 - val_loss: 2.7396e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0310e-05 - val_loss: 2.7852e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0218e-05 - val_loss: 3.1707e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0215e-05 - val_loss: 2.8437e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1889e-05 - val_loss: 2.8111e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0759e-05 - val_loss: 3.5025e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9035e-05 - val_loss: 3.3051e-05\n",
            "261/261 [==============================] - 0s 909us/step - loss: 2.7709e-05\n",
            "[CV] ......................... n_neurons=47, n_hidden=3, total=  35.9s\n",
            "[CV] n_neurons=49, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.7427e-04 - val_loss: 1.4326e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.8356e-05 - val_loss: 1.3352e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.0465e-05 - val_loss: 1.6904e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2657e-05 - val_loss: 1.0988e-04\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4753e-05 - val_loss: 4.6292e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7854e-05 - val_loss: 5.8799e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7831e-05 - val_loss: 4.9769e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5724e-05 - val_loss: 4.0929e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5804e-05 - val_loss: 1.0607e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3600e-05 - val_loss: 5.7923e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3847e-05 - val_loss: 7.4231e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5948e-05 - val_loss: 3.4403e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3007e-05 - val_loss: 4.3169e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5178e-05 - val_loss: 3.4316e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5538e-05 - val_loss: 3.2082e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4068e-05 - val_loss: 3.2707e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3277e-05 - val_loss: 6.1221e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1317e-05 - val_loss: 4.6577e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1138e-05 - val_loss: 2.7659e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2309e-05 - val_loss: 3.7715e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1975e-05 - val_loss: 1.0108e-04\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2576e-05 - val_loss: 2.8940e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3544e-05 - val_loss: 2.6475e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1260e-05 - val_loss: 2.7970e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5804e-05 - val_loss: 3.1038e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2419e-05 - val_loss: 3.6607e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9136e-05 - val_loss: 4.4295e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0094e-05 - val_loss: 2.9639e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4680e-05 - val_loss: 2.7861e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7615e-05 - val_loss: 3.7303e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0290e-05 - val_loss: 3.4061e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0142e-05 - val_loss: 2.7429e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2952e-05 - val_loss: 2.6466e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2025e-05 - val_loss: 3.1517e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3818e-05 - val_loss: 2.6692e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8720e-05 - val_loss: 2.8563e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8073e-05 - val_loss: 2.7991e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9797e-05 - val_loss: 6.6336e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8545e-05 - val_loss: 5.8142e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9968e-05 - val_loss: 8.3422e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8405e-05 - val_loss: 4.8365e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6488e-05 - val_loss: 4.5514e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1168e-05 - val_loss: 3.0871e-05\n",
            "261/261 [==============================] - 0s 1ms/step - loss: 2.2570e-05\n",
            "[CV] ......................... n_neurons=49, n_hidden=3, total=  40.0s\n",
            "[CV] n_neurons=49, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0031 - val_loss: 1.7673e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.0932e-04 - val_loss: 9.3075e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 8.2918e-05 - val_loss: 7.5905e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 2s 3ms/step - loss: 7.2452e-05 - val_loss: 8.8965e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 6.2789e-05 - val_loss: 1.0858e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 6.0352e-05 - val_loss: 8.9857e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7927e-05 - val_loss: 5.4773e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6930e-05 - val_loss: 4.2141e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6079e-05 - val_loss: 5.2476e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.4430e-05 - val_loss: 5.6003e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7444e-05 - val_loss: 4.2066e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5418e-05 - val_loss: 4.0297e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2547e-05 - val_loss: 3.2082e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4093e-05 - val_loss: 6.2771e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8324e-05 - val_loss: 6.2139e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2375e-05 - val_loss: 4.0847e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6578e-05 - val_loss: 4.1368e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0581e-05 - val_loss: 3.4372e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2787e-05 - val_loss: 7.6817e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7517e-05 - val_loss: 4.5769e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0322e-05 - val_loss: 3.7661e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2162e-05 - val_loss: 4.5594e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9098e-05 - val_loss: 5.2052e-05\n",
            "261/261 [==============================] - 0s 959us/step - loss: 3.1767e-05\n",
            "[CV] ......................... n_neurons=49, n_hidden=3, total=  25.5s\n",
            "[CV] n_neurons=49, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 1.5521e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.0144e-04 - val_loss: 9.9870e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1948e-05 - val_loss: 7.3198e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1934e-05 - val_loss: 7.3204e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7714e-05 - val_loss: 5.6360e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9497e-05 - val_loss: 5.7817e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4369e-05 - val_loss: 5.3442e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9753e-05 - val_loss: 4.6219e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0862e-05 - val_loss: 6.6535e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9626e-05 - val_loss: 5.0555e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0619e-05 - val_loss: 8.3540e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3512e-05 - val_loss: 4.1444e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9051e-05 - val_loss: 4.2826e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0926e-05 - val_loss: 5.8032e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1306e-05 - val_loss: 3.7989e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8618e-05 - val_loss: 3.7489e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1659e-05 - val_loss: 4.3586e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6936e-05 - val_loss: 3.0726e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6345e-05 - val_loss: 5.2915e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4764e-05 - val_loss: 3.0488e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8427e-05 - val_loss: 4.5047e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2861e-05 - val_loss: 2.7915e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4388e-05 - val_loss: 3.0436e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4043e-05 - val_loss: 3.3816e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1231e-05 - val_loss: 5.0560e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3268e-05 - val_loss: 1.3474e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 3.2916e-05 - val_loss: 7.1765e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 3.3245e-05 - val_loss: 2.5733e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 3ms/step - loss: 3.3141e-05 - val_loss: 3.1105e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2380e-05 - val_loss: 2.9387e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3774e-05 - val_loss: 3.3857e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9514e-05 - val_loss: 9.2257e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0033e-05 - val_loss: 2.7039e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1188e-05 - val_loss: 2.7946e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7976e-05 - val_loss: 3.0323e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8932e-05 - val_loss: 2.5347e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8667e-05 - val_loss: 2.7972e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0519e-05 - val_loss: 3.3046e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8852e-05 - val_loss: 3.2903e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9946e-05 - val_loss: 2.6841e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9662e-05 - val_loss: 2.9317e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8509e-05 - val_loss: 3.9525e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9851e-05 - val_loss: 2.7079e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4682e-05 - val_loss: 2.6349e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7414e-05 - val_loss: 3.7206e-05\n",
            "Epoch 46/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0696e-05 - val_loss: 4.3340e-05\n",
            "261/261 [==============================] - 0s 878us/step - loss: 4.2329e-05\n",
            "[CV] ......................... n_neurons=49, n_hidden=3, total=  44.5s\n",
            "[CV] n_neurons=51, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9494e-04 - val_loss: 2.0100e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.5353e-05 - val_loss: 1.2700e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9201e-05 - val_loss: 9.7851e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9002e-05 - val_loss: 5.1086e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1845e-05 - val_loss: 4.7279e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9184e-05 - val_loss: 6.1772e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0568e-05 - val_loss: 6.6561e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6398e-05 - val_loss: 5.0323e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6900e-05 - val_loss: 1.0752e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0749e-05 - val_loss: 8.5252e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5671e-05 - val_loss: 5.4385e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8532e-05 - val_loss: 7.2939e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3622e-05 - val_loss: 8.1485e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4690e-05 - val_loss: 3.5288e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6745e-05 - val_loss: 3.8290e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0679e-05 - val_loss: 4.0645e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7665e-05 - val_loss: 5.8046e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4253e-05 - val_loss: 6.8275e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2493e-05 - val_loss: 4.2329e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1762e-05 - val_loss: 4.1122e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4572e-05 - val_loss: 5.7369e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7619e-05 - val_loss: 5.8105e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2805e-05 - val_loss: 3.5522e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3425e-05 - val_loss: 4.6749e-05\n",
            "261/261 [==============================] - 0s 883us/step - loss: 4.5273e-05\n",
            "[CV] ......................... n_neurons=51, n_hidden=3, total=  22.4s\n",
            "[CV] n_neurons=51, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.3161e-04 - val_loss: 8.8910e-05\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.7405e-05 - val_loss: 5.8113e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.2306e-05 - val_loss: 6.9620e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.4261e-05 - val_loss: 1.0531e-04\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.5759e-05 - val_loss: 5.4083e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.4153e-05 - val_loss: 3.9763e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.8156e-05 - val_loss: 4.0391e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.1755e-05 - val_loss: 4.1183e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.4412e-05 - val_loss: 3.0116e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.1437e-05 - val_loss: 2.9944e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0349e-05 - val_loss: 2.8538e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.5994e-05 - val_loss: 1.2842e-04\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8477e-05 - val_loss: 2.7749e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6630e-05 - val_loss: 9.3343e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8062e-05 - val_loss: 2.7953e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1220e-05 - val_loss: 3.2055e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8094e-05 - val_loss: 3.5356e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.0137e-05 - val_loss: 5.6942e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5127e-05 - val_loss: 8.2789e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8629e-05 - val_loss: 7.0465e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5875e-05 - val_loss: 3.0752e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1776e-05 - val_loss: 2.9454e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8440e-05 - val_loss: 2.7582e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0546e-05 - val_loss: 2.6803e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0320e-05 - val_loss: 3.9090e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1049e-05 - val_loss: 2.0081e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2192e-05 - val_loss: 3.2254e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8828e-05 - val_loss: 4.9526e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8149e-05 - val_loss: 4.0340e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3886e-05 - val_loss: 2.8226e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1471e-05 - val_loss: 6.2833e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9019e-05 - val_loss: 4.3960e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2393e-05 - val_loss: 3.0532e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1141e-05 - val_loss: 3.2700e-05\n",
            "261/261 [==============================] - 0s 939us/step - loss: 4.4617e-05\n",
            "[CV] ......................... n_neurons=51, n_hidden=3, total=  31.7s\n",
            "[CV] n_neurons=51, n_hidden=3 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 1.5253e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.2039e-04 - val_loss: 9.6722e-05\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.2215e-05 - val_loss: 2.7462e-04\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.0084e-04 - val_loss: 5.9810e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.3842e-05 - val_loss: 6.9691e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.7526e-05 - val_loss: 6.4033e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.6246e-05 - val_loss: 4.1741e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.5928e-05 - val_loss: 3.9221e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8552e-05 - val_loss: 1.3308e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4990e-05 - val_loss: 4.7928e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.5356e-05 - val_loss: 1.6483e-04\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0227e-05 - val_loss: 7.7906e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9346e-05 - val_loss: 5.4949e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.2705e-05 - val_loss: 1.8923e-04\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3161e-05 - val_loss: 4.3259e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.3600e-05 - val_loss: 4.1379e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7666e-05 - val_loss: 3.1955e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0675e-05 - val_loss: 4.4700e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1067e-05 - val_loss: 8.9629e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2692e-05 - val_loss: 2.7806e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1999e-05 - val_loss: 5.8552e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1787e-05 - val_loss: 2.8593e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9654e-05 - val_loss: 3.3386e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7286e-05 - val_loss: 3.8581e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1871e-05 - val_loss: 2.8210e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6347e-05 - val_loss: 1.5133e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4918e-05 - val_loss: 3.0336e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5595e-05 - val_loss: 4.6973e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5887e-05 - val_loss: 2.8672e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5870e-05 - val_loss: 2.9703e-05\n",
            "261/261 [==============================] - 0s 875us/step - loss: 2.5909e-05\n",
            "[CV] ......................... n_neurons=51, n_hidden=3, total=  28.1s\n",
            "[CV] n_neurons=55, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0025 - val_loss: 1.0896e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.4991e-05 - val_loss: 1.0368e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.1034e-05 - val_loss: 5.2445e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2467e-05 - val_loss: 5.1370e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7817e-05 - val_loss: 4.4239e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7449e-05 - val_loss: 4.6124e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9855e-05 - val_loss: 3.8615e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.6943e-05 - val_loss: 3.7457e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3099e-05 - val_loss: 1.0893e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6670e-05 - val_loss: 5.1445e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8277e-05 - val_loss: 5.4643e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1327e-05 - val_loss: 3.2660e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7873e-05 - val_loss: 8.3322e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8310e-05 - val_loss: 3.2088e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5831e-05 - val_loss: 3.0837e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9473e-05 - val_loss: 7.1548e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5303e-05 - val_loss: 6.7853e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8328e-05 - val_loss: 2.7690e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5653e-05 - val_loss: 3.8775e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5717e-05 - val_loss: 5.2559e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9263e-05 - val_loss: 8.2665e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4623e-05 - val_loss: 5.7094e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7700e-05 - val_loss: 2.7352e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3813e-05 - val_loss: 2.8543e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9232e-05 - val_loss: 2.4794e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5831e-05 - val_loss: 3.9006e-05\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2019e-05 - val_loss: 3.7458e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8035e-05 - val_loss: 2.8007e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3435e-05 - val_loss: 4.5218e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2050e-05 - val_loss: 2.6502e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1435e-05 - val_loss: 3.4181e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9533e-05 - val_loss: 3.5853e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0890e-05 - val_loss: 3.5113e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2490e-05 - val_loss: 2.6726e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5553e-05 - val_loss: 2.8670e-05\n",
            "261/261 [==============================] - 0s 976us/step - loss: 2.5417e-05\n",
            "[CV] ......................... n_neurons=55, n_hidden=4, total=  36.0s\n",
            "[CV] n_neurons=55, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0026 - val_loss: 1.5498e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 1.1287e-04 - val_loss: 1.4490e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.2602e-05 - val_loss: 7.2166e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.0916e-05 - val_loss: 7.2772e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.7039e-05 - val_loss: 1.9970e-04\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.9106e-05 - val_loss: 5.5278e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.4110e-05 - val_loss: 5.2021e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8669e-05 - val_loss: 6.7944e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.0677e-05 - val_loss: 4.4998e-05\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.2548e-05 - val_loss: 5.2321e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.9190e-05 - val_loss: 4.6475e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.7079e-05 - val_loss: 4.9055e-05\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.8110e-05 - val_loss: 4.9059e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.1836e-05 - val_loss: 7.7775e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.4062e-05 - val_loss: 4.7349e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6568e-05 - val_loss: 3.3299e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4882e-05 - val_loss: 4.1180e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.9022e-05 - val_loss: 2.9154e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2296e-05 - val_loss: 8.0800e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8093e-05 - val_loss: 2.9737e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.5510e-05 - val_loss: 3.4835e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8115e-05 - val_loss: 3.1963e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.1635e-05 - val_loss: 4.2918e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6406e-05 - val_loss: 2.9132e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.7212e-05 - val_loss: 5.6470e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2192e-05 - val_loss: 1.5107e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0692e-05 - val_loss: 5.9600e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0393e-05 - val_loss: 2.9529e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8729e-05 - val_loss: 3.7394e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6740e-05 - val_loss: 3.3943e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0602e-05 - val_loss: 6.8277e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6314e-05 - val_loss: 4.2970e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0129e-05 - val_loss: 4.5535e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5439e-05 - val_loss: 2.4869e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5766e-05 - val_loss: 3.8361e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2437e-05 - val_loss: 3.1001e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.1940e-05 - val_loss: 3.6979e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2633e-05 - val_loss: 4.6578e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0377e-05 - val_loss: 4.4526e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6492e-05 - val_loss: 2.5275e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2171e-05 - val_loss: 7.1656e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5280e-05 - val_loss: 7.1474e-05\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2352e-05 - val_loss: 2.5749e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4312e-05 - val_loss: 2.9358e-05\n",
            "261/261 [==============================] - 0s 918us/step - loss: 2.5741e-05\n",
            "[CV] ......................... n_neurons=55, n_hidden=4, total=  45.4s\n",
            "[CV] n_neurons=55, n_hidden=4 ........................................\n",
            "Epoch 1/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 1.2734e-04\n",
            "Epoch 2/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 8.9022e-05 - val_loss: 1.2631e-04\n",
            "Epoch 3/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.0382e-05 - val_loss: 8.2199e-05\n",
            "Epoch 4/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.5345e-05 - val_loss: 6.5627e-05\n",
            "Epoch 5/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 9.0578e-05 - val_loss: 6.2053e-05\n",
            "Epoch 6/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.0235e-05 - val_loss: 6.9455e-05\n",
            "Epoch 7/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.4215e-05 - val_loss: 6.9355e-05\n",
            "Epoch 8/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.8036e-05 - val_loss: 5.2425e-05\n",
            "Epoch 9/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3525e-05 - val_loss: 1.1933e-04\n",
            "Epoch 10/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 7.4934e-05 - val_loss: 4.1866e-05\n",
            "Epoch 11/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 6.7417e-05 - val_loss: 7.1471e-05\n",
            "Epoch 12/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3756e-05 - val_loss: 1.4294e-04\n",
            "Epoch 13/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7172e-05 - val_loss: 3.8159e-05\n",
            "Epoch 14/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.3164e-05 - val_loss: 4.3791e-05\n",
            "Epoch 15/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.4832e-05 - val_loss: 4.3563e-05\n",
            "Epoch 16/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 5.2272e-05 - val_loss: 4.7407e-05\n",
            "Epoch 17/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.8069e-05 - val_loss: 5.9548e-05\n",
            "Epoch 18/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.7463e-05 - val_loss: 3.6784e-05\n",
            "Epoch 19/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.0453e-05 - val_loss: 5.1927e-05\n",
            "Epoch 20/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.2737e-05 - val_loss: 5.1467e-05\n",
            "Epoch 21/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6483e-05 - val_loss: 3.3204e-05\n",
            "Epoch 22/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.6103e-05 - val_loss: 3.8344e-05\n",
            "Epoch 23/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.8555e-05 - val_loss: 4.0677e-05\n",
            "Epoch 24/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4421e-05 - val_loss: 3.6170e-05\n",
            "Epoch 25/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 4.4578e-05 - val_loss: 3.1424e-05\n",
            "Epoch 26/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.9302e-05 - val_loss: 1.4858e-04\n",
            "Epoch 27/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3179e-05 - val_loss: 4.8805e-05\n",
            "Epoch 28/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.4875e-05 - val_loss: 2.5351e-05\n",
            "Epoch 29/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.5146e-05 - val_loss: 3.1973e-05\n",
            "Epoch 30/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2103e-05 - val_loss: 2.7372e-05\n",
            "Epoch 31/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.6347e-05 - val_loss: 3.5239e-05\n",
            "Epoch 32/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9806e-05 - val_loss: 6.7490e-05\n",
            "Epoch 33/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3713e-05 - val_loss: 2.5550e-05\n",
            "Epoch 34/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3062e-05 - val_loss: 2.8788e-05\n",
            "Epoch 35/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8763e-05 - val_loss: 2.4772e-05\n",
            "Epoch 36/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.6857e-05 - val_loss: 2.9485e-05\n",
            "Epoch 37/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9136e-05 - val_loss: 3.0022e-05\n",
            "Epoch 38/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.2850e-05 - val_loss: 2.9997e-05\n",
            "Epoch 39/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3571e-05 - val_loss: 3.0821e-05\n",
            "Epoch 40/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.9847e-05 - val_loss: 2.6131e-05\n",
            "Epoch 41/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.0247e-05 - val_loss: 2.7591e-05\n",
            "Epoch 42/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.7823e-05 - val_loss: 1.1001e-04\n",
            "Epoch 43/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 3.3588e-05 - val_loss: 2.9018e-05\n",
            "Epoch 44/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.4796e-05 - val_loss: 2.7400e-05\n",
            "Epoch 45/70\n",
            "521/521 [==============================] - 1s 2ms/step - loss: 2.8755e-05 - val_loss: 3.6609e-05\n",
            "261/261 [==============================] - 0s 937us/step - loss: 3.2278e-05\n",
            "[CV] ......................... n_neurons=55, n_hidden=4, total=  46.2s\n",
            "Epoch 1/70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 18.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 4.6973e-04 - val_loss: 1.1922e-04\n",
            "Epoch 2/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 7.9129e-05 - val_loss: 1.4422e-04\n",
            "Epoch 3/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 6.9994e-05 - val_loss: 9.9681e-05\n",
            "Epoch 4/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 7.1986e-05 - val_loss: 9.0330e-05\n",
            "Epoch 5/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 6.4063e-05 - val_loss: 6.4108e-05\n",
            "Epoch 6/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 5.5051e-05 - val_loss: 3.7914e-05\n",
            "Epoch 7/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.0688e-05 - val_loss: 3.2745e-05\n",
            "Epoch 8/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 5.7674e-05 - val_loss: 1.1017e-04\n",
            "Epoch 9/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.8241e-05 - val_loss: 5.7621e-05\n",
            "Epoch 10/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.3200e-05 - val_loss: 3.2616e-05\n",
            "Epoch 11/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.4633e-05 - val_loss: 2.8259e-05\n",
            "Epoch 12/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.5311e-05 - val_loss: 4.2442e-05\n",
            "Epoch 13/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.4474e-05 - val_loss: 3.7974e-05\n",
            "Epoch 14/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.3775e-05 - val_loss: 1.0539e-04\n",
            "Epoch 15/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.2337e-05 - val_loss: 5.8449e-05\n",
            "Epoch 16/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.9711e-05 - val_loss: 2.6977e-05\n",
            "Epoch 17/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.4268e-05 - val_loss: 4.8378e-05\n",
            "Epoch 18/70\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 4.2424e-05 - val_loss: 4.0910e-05\n",
            "Epoch 19/70\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.1555e-05 - val_loss: 8.0928e-05\n",
            "Epoch 20/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.3380e-05 - val_loss: 4.2943e-05\n",
            "Epoch 21/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.6493e-05 - val_loss: 4.6336e-05\n",
            "Epoch 22/70\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.9667e-05 - val_loss: 5.9389e-05\n",
            "Epoch 23/70\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.4636e-05 - val_loss: 9.0795e-05\n",
            "Epoch 24/70\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.3183e-05 - val_loss: 2.9540e-05\n",
            "Epoch 25/70\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.0689e-05 - val_loss: 2.8565e-05\n",
            "Epoch 26/70\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 3.2291e-05 - val_loss: 3.0063e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f23bb051a58>,\n",
              "                   iid='warn', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'n_hidden': [2, 3, 4],\n",
              "                                        'n_neurons': array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
              "       57, 58, 59])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnXsTEsWL7eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c534cf8-5174-437a-f40d-069b5f7b86e6"
      },
      "source": [
        "model.evaluate(X_test, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 0s 906us/step - loss: 3.4346e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.434603786445223e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ30tfTrHPoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1ef86723-66c7-41bd-a37c-40143b53a2c9"
      },
      "source": [
        "!pip uninstall sklearn\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling sklearn-0.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/sklearn-0.0.dist-info/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled sklearn-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbIQ0kPjra3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-learn==0.21.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItDLEeJKns_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "db8f4d15-6055-4132-f4cf-94f304811445"
      },
      "source": [
        "model = rnd_search_cv.best_estimator_.model\n",
        "model\n",
        "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkFhQrLSns8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8db0427e-348c-4b53-9725-ddbf54de49ac"
      },
      "source": [
        "\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "\n",
        "\n",
        "#### dense model use as baseline\n",
        "\n",
        "#loss: 2.9652e-05 - mean_absolute_error: 0.0034 [2.9652341254404746e-05, 0.0033624102361500263]\n",
        "#sklearn mae - 3.3048239\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[X.shape[1],X.shape[2]]),                   \n",
        "    tf.keras.layers.Dense(units=55, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=55, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=55, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=55, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint_cb,tensorboard_cb], shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/782 [..............................] - ETA: 25s - loss: 0.2558 - mean_absolute_error: 0.4162WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_train_batch_end` time: 0.0597s). Check your callbacks.\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.0013 - mean_absolute_error: 0.0133 - val_loss: 9.8371e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 8.1850e-05 - mean_absolute_error: 0.0069 - val_loss: 6.6538e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 6.6287e-05 - mean_absolute_error: 0.0061 - val_loss: 4.9322e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 5.9070e-05 - mean_absolute_error: 0.0057 - val_loss: 4.1626e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 5.4755e-05 - mean_absolute_error: 0.0055 - val_loss: 8.4710e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 5.6624e-05 - mean_absolute_error: 0.0056 - val_loss: 3.5041e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.4570e-05 - mean_absolute_error: 0.0050 - val_loss: 3.2697e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 5.1960e-05 - mean_absolute_error: 0.0054 - val_loss: 1.4358e-04 - val_mean_absolute_error: 0.0106\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.5895e-05 - mean_absolute_error: 0.0050 - val_loss: 3.4933e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.1408e-05 - mean_absolute_error: 0.0047 - val_loss: 2.6756e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 5.0706e-05 - mean_absolute_error: 0.0053 - val_loss: 3.4014e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.0992e-05 - mean_absolute_error: 0.0047 - val_loss: 3.1157e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.7329e-05 - mean_absolute_error: 0.0044 - val_loss: 3.9961e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.2389e-05 - mean_absolute_error: 0.0048 - val_loss: 4.3722e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.1528e-05 - mean_absolute_error: 0.0040 - val_loss: 3.4259e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.8903e-05 - mean_absolute_error: 0.0046 - val_loss: 2.9801e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.2408e-05 - mean_absolute_error: 0.0041 - val_loss: 5.8721e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.6387e-05 - mean_absolute_error: 0.0044 - val_loss: 2.5183e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.5844e-05 - mean_absolute_error: 0.0042 - val_loss: 6.3532e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.1080e-05 - mean_absolute_error: 0.0040 - val_loss: 3.2525e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.5724e-05 - mean_absolute_error: 0.0044 - val_loss: 3.9462e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.0000e-05 - mean_absolute_error: 0.0039 - val_loss: 4.0138e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.1137e-05 - mean_absolute_error: 0.0040 - val_loss: 5.4863e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.2627e-05 - mean_absolute_error: 0.0041 - val_loss: 3.1192e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.1476e-05 - mean_absolute_error: 0.0041 - val_loss: 3.5393e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 3.1246e-05 - mean_absolute_error: 0.0040 - val_loss: 2.6464e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.8137e-05 - mean_absolute_error: 0.0038 - val_loss: 2.6477e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.2583e-05 - mean_absolute_error: 0.0041 - val_loss: 3.3158e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7900e-05 - mean_absolute_error: 0.0038 - val_loss: 3.4302e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.0735e-05 - mean_absolute_error: 0.0040 - val_loss: 3.2509e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.8161e-05 - mean_absolute_error: 0.0038 - val_loss: 2.4333e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.9886e-05 - mean_absolute_error: 0.0039 - val_loss: 3.5859e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.8819e-05 - mean_absolute_error: 0.0038 - val_loss: 3.7408e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7174e-05 - mean_absolute_error: 0.0037 - val_loss: 3.0062e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.8439e-05 - mean_absolute_error: 0.0038 - val_loss: 3.8207e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.9490e-05 - mean_absolute_error: 0.0039 - val_loss: 2.3222e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6321e-05 - mean_absolute_error: 0.0036 - val_loss: 4.0371e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.9575e-05 - mean_absolute_error: 0.0039 - val_loss: 8.1351e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 3.1124e-05 - mean_absolute_error: 0.0039 - val_loss: 2.4874e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5562e-05 - mean_absolute_error: 0.0036 - val_loss: 3.3607e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6657e-05 - mean_absolute_error: 0.0037 - val_loss: 4.0262e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7623e-05 - mean_absolute_error: 0.0038 - val_loss: 2.6294e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.9161e-05 - mean_absolute_error: 0.0038 - val_loss: 4.2945e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.6048e-05 - mean_absolute_error: 0.0036 - val_loss: 2.7210e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.8684e-05 - mean_absolute_error: 0.0038 - val_loss: 2.3438e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.6902e-05 - mean_absolute_error: 0.0037 - val_loss: 3.7206e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5208e-05 - mean_absolute_error: 0.0035 - val_loss: 3.5274e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.7062e-05 - mean_absolute_error: 0.0037 - val_loss: 2.7142e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7726e-05 - mean_absolute_error: 0.0037 - val_loss: 3.7494e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.9221e-05 - mean_absolute_error: 0.0038 - val_loss: 2.4316e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7541e-05 - mean_absolute_error: 0.0037 - val_loss: 3.1286e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3589e-05 - mean_absolute_error: 0.0034 - val_loss: 2.5515e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5833e-05 - mean_absolute_error: 0.0036 - val_loss: 2.3596e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5573e-05 - mean_absolute_error: 0.0036 - val_loss: 2.5337e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7338e-05 - mean_absolute_error: 0.0037 - val_loss: 2.3452e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.2962e-05 - mean_absolute_error: 0.0033 - val_loss: 2.6139e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6508e-05 - mean_absolute_error: 0.0036 - val_loss: 3.3918e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6506e-05 - mean_absolute_error: 0.0036 - val_loss: 2.3245e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.4870e-05 - mean_absolute_error: 0.0035 - val_loss: 2.5748e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.7355e-05 - mean_absolute_error: 0.0037 - val_loss: 2.9387e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.6306e-05 - mean_absolute_error: 0.0036 - val_loss: 2.3522e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.2897e-05 - mean_absolute_error: 0.0033 - val_loss: 4.8673e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3724e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4491e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3754e-05 - mean_absolute_error: 0.0034 - val_loss: 2.5572e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.4903e-05 - mean_absolute_error: 0.0035 - val_loss: 2.7020e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5904e-05 - mean_absolute_error: 0.0036 - val_loss: 6.1199e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5337e-05 - mean_absolute_error: 0.0035 - val_loss: 2.4505e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5324e-05 - mean_absolute_error: 0.0035 - val_loss: 3.0534e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5716e-05 - mean_absolute_error: 0.0036 - val_loss: 2.7988e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.3422e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4892e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.4214e-05 - mean_absolute_error: 0.0034 - val_loss: 2.3883e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3969e-05 - mean_absolute_error: 0.0034 - val_loss: 4.4692e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.4584e-05 - mean_absolute_error: 0.0035 - val_loss: 2.4416e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5409e-05 - mean_absolute_error: 0.0036 - val_loss: 2.4299e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.1948e-05 - mean_absolute_error: 0.0032 - val_loss: 4.6945e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.6364e-05 - mean_absolute_error: 0.0037 - val_loss: 2.5336e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.7785e-05 - mean_absolute_error: 0.0038 - val_loss: 3.5604e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.2749e-05 - mean_absolute_error: 0.0034 - val_loss: 5.4699e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.1453e-05 - mean_absolute_error: 0.0032 - val_loss: 3.7647e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.5128e-05 - mean_absolute_error: 0.0035 - val_loss: 2.8103e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3983e-05 - mean_absolute_error: 0.0035 - val_loss: 2.2543e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3559e-05 - mean_absolute_error: 0.0034 - val_loss: 2.3334e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3658e-05 - mean_absolute_error: 0.0034 - val_loss: 3.4727e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3996e-05 - mean_absolute_error: 0.0034 - val_loss: 3.6056e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.4617e-05 - mean_absolute_error: 0.0035 - val_loss: 6.7850e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.3409e-05 - mean_absolute_error: 0.0034 - val_loss: 4.3213e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.2573e-05 - mean_absolute_error: 0.0033 - val_loss: 2.9479e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.2505e-05 - mean_absolute_error: 0.0033 - val_loss: 3.5342e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.4581e-05 - mean_absolute_error: 0.0035 - val_loss: 2.3268e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.2995e-05 - mean_absolute_error: 0.0033 - val_loss: 2.2332e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.3835e-05 - mean_absolute_error: 0.0034 - val_loss: 3.7951e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3889e-05 - mean_absolute_error: 0.0034 - val_loss: 2.3272e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.2248e-05 - mean_absolute_error: 0.0033 - val_loss: 2.3251e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.4285e-05 - mean_absolute_error: 0.0034 - val_loss: 2.4484e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.4850e-05 - mean_absolute_error: 0.0035 - val_loss: 2.6664e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.2862e-05 - mean_absolute_error: 0.0033 - val_loss: 2.3011e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3427e-05 - mean_absolute_error: 0.0034 - val_loss: 4.5037e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.2479e-05 - mean_absolute_error: 0.0033 - val_loss: 2.2039e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3996e-05 - mean_absolute_error: 0.0034 - val_loss: 2.2813e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 2.3609e-05 - mean_absolute_error: 0.0034 - val_loss: 4.8090e-05 - val_mean_absolute_error: 0.0055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgbLRfO6jrZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "67037adf-2e5b-4aa4-d19c-678b6b8219f7"
      },
      "source": [
        "\n",
        "ytrue=denorm(y_test,df.target)\n",
        "yhat=denorm(model.predict(X_test),df.target)\n",
        "\n",
        "model.evaluate(X_test,y_test)\n",
        "print(\"sklearn mae：\",sklearn.metrics.mean_absolute_error(ytrue,yhat))\n",
        "\n",
        "gene_hist(ytrue,yhat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159/159 [==============================] - 0s 1ms/step - loss: 2.9335e-05 - mean_absolute_error: 0.0035\n",
            "sklearn mae： 3.9680288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnFae-anjrVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b1d3277-ff1a-49d1-f0e0-c4d49187ef86"
      },
      "source": [
        "calculate_profit(ytrue,yhat).head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "profit is 183.0185546875 position in portfolio is 0\n",
            "5063 (5063, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t</th>\n",
              "      <th>yhat</th>\n",
              "      <th>ytrue</th>\n",
              "      <th>profit</th>\n",
              "      <th>position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3062.427246</td>\n",
              "      <td>3067.877686</td>\n",
              "      <td>3066.791016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3066.791016</td>\n",
              "      <td>3069.314941</td>\n",
              "      <td>3071.956055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3071.956055</td>\n",
              "      <td>3073.448486</td>\n",
              "      <td>3066.280518</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3066.280518</td>\n",
              "      <td>3067.360352</td>\n",
              "      <td>3069.441650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3069.441650</td>\n",
              "      <td>3069.085693</td>\n",
              "      <td>3066.136230</td>\n",
              "      <td>7.014404</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3066.136230</td>\n",
              "      <td>3065.026855</td>\n",
              "      <td>3069.037842</td>\n",
              "      <td>7.014404</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3069.037842</td>\n",
              "      <td>3068.193359</td>\n",
              "      <td>3070.945312</td>\n",
              "      <td>7.014404</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3070.945312</td>\n",
              "      <td>3072.110840</td>\n",
              "      <td>3068.328369</td>\n",
              "      <td>7.014404</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3068.328369</td>\n",
              "      <td>3068.632324</td>\n",
              "      <td>3065.647949</td>\n",
              "      <td>7.014404</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3065.647949</td>\n",
              "      <td>3064.768799</td>\n",
              "      <td>3064.843506</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3064.843506</td>\n",
              "      <td>3064.411621</td>\n",
              "      <td>3062.054199</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3062.054199</td>\n",
              "      <td>3059.498047</td>\n",
              "      <td>3068.572754</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3068.572754</td>\n",
              "      <td>3068.114502</td>\n",
              "      <td>3068.527832</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3068.527832</td>\n",
              "      <td>3067.169434</td>\n",
              "      <td>3067.875000</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3067.875000</td>\n",
              "      <td>3067.144531</td>\n",
              "      <td>3071.869141</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3071.869141</td>\n",
              "      <td>3071.615723</td>\n",
              "      <td>3072.779297</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3072.779297</td>\n",
              "      <td>3073.013672</td>\n",
              "      <td>3067.480957</td>\n",
              "      <td>1.717041</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3067.480957</td>\n",
              "      <td>3066.108887</td>\n",
              "      <td>3068.172852</td>\n",
              "      <td>-3.581299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3068.172852</td>\n",
              "      <td>3067.072510</td>\n",
              "      <td>3071.736816</td>\n",
              "      <td>-3.581299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3071.736816</td>\n",
              "      <td>3070.664062</td>\n",
              "      <td>3072.154541</td>\n",
              "      <td>-3.581299</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3072.154541</td>\n",
              "      <td>3072.562012</td>\n",
              "      <td>3069.416992</td>\n",
              "      <td>-3.581299</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3069.416992</td>\n",
              "      <td>3067.886719</td>\n",
              "      <td>3070.246338</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3070.246338</td>\n",
              "      <td>3069.319336</td>\n",
              "      <td>3071.677246</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3071.677246</td>\n",
              "      <td>3070.800293</td>\n",
              "      <td>3049.422363</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3049.422363</td>\n",
              "      <td>3043.318604</td>\n",
              "      <td>3049.930420</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3049.930420</td>\n",
              "      <td>3041.536621</td>\n",
              "      <td>3048.798096</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3048.798096</td>\n",
              "      <td>3043.866699</td>\n",
              "      <td>3043.282959</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3043.282959</td>\n",
              "      <td>3040.164062</td>\n",
              "      <td>3044.380859</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3044.380859</td>\n",
              "      <td>3038.717773</td>\n",
              "      <td>3047.313965</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3047.313965</td>\n",
              "      <td>3045.934570</td>\n",
              "      <td>3042.189453</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3042.189453</td>\n",
              "      <td>3041.659668</td>\n",
              "      <td>3037.630859</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3037.630859</td>\n",
              "      <td>3037.080566</td>\n",
              "      <td>3037.286865</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>3037.286865</td>\n",
              "      <td>3035.711914</td>\n",
              "      <td>3034.037109</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3034.037109</td>\n",
              "      <td>3031.408203</td>\n",
              "      <td>3039.937500</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>3039.937500</td>\n",
              "      <td>3038.076172</td>\n",
              "      <td>3034.981445</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3034.981445</td>\n",
              "      <td>3032.433838</td>\n",
              "      <td>3040.439209</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3040.439209</td>\n",
              "      <td>3039.298096</td>\n",
              "      <td>3044.800293</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3044.800293</td>\n",
              "      <td>3043.636475</td>\n",
              "      <td>3042.771240</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3042.771240</td>\n",
              "      <td>3042.103516</td>\n",
              "      <td>3038.850098</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3038.850098</td>\n",
              "      <td>3036.915283</td>\n",
              "      <td>3039.439453</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>3039.439453</td>\n",
              "      <td>3037.393311</td>\n",
              "      <td>3036.189453</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3036.189453</td>\n",
              "      <td>3034.987793</td>\n",
              "      <td>3038.966553</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3038.966553</td>\n",
              "      <td>3035.729980</td>\n",
              "      <td>3035.939209</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3035.939209</td>\n",
              "      <td>3033.117432</td>\n",
              "      <td>3034.896484</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>3034.896484</td>\n",
              "      <td>3030.610840</td>\n",
              "      <td>3029.633057</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3029.633057</td>\n",
              "      <td>3026.155762</td>\n",
              "      <td>3038.998535</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>3038.998535</td>\n",
              "      <td>3037.116211</td>\n",
              "      <td>3041.649170</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>3041.649170</td>\n",
              "      <td>3038.294189</td>\n",
              "      <td>3043.789795</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3043.789795</td>\n",
              "      <td>3042.757324</td>\n",
              "      <td>3042.002930</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>3042.002930</td>\n",
              "      <td>3040.600586</td>\n",
              "      <td>3045.737793</td>\n",
              "      <td>-6.318848</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              t         yhat        ytrue    profit  position\n",
              "1   3062.427246  3067.877686  3066.791016  0.000000         1\n",
              "2   3066.791016  3069.314941  3071.956055  0.000000         1\n",
              "3   3071.956055  3073.448486  3066.280518  0.000000         1\n",
              "4   3066.280518  3067.360352  3069.441650  0.000000         1\n",
              "5   3069.441650  3069.085693  3066.136230  7.014404         0\n",
              "6   3066.136230  3065.026855  3069.037842  7.014404         0\n",
              "7   3069.037842  3068.193359  3070.945312  7.014404         0\n",
              "8   3070.945312  3072.110840  3068.328369  7.014404         1\n",
              "9   3068.328369  3068.632324  3065.647949  7.014404         1\n",
              "10  3065.647949  3064.768799  3064.843506  1.717041         0\n",
              "11  3064.843506  3064.411621  3062.054199  1.717041         0\n",
              "12  3062.054199  3059.498047  3068.572754  1.717041         0\n",
              "13  3068.572754  3068.114502  3068.527832  1.717041         0\n",
              "14  3068.527832  3067.169434  3067.875000  1.717041         0\n",
              "15  3067.875000  3067.144531  3071.869141  1.717041         0\n",
              "16  3071.869141  3071.615723  3072.779297  1.717041         0\n",
              "17  3072.779297  3073.013672  3067.480957  1.717041         1\n",
              "18  3067.480957  3066.108887  3068.172852 -3.581299         0\n",
              "19  3068.172852  3067.072510  3071.736816 -3.581299         0\n",
              "20  3071.736816  3070.664062  3072.154541 -3.581299         0\n",
              "21  3072.154541  3072.562012  3069.416992 -3.581299         1\n",
              "22  3069.416992  3067.886719  3070.246338 -6.318848         0\n",
              "23  3070.246338  3069.319336  3071.677246 -6.318848         0\n",
              "24  3071.677246  3070.800293  3049.422363 -6.318848         0\n",
              "25  3049.422363  3043.318604  3049.930420 -6.318848         0\n",
              "26  3049.930420  3041.536621  3048.798096 -6.318848         0\n",
              "27  3048.798096  3043.866699  3043.282959 -6.318848         0\n",
              "28  3043.282959  3040.164062  3044.380859 -6.318848         0\n",
              "29  3044.380859  3038.717773  3047.313965 -6.318848         0\n",
              "30  3047.313965  3045.934570  3042.189453 -6.318848         0\n",
              "31  3042.189453  3041.659668  3037.630859 -6.318848         0\n",
              "32  3037.630859  3037.080566  3037.286865 -6.318848         0\n",
              "33  3037.286865  3035.711914  3034.037109 -6.318848         0\n",
              "34  3034.037109  3031.408203  3039.937500 -6.318848         0\n",
              "35  3039.937500  3038.076172  3034.981445 -6.318848         0\n",
              "36  3034.981445  3032.433838  3040.439209 -6.318848         0\n",
              "37  3040.439209  3039.298096  3044.800293 -6.318848         0\n",
              "38  3044.800293  3043.636475  3042.771240 -6.318848         0\n",
              "39  3042.771240  3042.103516  3038.850098 -6.318848         0\n",
              "40  3038.850098  3036.915283  3039.439453 -6.318848         0\n",
              "41  3039.439453  3037.393311  3036.189453 -6.318848         0\n",
              "42  3036.189453  3034.987793  3038.966553 -6.318848         0\n",
              "43  3038.966553  3035.729980  3035.939209 -6.318848         0\n",
              "44  3035.939209  3033.117432  3034.896484 -6.318848         0\n",
              "45  3034.896484  3030.610840  3029.633057 -6.318848         0\n",
              "46  3029.633057  3026.155762  3038.998535 -6.318848         0\n",
              "47  3038.998535  3037.116211  3041.649170 -6.318848         0\n",
              "48  3041.649170  3038.294189  3043.789795 -6.318848         0\n",
              "49  3043.789795  3042.757324  3042.002930 -6.318848         0\n",
              "50  3042.002930  3040.600586  3045.737793 -6.318848         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugQ_MwYuQ7v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iulpi-1QQ7yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gkhK_ivQ77n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eFtacGbQ79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvksuCwnQ8HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7zSAlgtQ8Bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}